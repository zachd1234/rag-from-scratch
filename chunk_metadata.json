{"0": {"text": "Introduction\nThis API reference describes the RESTful, streaming, and realtime APIs you can use to interact with the OpenAI platform. REST APIs are usable via HTTP in any environment that supports HTTP requests. Language-specific SDKs are listed on the libraries page.\n\nAuthentication\nThe OpenAI API uses API keys for authentication. Create, manage, and learn more about API keys in your organization settings.\n\nRemember that your API key is a secret! Do not share it with others or expose it in any ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 0, "end_char": 500}, "1": {"text": " settings.\n\nRemember that your API key is a secret! Do not share it with others or expose it in any client-side code (browsers, apps). API keys should be securely loaded from an environment variable or key management service on the server.\n\nAPI keys should be provided via HTTP Bearer authentication.\n\nAuthorization: Bearer OPENAI_API_KEY\nIf you belong to multiple organizations or access projects through a legacy user API key, pass a header to specify which organization and project to use for an API request:\n\ncurl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 400, "end_char": 1000}, "2": {"text": "PI request:\n\ncurl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Organization: org-Ci6VEUzIwy4EEKmLMhL7iHWn\" \\\n  -H \"OpenAI-Project: $PROJECT_ID\"\nUsage from these API requests counts as usage for the specified organization and project.Organization IDs can be found on your organization settings page. Project IDs can be found on your general settings page by selecting the specific project.\n\nDebugging requests\nIn addition to error codes returned from API responses, you can inspect HTTP response headers containing the unique ID of a particular API re", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 900, "end_char": 1500}, "3": {"text": "API responses, you can inspect HTTP response headers containing the unique ID of a particular API request or information about rate limiting applied to your requests. Below is an incomplete list of HTTP headers returned with API responses:\n\nAPI meta information\n\nopenai-organization: The organization associated with the request\nopenai-processing-ms: Time taken processing your API request\nopenai-version: REST API version used for this request (currently 2020-10-01)\nx-request-id: Unique identifier for this API request (used in troubleshooting)\nRate limiting information\n\nx-ratelimit-limit-requests", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 1400, "end_char": 2000}, "4": {"text": "for this API request (used in troubleshooting)\nRate limiting information\n\nx-ratelimit-limit-requests\nx-ratelimit-limit-tokens\nx-ratelimit-remaining-requests\nx-ratelimit-remaining-tokens\nx-ratelimit-reset-requests\nx-ratelimit-reset-tokens\nOpenAI recommends logging request IDs in production deployments for more efficient troubleshooting with our support team, should the need arise. Our official SDKs provide a property on top-level response objects containing the value of the x-request-id header.\n\nBackward compatibility\nOpenAI is committed to providing stability to API users by avoiding breaking ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 1900, "end_char": 2500}, "5": {"text": "Backward compatibility\nOpenAI is committed to providing stability to API users by avoiding breaking changes in major API versions whenever reasonably possible. This includes:\n\nThe REST API (currently v1)\nOur first-party SDKs (released SDKs adhere to semantic versioning)\nModel families (like gpt-4o or o4-mini)\nModel prompting behavior between snapshots is subject to change. Model outputs are by their nature variable, so expect changes in prompting and model behavior between snapshots. For example, if you moved from gpt-4o-2024-05-13 to gpt-4o-2024-08-06, the same system or user messages could f", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 2400, "end_char": 3000}, "6": {"text": ", if you moved from gpt-4o-2024-05-13 to gpt-4o-2024-08-06, the same system or user messages could function differently between versions. The best way to ensure consistent prompting behavior and model output is to use pinned model versions, and to implement evals for your applications.\n\nBackwards-compatible API changes:\n\nAdding new resources (URLs) to the REST API and SDKs\nAdding new optional API parameters\nAdding new properties to JSON response objects or event data\nChanging the order of properties in a JSON response object\nChanging the length or format of opaque strings, like resource identi", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 2900, "end_char": 3500}, "7": {"text": "ties in a JSON response object\nChanging the length or format of opaque strings, like resource identifiers and UUIDs\nAdding new event types (in either streaming or the Realtime API)\nSee the changelog for a list of backwards-compatible changes and rare breaking changes.\n\nResponses\nOpenAI's most advanced interface for generating model responses. Supports text and image inputs, and text outputs. Create stateful interactions with the model, using the output of previous responses as input. Extend the model's capabilities with built-in tools for file search, web search, computer use, and more. Allow ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 3400, "end_char": 4000}, "8": {"text": "model's capabilities with built-in tools for file search, web search, computer use, and more. Allow the model access to external systems and data using function calling.\n\nRelated guides:\n\nQuickstart\nText inputs and outputs\nImage inputs\nStructured Outputs\nFunction calling\nConversation state\nExtend the models with tools\nCreate a model response\npost\n \nhttps://api.openai.com/v1/responses\nCreates a model response. Provide text or image inputs to generate text or JSON outputs. Have the model call your own custom code or use built-in tools like web search or file search to use your own data as input ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 3900, "end_char": 4500}, "9": {"text": " own custom code or use built-in tools like web search or file search to use your own data as input for the model's response.\n\nRequest body\ninput\nstring or array\n\nRequired\nText, image, or file inputs to the model, used to generate a response.\n\nLearn more:\n\nText inputs and outputs\nImage inputs\nFile inputs\nConversation state\nFunction calling\n\nShow possible types\nmodel\nstring\n\nRequired\nModel ID used to generate the response, like gpt-4o or o3. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the model guide to browse and com", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 4400, "end_char": 5000}, "10": {"text": "abilities, performance characteristics, and price points. Refer to the model guide to browse and compare available models.\n\ninclude\narray or null\n\nOptional\nSpecify additional output data to include in the model response. Currently supported values are:\n\nfile_search_call.results: Include the search results of the file search tool call.\nmessage.input_image.image_url: Include image urls from the input message.\ncomputer_call_output.output.image_url: Include image urls from the computer call output.\ninstructions\nstring or null\n\nOptional\nInserts a system (or developer) message as the first item in t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 4900, "end_char": 5500}, "11": {"text": "instructions\nstring or null\n\nOptional\nInserts a system (or developer) message as the first item in the model's context.\n\nWhen using along with previous_response_id, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.\n\nmax_output_tokens\ninteger or null\n\nOptional\nAn upper bound for the number of tokens that can be generated for a response, including visible output tokens and reasoning tokens.\n\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. Th", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 5400, "end_char": 6000}, "12": {"text": "ning tokens.\n\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nparallel_tool_calls\nboolean or null\n\nOptional\nDefaults to true\nWhether to allow the model to run tool calls in parallel.\n\nprevious_response_id\nstring or null\n\nOptional\nThe unique ID of the previous response to the model. Use this to crea", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 5900, "end_char": 6500}, "13": {"text": "se_id\nstring or null\n\nOptional\nThe unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about conversation state.\n\nreasoning\nobject or null\n\nOptional\no-series models only\n\nConfiguration options for reasoning models.\n\n\nShow properties\nservice_tier\nstring or null\n\nOptional\nDefaults to auto\nSpecifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:\n\nIf set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are ex", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 6400, "end_char": 7000}, "14": {"text": " and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.\nIf set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.\nIf set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.\nIf set to 'flex', the request will be processed with the Flex Processing service tier. Learn more.\nWhen not set, the default behavior is 'auto'.\nWhen this parameter is set, the response b", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 6900, "end_char": 7500}, "15": {"text": "Learn more.\nWhen not set, the default behavior is 'auto'.\nWhen this parameter is set, the response body will include the service_tier utilized.\n\nstore\nboolean or null\n\nOptional\nDefaults to true\nWhether to store the generated model response for later retrieval via API.\n\nstream\nboolean or null\n\nOptional\nDefaults to false\nIf set to true, the model response data will be streamed to the client as it is generated using server-sent events. See the Streaming section below for more information.\n\ntemperature\nnumber or null\n\nOptional\nDefaults to 1\nWhat sampling temperature to use, between 0 and 2. Higher", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 7400, "end_char": 8000}, "16": {"text": "ure\nnumber or null\n\nOptional\nDefaults to 1\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.\n\ntext\nobject\n\nOptional\nConfiguration options for a text response from the model. Can be plain text or structured JSON data. Learn more:\n\nText inputs and outputs\nStructured Outputs\n\nShow properties\ntool_choice\nstring or object\n\nOptional\nHow the model should select which tool (or tools) to use when generating a respo", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 7900, "end_char": 8500}, "17": {"text": "or object\n\nOptional\nHow the model should select which tool (or tools) to use when generating a response. See the tools parameter to see how to specify which tools the model can call.\n\n\nShow possible types\ntools\narray\n\nOptional\nAn array of tools the model may call while generating a response. You can specify which tool to use by setting the tool_choice parameter.\n\nThe two categories of tools you can provide the model are:\n\nBuilt-in tools: Tools that are provided by OpenAI that extend the model's capabilities, like web search or file search. Learn more about built-in tools.\nFunction calls (custo", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 8400, "end_char": 9000}, "18": {"text": "capabilities, like web search or file search. Learn more about built-in tools.\nFunction calls (custom tools): Functions that are defined by you, enabling the model to call your own code. Learn more about function calling.\n\nShow possible types\ntop_p\nnumber or null\n\nOptional\nDefaults to 1\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n\ntruncati", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 8900, "end_char": 9500}, "19": {"text": "ty mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n\ntruncation\nstring or null\n\nOptional\nDefaults to disabled\nThe truncation strategy to use for the model response.\n\nauto: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.\ndisabled (default): If a model response will exceed the context window size for a model, the request will fail with a 400 error.\nuser\nstring\n\nOptional\nA unique identifier repre", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 9400, "end_char": 10000}, "20": {"text": "for a model, the request will fail with a 400 error.\nuser\nstring\n\nOptional\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.\n\nReturns\nReturns a Response object.\n\n\nText input\n\nImage input\n\nWeb search\n\nFile search\n\nStreaming\n\nFunctions\n\nReasoning\nExample request\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nresponse = client.responses.create(\n  model=\"gpt-4.1\",\n  input=\"Tell me a three sentence bedtime story about a unicorn.\"\n)\n\nprint(response)\nResponse\n{\n  \"id\": \"resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b\",\n  \"object\": \"res", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 9900, "end_char": 10500}, "21": {"text": "sponse)\nResponse\n{\n  \"id\": \"resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b\",\n  \"object\": \"response\",\n  \"created_at\": 1741476542,\n  \"status\": \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\": \"gpt-4.1-2025-04-14\",\n  \"output\": [\n    {\n      \"type\": \"message\",\n      \"id\": \"msg_67ccd2bf17f0819081ff3bb2cf6508e60bb6a6b452d3795b\",\n      \"status\": \"completed\",\n      \"role\": \"assistant\",\n      \"content\": [\n        {\n          \"type\": \"output_text\",\n          \"text\": \"In a peaceful grove beneath a silver moon, a unicorn nam", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 10400, "end_char": 11000}, "22": {"text": "  \"type\": \"output_text\",\n          \"text\": \"In a peaceful grove beneath a silver moon, a unicorn named Lumina discovered a hidden pool that reflected the stars. As she dipped her horn into the water, the pool began to shimmer, revealing a pathway to a magical realm of endless night skies. Filled with wonder, Lumina whispered a wish for all who dream to find their own hidden magic, and as she glanced back, her hoofprints sparkled like stardust.\",\n          \"annotations\": []\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\": true,\n  \"previous_response_id\": null,\n  \"reasoning\": {\n    \"effort\":", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 10900, "end_char": 11500}, "23": {"text": "}\n  ],\n  \"parallel_tool_calls\": true,\n  \"previous_response_id\": null,\n  \"reasoning\": {\n    \"effort\": null,\n    \"summary\": null\n  },\n  \"store\": true,\n  \"temperature\": 1.0,\n  \"text\": {\n    \"format\": {\n      \"type\": \"text\"\n    }\n  },\n  \"tool_choice\": \"auto\",\n  \"tools\": [],\n  \"top_p\": 1.0,\n  \"truncation\": \"disabled\",\n  \"usage\": {\n    \"input_tokens\": 36,\n    \"input_tokens_details\": {\n      \"cached_tokens\": 0\n    },\n    \"output_tokens\": 87,\n    \"output_tokens_details\": {\n      \"reasoning_tokens\": 0\n    },\n    \"total_tokens\": 123\n  },\n  \"user\": null,\n  \"metadata\": {}\n}\nGet a model response\nget\n \nhttp", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 11400, "end_char": 12000}, "24": {"text": "  },\n    \"total_tokens\": 123\n  },\n  \"user\": null,\n  \"metadata\": {}\n}\nGet a model response\nget\n \nhttps://api.openai.com/v1/responses/{response_id}\nRetrieves a model response with the given ID.\n\nPath parameters\nresponse_id\nstring\n\nRequired\nThe ID of the response to retrieve.\n\nQuery parameters\ninclude\narray\n\nOptional\nAdditional fields to include in the response. See the include parameter for Response creation above for more information.\n\nReturns\nThe Response object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.responses.retrieve(\"resp_1", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 11900, "end_char": 12500}, "25": {"text": "le request\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.responses.retrieve(\"resp_123\")\nprint(response)\nResponse\n{\n  \"id\": \"resp_67cb71b351908190a308f3859487620d06981a8637e6bc44\",\n  \"object\": \"response\",\n  \"created_at\": 1741386163,\n  \"status\": \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"output\": [\n    {\n      \"type\": \"message\",\n      \"id\": \"msg_67cb71b3c2b0819084d481baaaf148f206981a8637e6bc44\",\n      \"status\": \"completed\",\n      \"role\": \"assistant\",\n      \"content\": [\n      ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 12400, "end_char": 13000}, "26": {"text": "06981a8637e6bc44\",\n      \"status\": \"completed\",\n      \"role\": \"assistant\",\n      \"content\": [\n        {\n          \"type\": \"output_text\",\n          \"text\": \"Silent circuits hum,  \\nThoughts emerge in data streams\u2014  \\nDigital dawn breaks.\",\n          \"annotations\": []\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\": true,\n  \"previous_response_id\": null,\n  \"reasoning\": {\n    \"effort\": null,\n    \"summary\": null\n  },\n  \"store\": true,\n  \"temperature\": 1.0,\n  \"text\": {\n    \"format\": {\n      \"type\": \"text\"\n    }\n  },\n  \"tool_choice\": \"auto\",\n  \"tools\": [],\n  \"top_p\": 1.0,\n  \"truncation\": \"disable", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 12900, "end_char": 13500}, "27": {"text": ": \"text\"\n    }\n  },\n  \"tool_choice\": \"auto\",\n  \"tools\": [],\n  \"top_p\": 1.0,\n  \"truncation\": \"disabled\",\n  \"usage\": {\n    \"input_tokens\": 32,\n    \"input_tokens_details\": {\n      \"cached_tokens\": 0\n    },\n    \"output_tokens\": 18,\n    \"output_tokens_details\": {\n      \"reasoning_tokens\": 0\n    },\n    \"total_tokens\": 50\n  },\n  \"user\": null,\n  \"metadata\": {}\n}\nDelete a model response\ndelete\n \nhttps://api.openai.com/v1/responses/{response_id}\nDeletes a model response with the given ID.\n\nPath parameters\nresponse_id\nstring\n\nRequired\nThe ID of the response to delete.\n\nReturns\nA success message.\n\nExample", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 13400, "end_char": 14000}, "28": {"text": "\nresponse_id\nstring\n\nRequired\nThe ID of the response to delete.\n\nReturns\nA success message.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.responses.del(\"resp_123\")\nprint(response)\nResponse\n{\n  \"id\": \"resp_6786a1bec27481909a17d673315b29f6\",\n  \"object\": \"response\",\n  \"deleted\": true\n}\nList input items\nget\n \nhttps://api.openai.com/v1/responses/{response_id}/input_items\nReturns a list of input items for a given response.\n\nPath parameters\nresponse_id\nstring\n\nRequired\nThe ID of the response to retrieve input items for.\n\nQuery parameters\nafter\nstring\n\nOptional\nAn ite", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 13900, "end_char": 14500}, "29": {"text": "\nThe ID of the response to retrieve input items for.\n\nQuery parameters\nafter\nstring\n\nOptional\nAn item ID to list items after, used in pagination.\n\nbefore\nstring\n\nOptional\nAn item ID to list items before, used in pagination.\n\ninclude\narray\n\nOptional\nAdditional fields to include in the response. See the include parameter for Response creation above for more information.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\n\nOptional\nThe order to return the input items in. Default is asc.\n\na", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 14400, "end_char": 15000}, "30": {"text": "he default is 20.\n\norder\nstring\n\nOptional\nThe order to return the input items in. Default is asc.\n\nasc: Return the input items in ascending order.\ndesc: Return the input items in descending order.\nReturns\nA list of input item objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.responses.input_items.list(\"resp_123\")\nprint(response.data)\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"msg_abc123\",\n      \"type\": \"message\",\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"input_text\",\n          \"text\": \"Tell me a three sentenc", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 14900, "end_char": 15500}, "31": {"text": "   \"content\": [\n        {\n          \"type\": \"input_text\",\n          \"text\": \"Tell me a three sentence bedtime story about a unicorn.\"\n        }\n      ]\n    }\n  ],\n  \"first_id\": \"msg_abc123\",\n  \"last_id\": \"msg_abc123\",\n  \"has_more\": false\n}\nThe response object\ncreated_at\nnumber\n\nUnix timestamp (in seconds) of when this Response was created.\n\nerror\nobject or null\n\nAn error object returned when the model fails to generate a Response.\n\n\nShow properties\nid\nstring\n\nUnique identifier for this Response.\n\nincomplete_details\nobject or null\n\nDetails about why the response is incomplete.\n\n\nShow properties", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 15400, "end_char": 16000}, "32": {"text": "\n\nincomplete_details\nobject or null\n\nDetails about why the response is incomplete.\n\n\nShow properties\ninstructions\nstring or null\n\nInserts a system (or developer) message as the first item in the model's context.\n\nWhen using along with previous_response_id, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.\n\nmax_output_tokens\ninteger or null\n\nAn upper bound for the number of tokens that can be generated for a response, including visible output tokens and reasoning tokens.\n\nmet", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 15900, "end_char": 16500}, "33": {"text": "ens that can be generated for a response, including visible output tokens and reasoning tokens.\n\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nmodel\nstring\n\nModel ID used to generate the response, like gpt-4o or o3. OpenAI offers a wide range of models with different capabilities, performance characterist", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 16400, "end_char": 17000}, "34": {"text": "4o or o3. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the model guide to browse and compare available models.\n\nobject\nstring\n\nThe object type of this resource - always set to response.\n\noutput\narray\n\nAn array of content items generated by the model.\n\nThe length and order of items in the output array is dependent on the model's response.\nRather than accessing the first item in the output array and assuming it's an assistant message with the content generated by the model, you might consider using the output_text prope", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 16900, "end_char": 17500}, "35": {"text": "tant message with the content generated by the model, you might consider using the output_text property where supported in SDKs.\n\nShow possible types\noutput_text\nstring or null\n\nSDK Only\nSDK-only convenience property that contains the aggregated text output from all output_text items in the output array, if any are present. Supported in the Python and JavaScript SDKs.\n\nparallel_tool_calls\nboolean\n\nWhether to allow the model to run tool calls in parallel.\n\nprevious_response_id\nstring or null\n\nThe unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 17400, "end_char": 18000}, "36": {"text": " unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about conversation state.\n\nreasoning\nobject or null\n\no-series models only\n\nConfiguration options for reasoning models.\n\n\nShow properties\nservice_tier\nstring or null\n\nSpecifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:\n\nIf set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.\nIf set to 'auto', and the Project is not Scale tier enabled,", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 17900, "end_char": 18500}, "37": {"text": " tier credits until they are exhausted.\nIf set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.\nIf set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.\nIf set to 'flex', the request will be processed with the Flex Processing service tier. Learn more.\nWhen not set, the default behavior is 'auto'.\nWhen this parameter is set, the response body will include the service_tier utilized.\n\nstatus\nstring\n\nThe statu", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 18400, "end_char": 19000}, "38": {"text": "arameter is set, the response body will include the service_tier utilized.\n\nstatus\nstring\n\nThe status of the response generation. One of completed, failed, in_progress, or incomplete.\n\ntemperature\nnumber or null\n\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.\n\ntext\nobject\n\nConfiguration options for a text response from the model. Can be plain text or structured JSON data. Learn more:\n\nText inputs and ou", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 18900, "end_char": 19500}, "39": {"text": " response from the model. Can be plain text or structured JSON data. Learn more:\n\nText inputs and outputs\nStructured Outputs\n\nShow properties\ntool_choice\nstring or object\n\nHow the model should select which tool (or tools) to use when generating a response. See the tools parameter to see how to specify which tools the model can call.\n\n\nShow possible types\ntools\narray\n\nAn array of tools the model may call while generating a response. You can specify which tool to use by setting the tool_choice parameter.\n\nThe two categories of tools you can provide the model are:\n\nBuilt-in tools: Tools that are ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 19400, "end_char": 20000}, "40": {"text": "ameter.\n\nThe two categories of tools you can provide the model are:\n\nBuilt-in tools: Tools that are provided by OpenAI that extend the model's capabilities, like web search or file search. Learn more about built-in tools.\nFunction calls (custom tools): Functions that are defined by you, enabling the model to call your own code. Learn more about function calling.\n\nShow possible types\ntop_p\nnumber or null\n\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 19900, "end_char": 20500}, "41": {"text": "ers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n\ntruncation\nstring or null\n\nThe truncation strategy to use for the model response.\n\nauto: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.\ndisabled (default): If a model response will exceed the context window size for a mode", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 20400, "end_char": 21000}, "42": {"text": "conversation.\ndisabled (default): If a model response will exceed the context window size for a model, the request will fail with a 400 error.\nusage\nobject\n\nRepresents token usage details including input tokens, output tokens, a breakdown of output tokens, and the total tokens used.\n\n\nShow properties\nuser\nstring\n\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.\n\nOBJECT The response object\n{\n  \"id\": \"resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41\",\n  \"object\": \"response\",\n  \"created_at\": 1741476777,\n  \"status\": \"completed\",\n  ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 20900, "end_char": 21500}, "43": {"text": "c604becb25c45c1d41\",\n  \"object\": \"response\",\n  \"created_at\": 1741476777,\n  \"status\": \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"output\": [\n    {\n      \"type\": \"message\",\n      \"id\": \"msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41\",\n      \"status\": \"completed\",\n      \"role\": \"assistant\",\n      \"content\": [\n        {\n          \"type\": \"output_text\",\n          \"text\": \"The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue s", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 21400, "end_char": 22000}, "44": {"text": "scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.\",\n          \"annotations\": []\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\": true,\n  \"previous_response_id\": null,\n  \"reasoning\": {\n    \"effort\": null,\n    \"summary\": null\n  },\n  \"store\": true,\n  \"temperature\": 1.0,\n  \"text\": {\n    \"format\": {\n      \"type\": \"text\"\n    }\n  },\n  \"tool_choice\": \"auto\",\n  \"tools\": [],\n  \"top_p\": 1.0,\n  \"truncation", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 21900, "end_char": 22500}, "45": {"text": "     \"type\": \"text\"\n    }\n  },\n  \"tool_choice\": \"auto\",\n  \"tools\": [],\n  \"top_p\": 1.0,\n  \"truncation\": \"disabled\",\n  \"usage\": {\n    \"input_tokens\": 328,\n    \"input_tokens_details\": {\n      \"cached_tokens\": 0\n    },\n    \"output_tokens\": 52,\n    \"output_tokens_details\": {\n      \"reasoning_tokens\": 0\n    },\n    \"total_tokens\": 380\n  },\n  \"user\": null,\n  \"metadata\": {}\n}\nThe input item list\nA list of Response items.\n\ndata\narray\n\nA list of items used to generate this response.\n\n\nShow possible types\nfirst_id\nstring\n\nThe ID of the first item in the list.\n\nhas_more\nboolean\n\nWhether there are more item", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 22400, "end_char": 23000}, "46": {"text": "irst_id\nstring\n\nThe ID of the first item in the list.\n\nhas_more\nboolean\n\nWhether there are more items available.\n\nlast_id\nstring\n\nThe ID of the last item in the list.\n\nobject\nstring\n\nThe type of object returned, must be list.\n\nOBJECT The input item list\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"msg_abc123\",\n      \"type\": \"message\",\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"input_text\",\n          \"text\": \"Tell me a three sentence bedtime story about a unicorn.\"\n        }\n      ]\n    }\n  ],\n  \"first_id\": \"msg_abc123\",\n  \"last_id\": \"msg_abc123\",\n  \"has_more\"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 22900, "end_char": 23500}, "47": {"text": "n.\"\n        }\n      ]\n    }\n  ],\n  \"first_id\": \"msg_abc123\",\n  \"last_id\": \"msg_abc123\",\n  \"has_more\": false\n}\nStreaming\nWhen you create a Response with stream set to true, the server will emit server-sent events to the client as the Response is generated. This section contains the events that are emitted by the server.\n\nLearn more about streaming responses.\n\nresponse.created\nAn event that is emitted when a response is created.\n\nresponse\nobject\n\nThe response that was created.\n\n\nShow properties\ntype\nstring\n\nThe type of the event. Always response.created.\n\nOBJECT response.created\n{\n  \"type\": \"res", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 23400, "end_char": 24000}, "48": {"text": "pe\nstring\n\nThe type of the event. Always response.created.\n\nOBJECT response.created\n{\n  \"type\": \"response.created\",\n  \"response\": {\n    \"id\": \"resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c\",\n    \"object\": \"response\",\n    \"created_at\": 1741487325,\n    \"status\": \"in_progress\",\n    \"error\": null,\n    \"incomplete_details\": null,\n    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\": \"gpt-4o-2024-08-06\",\n    \"output\": [],\n    \"parallel_tool_calls\": true,\n    \"previous_response_id\": null,\n    \"reasoning\": {\n      \"effort\": null,\n      \"summary\": null\n    },\n    \"store\": true,\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 23900, "end_char": 24500}, "49": {"text": "id\": null,\n    \"reasoning\": {\n      \"effort\": null,\n      \"summary\": null\n    },\n    \"store\": true,\n    \"temperature\": 1,\n    \"text\": {\n      \"format\": {\n        \"type\": \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\": [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\": null,\n    \"user\": null,\n    \"metadata\": {}\n  }\n}\nresponse.in_progress\nEmitted when the response is in progress.\n\nresponse\nobject\n\nThe response that is in progress.\n\n\nShow properties\ntype\nstring\n\nThe type of the event. Always response.in_progress.\n\nOBJECT response.in_progress\n{\n  \"type\": \"response.in_prog", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 24400, "end_char": 25000}, "50": {"text": "f the event. Always response.in_progress.\n\nOBJECT response.in_progress\n{\n  \"type\": \"response.in_progress\",\n  \"response\": {\n    \"id\": \"resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c\",\n    \"object\": \"response\",\n    \"created_at\": 1741487325,\n    \"status\": \"in_progress\",\n    \"error\": null,\n    \"incomplete_details\": null,\n    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\": \"gpt-4o-2024-08-06\",\n    \"output\": [],\n    \"parallel_tool_calls\": true,\n    \"previous_response_id\": null,\n    \"reasoning\": {\n      \"effort\": null,\n      \"summary\": null\n    },\n    \"store\": true,\n    \"temp", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 24900, "end_char": 25500}, "51": {"text": ",\n    \"reasoning\": {\n      \"effort\": null,\n      \"summary\": null\n    },\n    \"store\": true,\n    \"temperature\": 1,\n    \"text\": {\n      \"format\": {\n        \"type\": \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\": [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\": null,\n    \"user\": null,\n    \"metadata\": {}\n  }\n}\nresponse.completed\nEmitted when the model response is complete.\n\nresponse\nobject\n\nProperties of the completed response.\n\n\nShow properties\ntype\nstring\n\nThe type of the event. Always response.completed.\n\nOBJECT response.completed\n{\n  \"type\": \"response.completed\",\n  \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 25400, "end_char": 26000}, "52": {"text": "e event. Always response.completed.\n\nOBJECT response.completed\n{\n  \"type\": \"response.completed\",\n  \"response\": {\n    \"id\": \"resp_123\",\n    \"object\": \"response\",\n    \"created_at\": 1740855869,\n    \"status\": \"completed\",\n    \"error\": null,\n    \"incomplete_details\": null,\n    \"input\": [],\n    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"output\": [\n      {\n        \"id\": \"msg_123\",\n        \"type\": \"message\",\n        \"role\": \"assistant\",\n        \"content\": [\n          {\n            \"type\": \"output_text\",\n            \"text\": \"In a shimmering forest u", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 25900, "end_char": 26500}, "53": {"text": "ent\": [\n          {\n            \"type\": \"output_text\",\n            \"text\": \"In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.\",\n            \"annotations\": []\n          }\n        ]\n      }\n    ],\n    \"previous_response_id\": null,\n    \"reasoning_effort\": null,\n    \"store\": ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 26400, "end_char": 27000}, "54": {"text": "      ]\n      }\n    ],\n    \"previous_response_id\": null,\n    \"reasoning_effort\": null,\n    \"store\": false,\n    \"temperature\": 1,\n    \"text\": {\n      \"format\": {\n        \"type\": \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\": [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\": {\n      \"input_tokens\": 0,\n      \"output_tokens\": 0,\n      \"output_tokens_details\": {\n        \"reasoning_tokens\": 0\n      },\n      \"total_tokens\": 0\n    },\n    \"user\": null,\n    \"metadata\": {}\n  }\n}\nresponse.failed\nAn event that is emitted when a response fails.\n\nresponse\nobject\n\nThe response that", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 26900, "end_char": 27500}, "55": {"text": "\nresponse.failed\nAn event that is emitted when a response fails.\n\nresponse\nobject\n\nThe response that failed.\n\n\nShow properties\ntype\nstring\n\nThe type of the event. Always response.failed.\n\nOBJECT response.failed\n{\n  \"type\": \"response.failed\",\n  \"response\": {\n    \"id\": \"resp_123\",\n    \"object\": \"response\",\n    \"created_at\": 1740855869,\n    \"status\": \"failed\",\n    \"error\": {\n      \"code\": \"server_error\",\n      \"message\": \"The model failed to generate a response.\"\n    },\n    \"incomplete_details\": null,\n    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 27400, "end_char": 28000}, "56": {"text": "ll,\n    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"output\": [],\n    \"previous_response_id\": null,\n    \"reasoning_effort\": null,\n    \"store\": false,\n    \"temperature\": 1,\n    \"text\": {\n      \"format\": {\n        \"type\": \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\": [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\": null,\n    \"user\": null,\n    \"metadata\": {}\n  }\n}\nresponse.incomplete\nAn event that is emitted when a response finishes as incomplete.\n\nresponse\nobject\n\nThe response that was incomplete.\n\n\nShow properties", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 27900, "end_char": 28500}, "57": {"text": "sponse finishes as incomplete.\n\nresponse\nobject\n\nThe response that was incomplete.\n\n\nShow properties\ntype\nstring\n\nThe type of the event. Always response.incomplete.\n\nOBJECT response.incomplete\n{\n  \"type\": \"response.incomplete\",\n  \"response\": {\n    \"id\": \"resp_123\",\n    \"object\": \"response\",\n    \"created_at\": 1740855869,\n    \"status\": \"incomplete\",\n    \"error\": null, \n    \"incomplete_details\": {\n      \"reason\": \"max_tokens\"\n    },\n    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"output\": [],\n    \"previous_response_id\": null,\n    \"reasoning_eff", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 28400, "end_char": 29000}, "58": {"text": "l\": \"gpt-4o-mini-2024-07-18\",\n    \"output\": [],\n    \"previous_response_id\": null,\n    \"reasoning_effort\": null,\n    \"store\": false,\n    \"temperature\": 1,\n    \"text\": {\n      \"format\": {\n        \"type\": \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\": [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\": null,\n    \"user\": null,\n    \"metadata\": {}\n  }\n}\nresponse.output_item.added\nEmitted when a new output item is added.\n\nitem\nobject\n\nThe output item that was added.\n\n\nShow possible types\noutput_index\ninteger\n\nThe index of the output item that was added.\n\ntype\nstring\n\nThe typ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 28900, "end_char": 29500}, "59": {"text": "sible types\noutput_index\ninteger\n\nThe index of the output item that was added.\n\ntype\nstring\n\nThe type of the event. Always response.output_item.added.\n\nOBJECT response.output_item.added\n{\n  \"type\": \"response.output_item.added\",\n  \"output_index\": 0,\n  \"item\": {\n    \"id\": \"msg_123\",\n    \"status\": \"in_progress\",\n    \"type\": \"message\",\n    \"role\": \"assistant\",\n    \"content\": []\n  }\n}\nresponse.output_item.done\nEmitted when an output item is marked done.\n\nitem\nobject\n\nThe output item that was marked done.\n\n\nShow possible types\noutput_index\ninteger\n\nThe index of the output item that was marked done.\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 29400, "end_char": 30000}, "60": {"text": "one.\n\n\nShow possible types\noutput_index\ninteger\n\nThe index of the output item that was marked done.\n\ntype\nstring\n\nThe type of the event. Always response.output_item.done.\n\nOBJECT response.output_item.done\n{\n  \"type\": \"response.output_item.done\",\n  \"output_index\": 0,\n  \"item\": {\n    \"id\": \"msg_123\",\n    \"status\": \"completed\",\n    \"type\": \"message\",\n    \"role\": \"assistant\",\n    \"content\": [\n      {\n        \"type\": \"output_text\",\n        \"text\": \"In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she woul", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 29900, "end_char": 30500}, "61": {"text": "lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.\",\n        \"annotations\": []\n      }\n    ]\n  }\n}\nresponse.content_part.added\nEmitted when a new content part is added.\n\ncontent_index\ninteger\n\nThe index of the content part that was added.\n\nitem_id\nstring\n\nThe ID of the output item that the content part was added to.\n\noutput", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 30400, "end_char": 31000}, "62": {"text": "at was added.\n\nitem_id\nstring\n\nThe ID of the output item that the content part was added to.\n\noutput_index\ninteger\n\nThe index of the output item that the content part was added to.\n\npart\nobject\n\nThe content part that was added.\n\n\nShow possible types\ntype\nstring\n\nThe type of the event. Always response.content_part.added.\n\nOBJECT response.content_part.added\n{\n  \"type\": \"response.content_part.added\",\n  \"item_id\": \"msg_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"part\": {\n    \"type\": \"output_text\",\n    \"text\": \"\",\n    \"annotations\": []\n  }\n}\nresponse.content_part.done\nEmitted when a content", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 30900, "end_char": 31500}, "63": {"text": "text\",\n    \"text\": \"\",\n    \"annotations\": []\n  }\n}\nresponse.content_part.done\nEmitted when a content part is done.\n\ncontent_index\ninteger\n\nThe index of the content part that is done.\n\nitem_id\nstring\n\nThe ID of the output item that the content part was added to.\n\noutput_index\ninteger\n\nThe index of the output item that the content part was added to.\n\npart\nobject\n\nThe content part that is done.\n\n\nShow possible types\ntype\nstring\n\nThe type of the event. Always response.content_part.done.\n\nOBJECT response.content_part.done\n{\n  \"type\": \"response.content_part.done\",\n  \"item_id\": \"msg_123\",\n  \"output_i", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 31400, "end_char": 32000}, "64": {"text": "onse.content_part.done\n{\n  \"type\": \"response.content_part.done\",\n  \"item_id\": \"msg_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"part\": {\n    \"type\": \"output_text\",\n    \"text\": \"In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.\",\n    \"annotations\": []\n  }\n}\nresponse", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 31900, "end_char": 32500}, "65": {"text": " gathered around, eager to be friends and share in her magic.\",\n    \"annotations\": []\n  }\n}\nresponse.output_text.delta\nEmitted when there is an additional text delta.\n\ncontent_index\ninteger\n\nThe index of the content part that the text delta was added to.\n\ndelta\nstring\n\nThe text delta that was added.\n\nitem_id\nstring\n\nThe ID of the output item that the text delta was added to.\n\noutput_index\ninteger\n\nThe index of the output item that the text delta was added to.\n\ntype\nstring\n\nThe type of the event. Always response.output_text.delta.\n\nOBJECT response.output_text.delta\n{\n  \"type\": \"response.output_", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 32400, "end_char": 33000}, "66": {"text": " Always response.output_text.delta.\n\nOBJECT response.output_text.delta\n{\n  \"type\": \"response.output_text.delta\",\n  \"item_id\": \"msg_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"delta\": \"In\"\n}\nresponse.output_text.annotation.added\nEmitted when a text annotation is added.\n\nannotation\nobject\n\nannotation_index\ninteger\n\nThe index of the annotation that was added.\n\ncontent_index\ninteger\n\nThe index of the content part that the text annotation was added to.\n\nitem_id\nstring\n\nThe ID of the output item that the text annotation was added to.\n\noutput_index\ninteger\n\nThe index of the output item that t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 32900, "end_char": 33500}, "67": {"text": "em that the text annotation was added to.\n\noutput_index\ninteger\n\nThe index of the output item that the text annotation was added to.\n\ntype\nstring\n\nThe type of the event. Always response.output_text.annotation.added.\n\nOBJECT response.output_text.annotation.added\n{\n  \"type\": \"response.output_text.annotation.added\",\n  \"item_id\": \"msg_abc123\",\n  \"output_index\": 1,\n  \"content_index\": 0,\n  \"annotation_index\": 0,\n  \"annotation\": {\n    \"type\": \"file_citation\",\n    \"index\": 390,\n    \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\",\n    \"filename\": \"dragons.pdf\"\n  }\n}\nresponse.output_text.done\nEmitted when text", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 33400, "end_char": 34000}, "68": {"text": "5b167pAf72nx1h9eiN\",\n    \"filename\": \"dragons.pdf\"\n  }\n}\nresponse.output_text.done\nEmitted when text content is finalized.\n\ncontent_index\ninteger\n\nThe index of the content part that the text content is finalized.\n\nitem_id\nstring\n\nThe ID of the output item that the text content is finalized.\n\noutput_index\ninteger\n\nThe index of the output item that the text content is finalized.\n\ntext\nstring\n\nThe text content that is finalized.\n\ntype\nstring\n\nThe type of the event. Always response.output_text.done.\n\nOBJECT response.output_text.done\n{\n  \"type\": \"response.output_text.done\",\n  \"item_id\": \"msg_123\",\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 33900, "end_char": 34500}, "69": {"text": "\n\nOBJECT response.output_text.done\n{\n  \"type\": \"response.output_text.done\",\n  \"item_id\": \"msg_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"text\": \"In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.\"\n}\nresponse.refusal.delta\nEmitted when there is a partial refusal te", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 34400, "end_char": 35000}, "70": {"text": "friends and share in her magic.\"\n}\nresponse.refusal.delta\nEmitted when there is a partial refusal text.\n\ncontent_index\ninteger\n\nThe index of the content part that the refusal text is added to.\n\ndelta\nstring\n\nThe refusal text that is added.\n\nitem_id\nstring\n\nThe ID of the output item that the refusal text is added to.\n\noutput_index\ninteger\n\nThe index of the output item that the refusal text is added to.\n\ntype\nstring\n\nThe type of the event. Always response.refusal.delta.\n\nOBJECT response.refusal.delta\n{\n  \"type\": \"response.refusal.delta\",\n  \"item_id\": \"msg_123\",\n  \"output_index\": 0,\n  \"content_in", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 34900, "end_char": 35500}, "71": {"text": "lta\n{\n  \"type\": \"response.refusal.delta\",\n  \"item_id\": \"msg_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"delta\": \"refusal text so far\"\n}\nresponse.refusal.done\nEmitted when refusal text is finalized.\n\ncontent_index\ninteger\n\nThe index of the content part that the refusal text is finalized.\n\nitem_id\nstring\n\nThe ID of the output item that the refusal text is finalized.\n\noutput_index\ninteger\n\nThe index of the output item that the refusal text is finalized.\n\nrefusal\nstring\n\nThe refusal text that is finalized.\n\ntype\nstring\n\nThe type of the event. Always response.refusal.done.\n\nOBJECT response.", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 35400, "end_char": 36000}, "72": {"text": "t is finalized.\n\ntype\nstring\n\nThe type of the event. Always response.refusal.done.\n\nOBJECT response.refusal.done\n{\n  \"type\": \"response.refusal.done\",\n  \"item_id\": \"item-abc\",\n  \"output_index\": 1,\n  \"content_index\": 2,\n  \"refusal\": \"final refusal text\"\n}\nresponse.function_call_arguments.delta\nEmitted when there is a partial function-call arguments delta.\n\ndelta\nstring\n\nThe function-call arguments delta that is added.\n\nitem_id\nstring\n\nThe ID of the output item that the function-call arguments delta is added to.\n\noutput_index\ninteger\n\nThe index of the output item that the function-call arguments ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 35900, "end_char": 36500}, "73": {"text": "a is added to.\n\noutput_index\ninteger\n\nThe index of the output item that the function-call arguments delta is added to.\n\ntype\nstring\n\nThe type of the event. Always response.function_call_arguments.delta.\n\nOBJECT response.function_call_arguments.delta\n{\n  \"type\": \"response.function_call_arguments.delta\",\n  \"item_id\": \"item-abc\",\n  \"output_index\": 0,\n  \"delta\": \"{ \\\"arg\\\":\"\n}\nresponse.function_call_arguments.done\nEmitted when function-call arguments are finalized.\n\narguments\nstring\n\nThe function-call arguments.\n\nitem_id\nstring\n\nThe ID of the item.\n\noutput_index\ninteger\n\nThe index of the output it", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 36400, "end_char": 37000}, "74": {"text": "ll arguments.\n\nitem_id\nstring\n\nThe ID of the item.\n\noutput_index\ninteger\n\nThe index of the output item.\n\ntype\nstring\n\nOBJECT response.function_call_arguments.done\n{\n  \"type\": \"response.function_call_arguments.done\",\n  \"item_id\": \"item-abc\",\n  \"output_index\": 1,\n  \"arguments\": \"{ \\\"arg\\\": 123 }\"\n}\nresponse.file_search_call.in_progress\nEmitted when a file search call is initiated.\n\nitem_id\nstring\n\nThe ID of the output item that the file search call is initiated.\n\noutput_index\ninteger\n\nThe index of the output item that the file search call is initiated.\n\ntype\nstring\n\nThe type of the event. Always", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 36900, "end_char": 37500}, "75": {"text": " the output item that the file search call is initiated.\n\ntype\nstring\n\nThe type of the event. Always response.file_search_call.in_progress.\n\nOBJECT response.file_search_call.in_progress\n{\n  \"type\": \"response.file_search_call.in_progress\",\n  \"output_index\": 0,\n  \"item_id\": \"fs_123\",\n}\nresponse.file_search_call.searching\nEmitted when a file search is currently searching.\n\nitem_id\nstring\n\nThe ID of the output item that the file search call is initiated.\n\noutput_index\ninteger\n\nThe index of the output item that the file search call is searching.\n\ntype\nstring\n\nThe type of the event. Always response.", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 37400, "end_char": 38000}, "76": {"text": "t item that the file search call is searching.\n\ntype\nstring\n\nThe type of the event. Always response.file_search_call.searching.\n\nOBJECT response.file_search_call.searching\n{\n  \"type\": \"response.file_search_call.searching\",\n  \"output_index\": 0,\n  \"item_id\": \"fs_123\",\n}\nresponse.file_search_call.completed\nEmitted when a file search call is completed (results found).\n\nitem_id\nstring\n\nThe ID of the output item that the file search call is initiated.\n\noutput_index\ninteger\n\nThe index of the output item that the file search call is initiated.\n\ntype\nstring\n\nThe type of the event. Always response.file_", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 37900, "end_char": 38500}, "77": {"text": "m that the file search call is initiated.\n\ntype\nstring\n\nThe type of the event. Always response.file_search_call.completed.\n\nOBJECT response.file_search_call.completed\n{\n  \"type\": \"response.file_search_call.completed\",\n  \"output_index\": 0,\n  \"item_id\": \"fs_123\",\n}\nresponse.web_search_call.in_progress\nEmitted when a web search call is initiated.\n\nitem_id\nstring\n\nUnique ID for the output item associated with the web search call.\n\noutput_index\ninteger\n\nThe index of the output item that the web search call is associated with.\n\ntype\nstring\n\nThe type of the event. Always response.web_search_call.in_p", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 38400, "end_char": 39000}, "78": {"text": "h call is associated with.\n\ntype\nstring\n\nThe type of the event. Always response.web_search_call.in_progress.\n\nOBJECT response.web_search_call.in_progress\n{\n  \"type\": \"response.web_search_call.in_progress\",\n  \"output_index\": 0,\n  \"item_id\": \"ws_123\",\n}\nresponse.web_search_call.searching\nEmitted when a web search call is executing.\n\nitem_id\nstring\n\nUnique ID for the output item associated with the web search call.\n\noutput_index\ninteger\n\nThe index of the output item that the web search call is associated with.\n\ntype\nstring\n\nThe type of the event. Always response.web_search_call.searching.\n\nOBJECT", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 38900, "end_char": 39500}, "79": {"text": "ciated with.\n\ntype\nstring\n\nThe type of the event. Always response.web_search_call.searching.\n\nOBJECT response.web_search_call.searching\n{\n  \"type\": \"response.web_search_call.searching\",\n  \"output_index\": 0,\n  \"item_id\": \"ws_123\",\n}\nresponse.web_search_call.completed\nEmitted when a web search call is completed.\n\nitem_id\nstring\n\nUnique ID for the output item associated with the web search call.\n\noutput_index\ninteger\n\nThe index of the output item that the web search call is associated with.\n\ntype\nstring\n\nThe type of the event. Always response.web_search_call.completed.\n\nOBJECT response.web_search", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 39400, "end_char": 40000}, "80": {"text": "tring\n\nThe type of the event. Always response.web_search_call.completed.\n\nOBJECT response.web_search_call.completed\n{\n  \"type\": \"response.web_search_call.completed\",\n  \"output_index\": 0,\n  \"item_id\": \"ws_123\",\n}\nerror\nEmitted when an error occurs.\n\ncode\nstring or null\n\nThe error code.\n\nmessage\nstring\n\nThe error message.\n\nparam\nstring or null\n\nThe error parameter.\n\ntype\nstring\n\nThe type of the event. Always error.\n\nOBJECT error\n{\n  \"type\": \"error\",\n  \"code\": \"ERR_SOMETHING\",\n  \"message\": \"Something went wrong\",\n  \"param\": null\n}\nChat Completions\nThe Chat Completions API endpoint will generate a", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 39900, "end_char": 40500}, "81": {"text": "ng went wrong\",\n  \"param\": null\n}\nChat Completions\nThe Chat Completions API endpoint will generate a model response from a list of messages comprising a conversation.\n\nRelated guides:\n\nQuickstart\nText inputs and outputs\nImage inputs\nAudio inputs and outputs\nStructured Outputs\nFunction calling\nConversation state\nStarting a new project? We recommend trying Responses to take advantage of the latest OpenAI platform features. Compare Chat Completions with Responses.\n\nCreate chat completion\npost\n \nhttps://api.openai.com/v1/chat/completions\nStarting a new project? We recommend trying Responses to tak", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 40400, "end_char": 41000}, "82": {"text": "ps://api.openai.com/v1/chat/completions\nStarting a new project? We recommend trying Responses to take advantage of the latest OpenAI platform features. Compare Chat Completions with Responses.\n\nCreates a model response for the given chat conversation. Learn more in the text generation, vision, and audio guides.\n\nParameter support can differ depending on the model used to generate the response, particularly for newer reasoning models. Parameters that are only supported for reasoning models are noted below. For the current state of unsupported parameters in reasoning models, refer to the reasoni", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 40900, "end_char": 41500}, "83": {"text": "ted below. For the current state of unsupported parameters in reasoning models, refer to the reasoning guide.\n\nRequest body\nmessages\narray\n\nRequired\nA list of messages comprising the conversation so far. Depending on the model you use, different message types (modalities) are supported, like text, images, and audio.\n\n\nShow possible types\nmodel\nstring\n\nRequired\nModel ID used to generate the response, like gpt-4o or o3. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the model guide to browse and compare available models.\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 41400, "end_char": 42000}, "84": {"text": "characteristics, and price points. Refer to the model guide to browse and compare available models.\n\naudio\nobject or null\n\nOptional\nParameters for audio output. Required when audio output is requested with modalities: [\"audio\"]. Learn more.\n\n\nShow properties\nfrequency_penalty\nnumber or null\n\nOptional\nDefaults to 0\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n\nfunction_call\nDeprecated\nstring or object\n\nOptional\nDeprecated in favor of tool_choice.\n\nControl", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 41900, "end_char": 42500}, "85": {"text": "m.\n\nfunction_call\nDeprecated\nstring or object\n\nOptional\nDeprecated in favor of tool_choice.\n\nControls which (if any) function is called by the model.\n\nnone means the model will not call a function and instead generates a message.\n\nauto means the model can pick between generating a message or calling a function.\n\nSpecifying a particular function via {\"name\": \"my_function\"} forces the model to call that function.\n\nnone is the default when no functions are present. auto is the default if functions are present.\n\n\nShow possible types\nfunctions\nDeprecated\narray\n\nOptional\nDeprecated in favor of tools", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 42400, "end_char": 43000}, "86": {"text": "are present.\n\n\nShow possible types\nfunctions\nDeprecated\narray\n\nOptional\nDeprecated in favor of tools.\n\nA list of functions the model may generate JSON inputs for.\n\n\nShow properties\nlogit_bias\nmap\n\nOptional\nDefaults to null\nModify the likelihood of specified tokens appearing in the completion.\n\nAccepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease o", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 42900, "end_char": 43500}, "87": {"text": "ior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.\n\nlogprobs\nboolean or null\n\nOptional\nDefaults to false\nWhether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message.\n\nmax_completion_tokens\ninteger or null\n\nOptional\nAn upper bound for the number of tokens that can be generated for a completion, including visible output to", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 43400, "end_char": 44000}, "88": {"text": "r bound for the number of tokens that can be generated for a completion, including visible output tokens and reasoning tokens.\n\nmax_tokens\nDeprecated\ninteger or null\n\nOptional\nThe maximum number of tokens that can be generated in the chat completion. This value can be used to control costs for text generated via API.\n\nThis value is now deprecated in favor of max_completion_tokens, and is not compatible with o-series models.\n\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 43900, "end_char": 44500}, "89": {"text": "o an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nmodalities\narray or null\n\nOptional\nOutput types that you would like the model to generate. Most models are capable of generating text, which is the default:\n\n[\"text\"]\n\nThe gpt-4o-audio-preview model can also be used to generate audio. To request that this model generate both text and audio responses, you can use:\n\n[\"text", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 44400, "end_char": 45000}, "90": {"text": "erate audio. To request that this model generate both text and audio responses, you can use:\n\n[\"text\", \"audio\"]\n\nn\ninteger or null\n\nOptional\nDefaults to 1\nHow many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep n as 1 to minimize costs.\n\nparallel_tool_calls\nboolean\n\nOptional\nDefaults to true\nWhether to enable parallel function calling during tool use.\n\nprediction\nobject\n\nOptional\nConfiguration for a Predicted Output, which can greatly improve response times when large parts of the", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 44900, "end_char": 45500}, "91": {"text": "nfiguration for a Predicted Output, which can greatly improve response times when large parts of the model response are known ahead of time. This is most common when you are regenerating a file with only minor changes to most of the content.\n\n\nShow possible types\npresence_penalty\nnumber or null\n\nOptional\nDefaults to 0\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n\nreasoning_effort\nstring or null\n\nOptional\nDefaults to medium\no-series models only\n\nConstrains effort on r", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 45400, "end_char": 46000}, "92": {"text": "ning_effort\nstring or null\n\nOptional\nDefaults to medium\no-series models only\n\nConstrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.\n\nresponse_format\nobject\n\nOptional\nAn object specifying the format that the model must output.\n\nSetting to { \"type\": \"json_schema\", \"json_schema\": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.\n\nSetting to { \"type\":", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 45900, "end_char": 46500}, "93": {"text": "l match your supplied JSON schema. Learn more in the Structured Outputs guide.\n\nSetting to { \"type\": \"json_object\" } enables the older JSON mode, which ensures the message the model generates is valid JSON. Using json_schema is preferred for models that support it.\n\n\nShow possible types\nseed\ninteger or null\n\nOptional\nThis feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint respons", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 46400, "end_char": 47000}, "94": {"text": "e same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend.\n\nservice_tier\nstring or null\n\nOptional\nDefaults to auto\nSpecifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:\n\nIf set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.\nIf set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 46900, "end_char": 47500}, "95": {"text": "ject is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.\nIf set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.\nIf set to 'flex', the request will be processed with the Flex Processing service tier. Learn more.\nWhen not set, the default behavior is 'auto'.\nWhen this parameter is set, the response body will include the service_tier utilized.\n\nstop\nstring / array / null\n\nOptional\nDefaults to null\nNot supported with latest reasoning mod", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 47400, "end_char": 48000}, "96": {"text": "ized.\n\nstop\nstring / array / null\n\nOptional\nDefaults to null\nNot supported with latest reasoning models o3 and o4-mini.\n\nUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.\n\nstore\nboolean or null\n\nOptional\nDefaults to false\nWhether or not to store the output of this chat completion request for use in our model distillation or evals products.\n\nstream\nboolean or null\n\nOptional\nDefaults to false\nIf set to true, the model response data will be streamed to the client as it is generated using server-sent events. See the Streaming", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 47900, "end_char": 48500}, "97": {"text": "e data will be streamed to the client as it is generated using server-sent events. See the Streaming section below for more information, along with the streaming responses guide for more information on how to handle the streaming events.\n\nstream_options\nobject or null\n\nOptional\nDefaults to null\nOptions for streaming response. Only set this when you set stream: true.\n\n\nShow properties\ntemperature\nnumber or null\n\nOptional\nDefaults to 1\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 48400, "end_char": 49000}, "98": {"text": "es like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.\n\ntool_choice\nstring or object\n\nOptional\nControls which (if any) tool is called by the model. none means the model will not call any tool and instead generates a message. auto means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools. Specifying a particular tool via {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} forces the model ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 48900, "end_char": 49500}, "99": {"text": "ng a particular tool via {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that tool.\n\nnone is the default when no tools are present. auto is the default if tools are present.\n\n\nShow possible types\ntools\narray\n\nOptional\nA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.\n\n\nShow properties\ntop_logprobs\ninteger or null\n\nOptional\nAn integer between 0 and 20 specifying the number of most likely tokens to return at ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 49400, "end_char": 50000}, "100": {"text": "null\n\nOptional\nAn integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. logprobs must be set to true if this parameter is used.\n\ntop_p\nnumber or null\n\nOptional\nDefaults to 1\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n\nuser\nstring\n\nOptional\nA unique i", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 49900, "end_char": 50500}, "101": {"text": "\nWe generally recommend altering this or temperature but not both.\n\nuser\nstring\n\nOptional\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.\n\nweb_search_options\nobject\n\nOptional\nThis tool searches the web for relevant results to use in a response. Learn more about the web search tool.\n\n\nShow properties\nReturns\nReturns a chat completion object, or a streamed sequence of chat completion chunk objects if the request is streamed.\n\n\nDefault\n\nImage input\n\nStreaming\n\nFunctions\n\nLogprobs\nExample request\nfrom openai import OpenAI\nclient = Open", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 50400, "end_char": 51000}, "102": {"text": "\nImage input\n\nStreaming\n\nFunctions\n\nLogprobs\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\ncompletion = client.chat.completions.create(\n  model=\"gpt-4.1\",\n  messages=[\n    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Hello!\"}\n  ]\n)\n\nprint(completion.choices[0].message)\nResponse\n{\n  \"id\": \"chatcmpl-B9MBs8CjcvOU2jLn4n570S5qMJKcT\",\n  \"object\": \"chat.completion\",\n  \"created\": 1741569952,\n  \"model\": \"gpt-4.1-2025-04-14\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"Hell", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 50900, "end_char": 51500}, "103": {"text": ": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"Hello! How can I assist you today?\",\n        \"refusal\": null,\n        \"annotations\": []\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 19,\n    \"completion_tokens\": 10,\n    \"total_tokens\": 29,\n    \"prompt_tokens_details\": {\n      \"cached_tokens\": 0,\n      \"audio_tokens\": 0\n    },\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0,\n      \"audio_tokens\": 0,\n      \"accepted_prediction_tokens\": 0,\n      \"rejected_prediction_tokens\":", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 51400, "end_char": 52000}, "104": {"text": "\n      \"audio_tokens\": 0,\n      \"accepted_prediction_tokens\": 0,\n      \"rejected_prediction_tokens\": 0\n    }\n  },\n  \"service_tier\": \"default\"\n}\nGet chat completion\nget\n \nhttps://api.openai.com/v1/chat/completions/{completion_id}\nGet a stored chat completion. Only Chat Completions that have been created with the store parameter set to true will be returned.\n\nPath parameters\ncompletion_id\nstring\n\nRequired\nThe ID of the chat completion to retrieve.\n\nReturns\nThe ChatCompletion object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\ncompletions = client.chat.", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 51900, "end_char": 52500}, "105": {"text": "ecified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\ncompletions = client.chat.completions.list()\nfirst_id = completions[0].id\nfirst_completion = client.chat.completions.retrieve(completion_id=first_id)\nprint(first_completion)\nResponse\n{\n  \"object\": \"chat.completion\",\n  \"id\": \"chatcmpl-abc123\",\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"created\": 1738960610,\n  \"request_id\": \"req_ded8ab984ec4bf840f37566c1011c417\",\n  \"tool_choice\": null,\n  \"usage\": {\n    \"total_tokens\": 31,\n    \"completion_tokens\": 18,\n    \"prompt_tokens\": 13\n  },\n  \"seed\": 4944116822809979520,\n  \"top_p\": 1.0,\n  \"te", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 52400, "end_char": 53000}, "106": {"text": "etion_tokens\": 18,\n    \"prompt_tokens\": 13\n  },\n  \"seed\": 4944116822809979520,\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"system_fingerprint\": \"fp_50cad350e4\",\n  \"input_user\": null,\n  \"service_tier\": \"default\",\n  \"tools\": null,\n  \"metadata\": {},\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"content\": \"Mind of circuits hum,  \\nLearning patterns in silence\u2014  \\nFuture's quiet spark.\",\n        \"role\": \"assistant\",\n        \"tool_calls\": null,\n        \"function_call\": null\n      },\n      \"finish_reason\": \"stop\",\n      \"logprob", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 52900, "end_char": 53500}, "107": {"text": "l_calls\": null,\n        \"function_call\": null\n      },\n      \"finish_reason\": \"stop\",\n      \"logprobs\": null\n    }\n  ],\n  \"response_format\": null\n}\nGet chat messages\nget\n \nhttps://api.openai.com/v1/chat/completions/{completion_id}/messages\nGet the messages in a stored chat completion. Only Chat Completions that have been created with the store parameter set to true will be returned.\n\nPath parameters\ncompletion_id\nstring\n\nRequired\nThe ID of the chat completion to retrieve messages from.\n\nQuery parameters\nafter\nstring\n\nOptional\nIdentifier for the last message from the previous pagination request", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 53400, "end_char": 54000}, "108": {"text": "rameters\nafter\nstring\n\nOptional\nIdentifier for the last message from the previous pagination request.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nNumber of messages to retrieve.\n\norder\nstring\n\nOptional\nDefaults to asc\nSort order for messages by timestamp. Use asc for ascending order or desc for descending order. Defaults to asc.\n\nReturns\nA list of messages for the specified chat completion.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\ncompletions = client.chat.completions.list()\nfirst_id = completions[0].id\nfirst_completion = client.chat.completions.retrieve(completion_id=first_id", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 53900, "end_char": 54500}, "109": {"text": "st_id = completions[0].id\nfirst_completion = client.chat.completions.retrieve(completion_id=first_id)\nmessages = client.chat.completions.messages.list(completion_id=first_id)\nprint(messages)\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0\",\n      \"role\": \"user\",\n      \"content\": \"write a haiku about ai\",\n      \"name\": null,\n      \"content_parts\": null\n    }\n  ],\n  \"first_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0\",\n  \"last_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0\",\n  \"has_more\": false\n}\nList Chat Completions\nget\n \nhttps://api.ope", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 54400, "end_char": 55000}, "110": {"text": "-AyPNinnUqUDYo9SAdA52NobMflmj2-0\",\n  \"has_more\": false\n}\nList Chat Completions\nget\n \nhttps://api.openai.com/v1/chat/completions\nList stored Chat Completions. Only Chat Completions that have been stored with the store parameter set to true will be returned.\n\nQuery parameters\nafter\nstring\n\nOptional\nIdentifier for the last chat completion from the previous pagination request.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nNumber of Chat Completions to retrieve.\n\nmetadata\nmap\n\nOptional\nA list of metadata keys to filter the Chat Completions by. Example:\n\nmetadata[key1]=value1&metadata[key2]=value2\n\nmodel\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 54900, "end_char": 55500}, "111": {"text": "eys to filter the Chat Completions by. Example:\n\nmetadata[key1]=value1&metadata[key2]=value2\n\nmodel\nstring\n\nOptional\nThe model used to generate the Chat Completions.\n\norder\nstring\n\nOptional\nDefaults to asc\nSort order for Chat Completions by timestamp. Use asc for ascending order or desc for descending order. Defaults to asc.\n\nReturns\nA list of Chat Completions matching the specified filters.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\ncompletions = client.chat.completions.list()\nprint(completions)\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"chat.completi", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 55400, "end_char": 56000}, "112": {"text": ")\nprint(completions)\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"chat.completion\",\n      \"id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n      \"model\": \"gpt-4.1-2025-04-14\",\n      \"created\": 1738960610,\n      \"request_id\": \"req_ded8ab984ec4bf840f37566c1011c417\",\n      \"tool_choice\": null,\n      \"usage\": {\n        \"total_tokens\": 31,\n        \"completion_tokens\": 18,\n        \"prompt_tokens\": 13\n      },\n      \"seed\": 4944116822809979520,\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"presence_penalty\": 0.0,\n      \"frequency_penalty\": 0.0,\n      \"system_fingerprint\": \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 55900, "end_char": 56500}, "113": {"text": "\": 1.0,\n      \"presence_penalty\": 0.0,\n      \"frequency_penalty\": 0.0,\n      \"system_fingerprint\": \"fp_50cad350e4\",\n      \"input_user\": null,\n      \"service_tier\": \"default\",\n      \"tools\": null,\n      \"metadata\": {},\n      \"choices\": [\n        {\n          \"index\": 0,\n          \"message\": {\n            \"content\": \"Mind of circuits hum,  \\nLearning patterns in silence\u2014  \\nFuture's quiet spark.\",\n            \"role\": \"assistant\",\n            \"tool_calls\": null,\n            \"function_call\": null\n          },\n          \"finish_reason\": \"stop\",\n          \"logprobs\": null\n        }\n      ],\n      \"re", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 56400, "end_char": 57000}, "114": {"text": "       },\n          \"finish_reason\": \"stop\",\n          \"logprobs\": null\n        }\n      ],\n      \"response_format\": null\n    }\n  ],\n  \"first_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n  \"last_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n  \"has_more\": false\n}\nUpdate chat completion\npost\n \nhttps://api.openai.com/v1/chat/completions/{completion_id}\nModify a stored chat completion. Only Chat Completions that have been created with the store parameter set to true can be modified. Currently, the only supported modification is to update the metadata field.\n\nPath parameters\ncompletion_id\nstring\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 56900, "end_char": 57500}, "115": {"text": " only supported modification is to update the metadata field.\n\nPath parameters\ncompletion_id\nstring\n\nRequired\nThe ID of the chat completion to update.\n\nRequest body\nmetadata\nmap\n\nRequired\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nReturns\nThe ChatCompletion object matching the specified ID.\n\nExample request\nfrom ope", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 57400, "end_char": 58000}, "116": {"text": " characters.\n\nReturns\nThe ChatCompletion object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\ncompletions = client.chat.completions.list()\nfirst_id = completions[0].id\nupdated_completion = client.chat.completions.update(completion_id=first_id, request_body={\"metadata\": {\"foo\": \"bar\"}})\nprint(updated_completion)\nResponse\n{\n  \"object\": \"chat.completion\",\n  \"id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"created\": 1738960610,\n  \"request_id\": \"req_ded8ab984ec4bf840f37566c1011c417\",\n  \"tool_choice\": null,\n  \"usage\": {\n   ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 57900, "end_char": 58500}, "117": {"text": "610,\n  \"request_id\": \"req_ded8ab984ec4bf840f37566c1011c417\",\n  \"tool_choice\": null,\n  \"usage\": {\n    \"total_tokens\": 31,\n    \"completion_tokens\": 18,\n    \"prompt_tokens\": 13\n  },\n  \"seed\": 4944116822809979520,\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"system_fingerprint\": \"fp_50cad350e4\",\n  \"input_user\": null,\n  \"service_tier\": \"default\",\n  \"tools\": null,\n  \"metadata\": {\n    \"foo\": \"bar\"\n  },\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"content\": \"Mind of circuits hum,  \\nLearning patterns in silence\u2014  \\nFuture's quiet", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 58400, "end_char": 59000}, "118": {"text": "age\": {\n        \"content\": \"Mind of circuits hum,  \\nLearning patterns in silence\u2014  \\nFuture's quiet spark.\",\n        \"role\": \"assistant\",\n        \"tool_calls\": null,\n        \"function_call\": null\n      },\n      \"finish_reason\": \"stop\",\n      \"logprobs\": null\n    }\n  ],\n  \"response_format\": null\n}\nDelete chat completion\ndelete\n \nhttps://api.openai.com/v1/chat/completions/{completion_id}\nDelete a stored chat completion. Only Chat Completions that have been created with the store parameter set to true can be deleted.\n\nPath parameters\ncompletion_id\nstring\n\nRequired\nThe ID of the chat completion t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 58900, "end_char": 59500}, "119": {"text": "true can be deleted.\n\nPath parameters\ncompletion_id\nstring\n\nRequired\nThe ID of the chat completion to delete.\n\nReturns\nA deletion confirmation object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\ncompletions = client.chat.completions.list()\nfirst_id = completions[0].id\ndelete_response = client.chat.completions.delete(completion_id=first_id)\nprint(delete_response)\nResponse\n{\n  \"object\": \"chat.completion.deleted\",\n  \"id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n  \"deleted\": true\n}\nThe chat completion object\nRepresents a chat completion response returned by model, based on the ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 59400, "end_char": 60000}, "120": {"text": "\n}\nThe chat completion object\nRepresents a chat completion response returned by model, based on the provided input.\n\nchoices\narray\n\nA list of chat completion choices. Can be more than one if n is greater than 1.\n\n\nShow properties\ncreated\ninteger\n\nThe Unix timestamp (in seconds) of when the chat completion was created.\n\nid\nstring\n\nA unique identifier for the chat completion.\n\nmodel\nstring\n\nThe model used for the chat completion.\n\nobject\nstring\n\nThe object type, which is always chat.completion.\n\nservice_tier\nstring or null\n\nSpecifies the latency tier to use for processing the request. This param", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 59900, "end_char": 60500}, "121": {"text": "ervice_tier\nstring or null\n\nSpecifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:\n\nIf set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.\nIf set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.\nIf set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 60400, "end_char": 61000}, "122": {"text": " will be processed using the default service tier with a lower uptime SLA and no latency guarentee.\nIf set to 'flex', the request will be processed with the Flex Processing service tier. Learn more.\nWhen not set, the default behavior is 'auto'.\nWhen this parameter is set, the response body will include the service_tier utilized.\n\nsystem_fingerprint\nstring\n\nThis fingerprint represents the backend configuration that the model runs with.\n\nCan be used in conjunction with the seed request parameter to understand when backend changes have been made that might impact determinism.\n\nusage\nobject\n\nUsage", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 60900, "end_char": 61500}, "123": {"text": "o understand when backend changes have been made that might impact determinism.\n\nusage\nobject\n\nUsage statistics for the completion request.\n\n\nShow properties\nOBJECT The chat completion object\n{\n  \"id\": \"chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG\",\n  \"object\": \"chat.completion\",\n  \"created\": 1741570283,\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"The image shows a wooden boardwalk path running through a lush green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a seren", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 61400, "end_char": 62000}, "124": {"text": "h green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a serene and peaceful atmosphere. Trees and shrubs are visible in the background.\",\n        \"refusal\": null,\n        \"annotations\": []\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 1117,\n    \"completion_tokens\": 46,\n    \"total_tokens\": 1163,\n    \"prompt_tokens_details\": {\n      \"cached_tokens\": 0,\n      \"audio_tokens\": 0\n    },\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0,\n      \"audio_tokens\": 0,\n      \"accepted_prediction", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 61900, "end_char": 62500}, "125": {"text": "_tokens_details\": {\n      \"reasoning_tokens\": 0,\n      \"audio_tokens\": 0,\n      \"accepted_prediction_tokens\": 0,\n      \"rejected_prediction_tokens\": 0\n    }\n  },\n  \"service_tier\": \"default\",\n  \"system_fingerprint\": \"fp_fc9f1d7035\"\n}\nThe chat completion list object\nAn object representing a list of Chat Completions.\n\ndata\narray\n\nAn array of chat completion objects.\n\n\nShow properties\nfirst_id\nstring\n\nThe identifier of the first chat completion in the data array.\n\nhas_more\nboolean\n\nIndicates whether there are more Chat Completions available.\n\nlast_id\nstring\n\nThe identifier of the last chat complet", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 62400, "end_char": 63000}, "126": {"text": " there are more Chat Completions available.\n\nlast_id\nstring\n\nThe identifier of the last chat completion in the data array.\n\nobject\nstring\n\nThe type of this object. It is always set to \"list\".\n\nOBJECT The chat completion list object\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"chat.completion\",\n      \"id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n      \"model\": \"gpt-4o-2024-08-06\",\n      \"created\": 1738960610,\n      \"request_id\": \"req_ded8ab984ec4bf840f37566c1011c417\",\n      \"tool_choice\": null,\n      \"usage\": {\n        \"total_tokens\": 31,\n        \"completion_tokens\": 18,\n        \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 62900, "end_char": 63500}, "127": {"text": "oice\": null,\n      \"usage\": {\n        \"total_tokens\": 31,\n        \"completion_tokens\": 18,\n        \"prompt_tokens\": 13\n      },\n      \"seed\": 4944116822809979520,\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"presence_penalty\": 0.0,\n      \"frequency_penalty\": 0.0,\n      \"system_fingerprint\": \"fp_50cad350e4\",\n      \"input_user\": null,\n      \"service_tier\": \"default\",\n      \"tools\": null,\n      \"metadata\": {},\n      \"choices\": [\n        {\n          \"index\": 0,\n          \"message\": {\n            \"content\": \"Mind of circuits hum,  \\nLearning patterns in silence\u2014  \\nFuture's quiet spark.\",\n ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 63400, "end_char": 64000}, "128": {"text": "     \"content\": \"Mind of circuits hum,  \\nLearning patterns in silence\u2014  \\nFuture's quiet spark.\",\n            \"role\": \"assistant\",\n            \"tool_calls\": null,\n            \"function_call\": null\n          },\n          \"finish_reason\": \"stop\",\n          \"logprobs\": null\n        }\n      ],\n      \"response_format\": null\n    }\n  ],\n  \"first_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n  \"last_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n  \"has_more\": false\n}\nThe chat completion message list object\nAn object representing a list of chat completion messages.\n\ndata\narray\n\nAn array of chat compl", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 63900, "end_char": 64500}, "129": {"text": "bject\nAn object representing a list of chat completion messages.\n\ndata\narray\n\nAn array of chat completion message objects.\n\n\nShow properties\nfirst_id\nstring\n\nThe identifier of the first chat message in the data array.\n\nhas_more\nboolean\n\nIndicates whether there are more chat messages available.\n\nlast_id\nstring\n\nThe identifier of the last chat message in the data array.\n\nobject\nstring\n\nThe type of this object. It is always set to \"list\".\n\nOBJECT The chat completion message list object\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0\",\n      \"role\": \"u", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 64400, "end_char": 65000}, "130": {"text": ": \"list\",\n  \"data\": [\n    {\n      \"id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0\",\n      \"role\": \"user\",\n      \"content\": \"write a haiku about ai\",\n      \"name\": null,\n      \"content_parts\": null\n    }\n  ],\n  \"first_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0\",\n  \"last_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0\",\n  \"has_more\": false\n}\nStreaming\nStream Chat Completions in real time. Receive chunks of completions returned from the model using server-sent events. Learn more.\n\nThe chat completion chunk object\nRepresents a streamed chunk of a chat completion response returned by the model, ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 64900, "end_char": 65500}, "131": {"text": "etion chunk object\nRepresents a streamed chunk of a chat completion response returned by the model, based on the provided input. Learn more.\n\nchoices\narray\n\nA list of chat completion choices. Can contain more than one elements if n is greater than 1. Can also be empty for the last chunk if you set stream_options: {\"include_usage\": true}.\n\n\nShow properties\ncreated\ninteger\n\nThe Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.\n\nid\nstring\n\nA unique identifier for the chat completion. Each chunk has the same ID.\n\nmodel\nstring\n\nThe model to gene", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 65400, "end_char": 66000}, "132": {"text": "que identifier for the chat completion. Each chunk has the same ID.\n\nmodel\nstring\n\nThe model to generate the completion.\n\nobject\nstring\n\nThe object type, which is always chat.completion.chunk.\n\nservice_tier\nstring or null\n\nSpecifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:\n\nIf set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.\nIf set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 65900, "end_char": 66500}, "133": {"text": " 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.\nIf set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.\nIf set to 'flex', the request will be processed with the Flex Processing service tier. Learn more.\nWhen not set, the default behavior is 'auto'.\nWhen this parameter is set, the response body will include the service_tier utilized.\n\nsystem_fingerprint\nstring\n\nThis fingerprint represents the backend config", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 66400, "end_char": 67000}, "134": {"text": "he service_tier utilized.\n\nsystem_fingerprint\nstring\n\nThis fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the seed request parameter to understand when backend changes have been made that might impact determinism.\n\nusage\nobject or null\n\nUsage statistics for the completion request.\n\n\nShow properties\nOBJECT The chat completion chunk object\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-4o-mini\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"}", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 66900, "end_char": 67500}, "135": {"text": "ystem_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"logprobs\":null,\"finish_reason\":null}]}\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-4o-mini\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{\"content\":\"Hello\"},\"logprobs\":null,\"finish_reason\":null}]}\n\n....\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-4o-mini\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{},\"logprobs\":null,\"finish_reason\":\"stop\"}]}\nRealtime\nBet", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 67400, "end_char": 68000}, "136": {"text": "44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{},\"logprobs\":null,\"finish_reason\":\"stop\"}]}\nRealtime\nBeta\nCommunicate with a GPT-4o class model in real time using WebRTC or WebSockets. Supports text and audio inputs and ouputs, along with audio transcriptions. Learn more about the Realtime API.\n\nSession tokens\nREST API endpoint to generate ephemeral session tokens for use in client-side applications.\n\nCreate session\npost\n \nhttps://api.openai.com/v1/realtime/sessions\nCreate an ephemeral API token for use in client-side applications with the Realtime API. Can be configured with the same session para", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 67900, "end_char": 68500}, "137": {"text": " use in client-side applications with the Realtime API. Can be configured with the same session parameters as the session.update client event.\n\nIt responds with a session object, plus a client_secret key which contains a usable ephemeral API token that can be used to authenticate browser clients for the Realtime API.\n\nRequest body\ninput_audio_format\nstring\n\nOptional\nDefaults to pcm16\nThe format of input audio. Options are pcm16, g711_ulaw, or g711_alaw. For pcm16, input audio must be 16-bit PCM at a 24kHz sample rate, single channel (mono), and little-endian byte order.\n\ninput_audio_noise_redu", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 68400, "end_char": 69000}, "138": {"text": "at a 24kHz sample rate, single channel (mono), and little-endian byte order.\n\ninput_audio_noise_reduction\nobject\n\nOptional\nDefaults to null\nConfiguration for input audio noise reduction. This can be set to null to turn off. Noise reduction filters audio added to the input audio buffer before it is sent to VAD and the model. Filtering the audio can improve VAD and turn detection accuracy (reducing false positives) and model performance by improving perception of the input audio.\n\n\nShow properties\ninput_audio_transcription\nobject\n\nOptional\nConfiguration for input audio transcription, defaults to", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 68900, "end_char": 69500}, "139": {"text": "\ninput_audio_transcription\nobject\n\nOptional\nConfiguration for input audio transcription, defaults to off and can be set to null to turn off once on. Input audio transcription is not native to the model, since the model consumes audio directly. Transcription runs asynchronously through the /audio/transcriptions endpoint and should be treated as guidance of input audio content rather than precisely what the model heard. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service.\n\n\nShow properties\ninstructions\nstring\n\nOpti", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 69400, "end_char": 70000}, "140": {"text": " offer additional guidance to the transcription service.\n\n\nShow properties\ninstructions\nstring\n\nOptional\nThe default system instructions (i.e. system message) prepended to model calls. This field allows the client to guide the model on desired responses. The model can be instructed on response content and format, (e.g. \"be extremely succinct\", \"act friendly\", \"here are examples of good responses\") and on audio behavior (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The instructions are not guaranteed to be followed by the model, but they provide guidance to the mo", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 69900, "end_char": 70500}, "141": {"text": "The instructions are not guaranteed to be followed by the model, but they provide guidance to the model on the desired behavior.\n\nNote that the server sets default instructions which will be used if this field is not set and are visible in the session.created event at the start of the session.\n\nmax_response_output_tokens\ninteger or \"inf\"\n\nOptional\nMaximum number of output tokens for a single assistant response, inclusive of tool calls. Provide an integer between 1 and 4096 to limit output tokens, or inf for the maximum available tokens for a given model. Defaults to inf.\n\nmodalities\nOptional\nT", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 70400, "end_char": 71000}, "142": {"text": ", or inf for the maximum available tokens for a given model. Defaults to inf.\n\nmodalities\nOptional\nThe set of modalities the model can respond with. To disable audio, set this to [\"text\"].\n\nmodel\nstring\n\nOptional\nThe Realtime model used for this session.\n\noutput_audio_format\nstring\n\nOptional\nDefaults to pcm16\nThe format of output audio. Options are pcm16, g711_ulaw, or g711_alaw. For pcm16, output audio is sampled at a rate of 24kHz.\n\ntemperature\nnumber\n\nOptional\nDefaults to 0.8\nSampling temperature for the model, limited to [0.6, 1.2]. For audio models a temperature of 0.8 is highly recommend", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 70900, "end_char": 71500}, "143": {"text": "ture for the model, limited to [0.6, 1.2]. For audio models a temperature of 0.8 is highly recommended for best performance.\n\ntool_choice\nstring\n\nOptional\nDefaults to auto\nHow the model chooses tools. Options are auto, none, required, or specify a function.\n\ntools\narray\n\nOptional\nTools (functions) available to the model.\n\n\nShow properties\nturn_detection\nobject\n\nOptional\nConfiguration for turn detection, ether Server VAD or Semantic VAD. This can be set to null to turn off, in which case the client must manually trigger model response. Server VAD means that the model will detect the start and e", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 71400, "end_char": 72000}, "144": {"text": "nt must manually trigger model response. Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech. Semantic VAD is more advanced and uses a turn detection model (in conjuction with VAD) to semantically estimate whether the user has finished speaking, then dynamically sets a timeout based on this probability. For example, if user audio trails off with \"uhhm\", the model will score a low probability of turn end and wait longer for the user to continue speaking. This can be useful for more natural conversations, but may hav", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 71900, "end_char": 72500}, "145": {"text": "er for the user to continue speaking. This can be useful for more natural conversations, but may have a higher latency.\n\n\nShow properties\nvoice\nstring\n\nOptional\nThe voice the model uses to respond. Voice cannot be changed during the session once the model has responded with audio at least once. Current voice options are alloy, ash, ballad, coral, echo, fable, onyx, nova, sage, shimmer, and verse.\n\nReturns\nThe created Realtime session object, plus an ephemeral key\n\nExample request\ncurl -X POST https://api.openai.com/v1/realtime/sessions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Con", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 72400, "end_char": 73000}, "146": {"text": "tps://api.openai.com/v1/realtime/sessions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"gpt-4o-realtime-preview\",\n    \"modalities\": [\"audio\", \"text\"],\n    \"instructions\": \"You are a friendly assistant.\"\n  }'\nResponse\n{\n  \"id\": \"sess_001\",\n  \"object\": \"realtime.session\",\n  \"model\": \"gpt-4o-realtime-preview\",\n  \"modalities\": [\"audio\", \"text\"],\n  \"instructions\": \"You are a friendly assistant.\",\n  \"voice\": \"alloy\",\n  \"input_audio_format\": \"pcm16\",\n  \"output_audio_format\": \"pcm16\",\n  \"input_audio_transcription\": {\n      \"model\": \"whis", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 72900, "end_char": 73500}, "147": {"text": "t\": \"pcm16\",\n  \"output_audio_format\": \"pcm16\",\n  \"input_audio_transcription\": {\n      \"model\": \"whisper-1\"\n  },\n  \"turn_detection\": null,\n  \"tools\": [],\n  \"tool_choice\": \"none\",\n  \"temperature\": 0.7,\n  \"max_response_output_tokens\": 200,\n  \"client_secret\": {\n    \"value\": \"ek_abc123\", \n    \"expires_at\": 1234567890\n  }\n}\nCreate transcription session\npost\n \nhttps://api.openai.com/v1/realtime/transcription_sessions\nCreate an ephemeral API token for use in client-side applications with the Realtime API specifically for realtime transcriptions. Can be configured with the same session parameters as th", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 73400, "end_char": 74000}, "148": {"text": "I specifically for realtime transcriptions. Can be configured with the same session parameters as the transcription_session.update client event.\n\nIt responds with a session object, plus a client_secret key which contains a usable ephemeral API token that can be used to authenticate browser clients for the Realtime API.\n\nRequest body\ninclude\narray\n\nOptional\nThe set of items to include in the transcription. Current available items are:\n\nnull.\n\ninput_audio_format\nstring\n\nOptional\nDefaults to pcm16\nThe format of input audio. Options are pcm16, g711_ulaw, or g711_alaw. For pcm16, input audio must b", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 73900, "end_char": 74500}, "149": {"text": "The format of input audio. Options are pcm16, g711_ulaw, or g711_alaw. For pcm16, input audio must be 16-bit PCM at a 24kHz sample rate, single channel (mono), and little-endian byte order.\n\ninput_audio_noise_reduction\nobject\n\nOptional\nDefaults to null\nConfiguration for input audio noise reduction. This can be set to null to turn off. Noise reduction filters audio added to the input audio buffer before it is sent to VAD and the model. Filtering the audio can improve VAD and turn detection accuracy (reducing false positives) and model performance by improving perception of the input audio.\n\n\nSh", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 74400, "end_char": 75000}, "150": {"text": "cy (reducing false positives) and model performance by improving perception of the input audio.\n\n\nShow properties\ninput_audio_transcription\nobject\n\nOptional\nConfiguration for input audio transcription. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service.\n\n\nShow properties\nmodalities\nOptional\nThe set of modalities the model can respond with. To disable audio, set this to [\"text\"].\n\nturn_detection\nobject\n\nOptional\nConfiguration for turn detection, ether Server VAD or Semantic VAD. This can be set to null to turn of", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 74900, "end_char": 75500}, "151": {"text": "nfiguration for turn detection, ether Server VAD or Semantic VAD. This can be set to null to turn off, in which case the client must manually trigger model response. Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech. Semantic VAD is more advanced and uses a turn detection model (in conjuction with VAD) to semantically estimate whether the user has finished speaking, then dynamically sets a timeout based on this probability. For example, if user audio trails off with \"uhhm\", the model will score a low probability ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 75400, "end_char": 76000}, "152": {"text": "bability. For example, if user audio trails off with \"uhhm\", the model will score a low probability of turn end and wait longer for the user to continue speaking. This can be useful for more natural conversations, but may have a higher latency.\n\n\nShow properties\nReturns\nThe created Realtime transcription session object, plus an ephemeral key\n\nExample request\ncurl -X POST https://api.openai.com/v1/realtime/transcription_sessions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{}'\nResponse\n{\n  \"id\": \"sess_BBwZc7cFV3XizEyKGDCGL\",\n  \"object\": \"realtim", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 75900, "end_char": 76500}, "153": {"text": " application/json\" \\\n  -d '{}'\nResponse\n{\n  \"id\": \"sess_BBwZc7cFV3XizEyKGDCGL\",\n  \"object\": \"realtime.transcription_session\",\n  \"modalities\": [\"audio\", \"text\"],\n  \"turn_detection\": {\n    \"type\": \"server_vad\",\n    \"threshold\": 0.5,\n    \"prefix_padding_ms\": 300,\n    \"silence_duration_ms\": 200\n  },\n  \"input_audio_format\": \"pcm16\",\n  \"input_audio_transcription\": {\n    \"model\": \"gpt-4o-transcribe\",\n    \"language\": null,\n    \"prompt\": \"\"\n  },\n  \"client_secret\": null\n}\nThe session object\nA new Realtime session configuration, with an ephermeral key. Default TTL for keys is one minute.\n\nclient_secret\no", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 76400, "end_char": 77000}, "154": {"text": " session configuration, with an ephermeral key. Default TTL for keys is one minute.\n\nclient_secret\nobject\n\nEphemeral key returned by the API.\n\n\nShow properties\ninput_audio_format\nstring\n\nThe format of input audio. Options are pcm16, g711_ulaw, or g711_alaw.\n\ninput_audio_transcription\nobject\n\nConfiguration for input audio transcription, defaults to off and can be set to null to turn off once on. Input audio transcription is not native to the model, since the model consumes audio directly. Transcription runs asynchronously through Whisper and should be treated as rough guidance rather than the r", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 76900, "end_char": 77500}, "155": {"text": "iption runs asynchronously through Whisper and should be treated as rough guidance rather than the representation understood by the model.\n\n\nShow properties\ninstructions\nstring\n\nThe default system instructions (i.e. system message) prepended to model calls. This field allows the client to guide the model on desired responses. The model can be instructed on response content and format, (e.g. \"be extremely succinct\", \"act friendly\", \"here are examples of good responses\") and on audio behavior (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The instructions are not gu", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 77400, "end_char": 78000}, "156": {"text": ". \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The instructions are not guaranteed to be followed by the model, but they provide guidance to the model on the desired behavior.\n\nNote that the server sets default instructions which will be used if this field is not set and are visible in the session.created event at the start of the session.\n\nmax_response_output_tokens\ninteger or \"inf\"\n\nMaximum number of output tokens for a single assistant response, inclusive of tool calls. Provide an integer between 1 and 4096 to limit output tokens, or inf for the maximum available t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 77900, "end_char": 78500}, "157": {"text": "ls. Provide an integer between 1 and 4096 to limit output tokens, or inf for the maximum available tokens for a given model. Defaults to inf.\n\nmodalities\nThe set of modalities the model can respond with. To disable audio, set this to [\"text\"].\n\noutput_audio_format\nstring\n\nThe format of output audio. Options are pcm16, g711_ulaw, or g711_alaw.\n\ntemperature\nnumber\n\nSampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n\ntool_choice\nstring\n\nHow the model chooses tools. Options are auto, none, required, or specify a function.\n\ntools\narray\n\nTools (functions) available to the mo", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 78400, "end_char": 79000}, "158": {"text": "are auto, none, required, or specify a function.\n\ntools\narray\n\nTools (functions) available to the model.\n\n\nShow properties\nturn_detection\nobject\n\nConfiguration for turn detection. Can be set to null to turn off. Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.\n\n\nShow properties\nvoice\nstring\n\nThe voice the model uses to respond. Voice cannot be changed during the session once the model has responded with audio at least once. Current voice options are alloy, ash, ballad, coral, echo sage, shimmer and verse.\n\nOBJE", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 78900, "end_char": 79500}, "159": {"text": "least once. Current voice options are alloy, ash, ballad, coral, echo sage, shimmer and verse.\n\nOBJECT The session object\n{\n  \"id\": \"sess_001\",\n  \"object\": \"realtime.session\",\n  \"model\": \"gpt-4o-realtime-preview\",\n  \"modalities\": [\"audio\", \"text\"],\n  \"instructions\": \"You are a friendly assistant.\",\n  \"voice\": \"alloy\",\n  \"input_audio_format\": \"pcm16\",\n  \"output_audio_format\": \"pcm16\",\n  \"input_audio_transcription\": {\n      \"model\": \"whisper-1\"\n  },\n  \"turn_detection\": null,\n  \"tools\": [],\n  \"tool_choice\": \"none\",\n  \"temperature\": 0.7,\n  \"max_response_output_tokens\": 200,\n  \"client_secret\": {\n  ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 79400, "end_char": 80000}, "160": {"text": "_choice\": \"none\",\n  \"temperature\": 0.7,\n  \"max_response_output_tokens\": 200,\n  \"client_secret\": {\n    \"value\": \"ek_abc123\", \n    \"expires_at\": 1234567890\n  }\n}\nThe transcription session object\nA new Realtime transcription session configuration.\n\nWhen a session is created on the server via REST API, the session object also contains an ephemeral key. Default TTL for keys is one minute. This property is not present when a session is updated via the WebSocket API.\n\nclient_secret\nobject\n\nEphemeral key returned by the API. Only present when the session is created on the server via REST API.\n\n\nShow p", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 79900, "end_char": 80500}, "161": {"text": "y returned by the API. Only present when the session is created on the server via REST API.\n\n\nShow properties\ninput_audio_format\nstring\n\nThe format of input audio. Options are pcm16, g711_ulaw, or g711_alaw.\n\ninput_audio_transcription\nobject\n\nConfiguration of the transcription model.\n\n\nShow properties\nmodalities\nThe set of modalities the model can respond with. To disable audio, set this to [\"text\"].\n\nturn_detection\nobject\n\nConfiguration for turn detection. Can be set to null to turn off. Server VAD means that the model will detect the start and end of speech based on audio volume and respond ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 80400, "end_char": 81000}, "162": {"text": " VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.\n\n\nShow properties\nOBJECT The transcription session object\n{\n  \"id\": \"sess_BBwZc7cFV3XizEyKGDCGL\",\n  \"object\": \"realtime.transcription_session\",\n  \"expires_at\": 1742188264,\n  \"modalities\": [\"audio\", \"text\"],\n  \"turn_detection\": {\n    \"type\": \"server_vad\",\n    \"threshold\": 0.5,\n    \"prefix_padding_ms\": 300,\n    \"silence_duration_ms\": 200\n  },\n  \"input_audio_format\": \"pcm16\",\n  \"input_audio_transcription\": {\n    \"model\": \"gpt-4o-transcribe\",\n    \"language\": null,\n    \"pro", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 80900, "end_char": 81500}, "163": {"text": "\",\n  \"input_audio_transcription\": {\n    \"model\": \"gpt-4o-transcribe\",\n    \"language\": null,\n    \"prompt\": \"\"\n  },\n  \"client_secret\": null\n}\nClient events\nThese are events that the OpenAI Realtime WebSocket server will accept from the client.\n\nsession.update\nSend this event to update the session\u2019s default configuration. The client may send this event at any time to update any field, except for voice. However, note that once a session has been initialized with a particular model, it can\u2019t be changed to another model using session.update.\n\nWhen the server receives a session.update, it will respon", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 81400, "end_char": 82000}, "164": {"text": "ed to another model using session.update.\n\nWhen the server receives a session.update, it will respond with a session.updated event showing the full, effective configuration. Only the fields that are present are updated. To clear a field like instructions, pass an empty string.\n\nevent_id\nstring\n\nOptional client-generated ID used to identify this event.\n\nsession\nobject\n\nRealtime session object configuration.\n\n\nShow properties\ntype\nstring\n\nThe event type, must be session.update.\n\nOBJECT session.update\n{\n    \"event_id\": \"event_123\",\n    \"type\": \"session.update\",\n    \"session\": {\n        \"modalitie", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 81900, "end_char": 82500}, "165": {"text": "ate\n{\n    \"event_id\": \"event_123\",\n    \"type\": \"session.update\",\n    \"session\": {\n        \"modalities\": [\"text\", \"audio\"],\n        \"instructions\": \"You are a helpful assistant.\",\n        \"voice\": \"sage\",\n        \"input_audio_format\": \"pcm16\",\n        \"output_audio_format\": \"pcm16\",\n        \"input_audio_transcription\": {\n            \"model\": \"whisper-1\"\n        },\n        \"turn_detection\": {\n            \"type\": \"server_vad\",\n            \"threshold\": 0.5,\n            \"prefix_padding_ms\": 300,\n            \"silence_duration_ms\": 500,\n            \"create_response\": true\n        },\n        \"tools\": ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 82400, "end_char": 83000}, "166": {"text": "        \"silence_duration_ms\": 500,\n            \"create_response\": true\n        },\n        \"tools\": [\n            {\n                \"type\": \"function\",\n                \"name\": \"get_weather\",\n                \"description\": \"Get the current weather...\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"location\": { \"type\": \"string\" }\n                    },\n                    \"required\": [\"location\"]\n                }\n            }\n        ],\n        \"tool_choice\": \"auto\",\n        \"temperature\": 0.8,\n        \"max_re", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 82900, "end_char": 83500}, "167": {"text": "\n            }\n        ],\n        \"tool_choice\": \"auto\",\n        \"temperature\": 0.8,\n        \"max_response_output_tokens\": \"inf\"\n    }\n}\ninput_audio_buffer.append\nSend this event to append audio bytes to the input audio buffer. The audio buffer is temporary storage you can write to and later commit. In Server VAD mode, the audio buffer is used to detect speech and the server will decide when to commit. When Server VAD is disabled, you must commit the audio buffer manually.\n\nThe client may choose how much audio to place in each event up to a maximum of 15 MiB, for example streaming smaller chun", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 83400, "end_char": 84000}, "168": {"text": " how much audio to place in each event up to a maximum of 15 MiB, for example streaming smaller chunks from the client may allow the VAD to be more responsive. Unlike made other client events, the server will not send a confirmation response to this event.\n\naudio\nstring\n\nBase64-encoded audio bytes. This must be in the format specified by the input_audio_format field in the session configuration.\n\nevent_id\nstring\n\nOptional client-generated ID used to identify this event.\n\ntype\nstring\n\nThe event type, must be input_audio_buffer.append.\n\nOBJECT input_audio_buffer.append\n{\n    \"event_id\": \"event_4", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 83900, "end_char": 84500}, "169": {"text": "ype, must be input_audio_buffer.append.\n\nOBJECT input_audio_buffer.append\n{\n    \"event_id\": \"event_456\",\n    \"type\": \"input_audio_buffer.append\",\n    \"audio\": \"Base64EncodedAudioData\"\n}\ninput_audio_buffer.commit\nSend this event to commit the user input audio buffer, which will create a new user message item in the conversation. This event will produce an error if the input audio buffer is empty. When in Server VAD mode, the client does not need to send this event, the server will commit the audio buffer automatically.\n\nCommitting the input audio buffer will trigger input audio transcription (i", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 84400, "end_char": 85000}, "170": {"text": "o buffer automatically.\n\nCommitting the input audio buffer will trigger input audio transcription (if enabled in session configuration), but it will not create a response from the model. The server will respond with an input_audio_buffer.committed event.\n\nevent_id\nstring\n\nOptional client-generated ID used to identify this event.\n\ntype\nstring\n\nThe event type, must be input_audio_buffer.commit.\n\nOBJECT input_audio_buffer.commit\n{\n    \"event_id\": \"event_789\",\n    \"type\": \"input_audio_buffer.commit\"\n}\ninput_audio_buffer.clear\nSend this event to clear the audio bytes in the buffer. The server will ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 84900, "end_char": 85500}, "171": {"text": "\n}\ninput_audio_buffer.clear\nSend this event to clear the audio bytes in the buffer. The server will respond with an input_audio_buffer.cleared event.\n\nevent_id\nstring\n\nOptional client-generated ID used to identify this event.\n\ntype\nstring\n\nThe event type, must be input_audio_buffer.clear.\n\nOBJECT input_audio_buffer.clear\n{\n    \"event_id\": \"event_012\",\n    \"type\": \"input_audio_buffer.clear\"\n}\nconversation.item.create\nAdd a new Item to the Conversation's context, including messages, function calls, and function call responses. This event can be used both to populate a \"history\" of the conversati", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 85400, "end_char": 86000}, "172": {"text": ", and function call responses. This event can be used both to populate a \"history\" of the conversation and to add new items mid-stream, but has the current limitation that it cannot populate assistant audio messages.\n\nIf successful, the server will respond with a conversation.item.created event, otherwise an error event will be sent.\n\nevent_id\nstring\n\nOptional client-generated ID used to identify this event.\n\nitem\nobject\n\nThe item to add to the conversation.\n\n\nShow properties\nprevious_item_id\nstring\n\nThe ID of the preceding item after which the new item will be inserted. If not set, the new it", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 85900, "end_char": 86500}, "173": {"text": "ring\n\nThe ID of the preceding item after which the new item will be inserted. If not set, the new item will be appended to the end of the conversation. If set to root, the new item will be added to the beginning of the conversation. If set to an existing ID, it allows an item to be inserted mid-conversation. If the ID cannot be found, an error will be returned and the item will not be added.\n\ntype\nstring\n\nThe event type, must be conversation.item.create.\n\nOBJECT conversation.item.create\n{\n    \"event_id\": \"event_345\",\n    \"type\": \"conversation.item.create\",\n    \"previous_item_id\": null,\n    \"it", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 86400, "end_char": 87000}, "174": {"text": "vent_id\": \"event_345\",\n    \"type\": \"conversation.item.create\",\n    \"previous_item_id\": null,\n    \"item\": {\n        \"id\": \"msg_001\",\n        \"type\": \"message\",\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"input_text\",\n                \"text\": \"Hello, how are you?\"\n            }\n        ]\n    }\n}\nconversation.item.retrieve\nSend this event when you want to retrieve the server's representation of a specific item in the conversation history. This is useful, for example, to inspect user audio after noise cancellation and VAD. The server will respond with a conve", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 86900, "end_char": 87500}, "175": {"text": "xample, to inspect user audio after noise cancellation and VAD. The server will respond with a conversation.item.retrieved event, unless the item does not exist in the conversation history, in which case the server will respond with an error.\n\nevent_id\nstring\n\nOptional client-generated ID used to identify this event.\n\nitem_id\nstring\n\nThe ID of the item to retrieve.\n\ntype\nstring\n\nThe event type, must be conversation.item.retrieve.\n\nOBJECT conversation.item.retrieve\n{\n    \"event_id\": \"event_901\",\n    \"type\": \"conversation.item.retrieve\",\n    \"item_id\": \"msg_003\"\n}\nconversation.item.truncate\nSend", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 87400, "end_char": 88000}, "176": {"text": "    \"type\": \"conversation.item.retrieve\",\n    \"item_id\": \"msg_003\"\n}\nconversation.item.truncate\nSend this event to truncate a previous assistant message\u2019s audio. The server will produce audio faster than realtime, so this event is useful when the user interrupts to truncate audio that has already been sent to the client but not yet played. This will synchronize the server's understanding of the audio with the client's playback.\n\nTruncating audio will delete the server-side text transcript to ensure there is not text in the context that hasn't been heard by the user.\n\nIf successful, the server ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 87900, "end_char": 88500}, "177": {"text": "ure there is not text in the context that hasn't been heard by the user.\n\nIf successful, the server will respond with a conversation.item.truncated event.\n\naudio_end_ms\ninteger\n\nInclusive duration up to which audio is truncated, in milliseconds. If the audio_end_ms is greater than the actual audio duration, the server will respond with an error.\n\ncontent_index\ninteger\n\nThe index of the content part to truncate. Set this to 0.\n\nevent_id\nstring\n\nOptional client-generated ID used to identify this event.\n\nitem_id\nstring\n\nThe ID of the assistant message item to truncate. Only assistant message item", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 88400, "end_char": 89000}, "178": {"text": "vent.\n\nitem_id\nstring\n\nThe ID of the assistant message item to truncate. Only assistant message items can be truncated.\n\ntype\nstring\n\nThe event type, must be conversation.item.truncate.\n\nOBJECT conversation.item.truncate\n{\n    \"event_id\": \"event_678\",\n    \"type\": \"conversation.item.truncate\",\n    \"item_id\": \"msg_002\",\n    \"content_index\": 0,\n    \"audio_end_ms\": 1500\n}\nconversation.item.delete\nSend this event when you want to remove any item from the conversation history. The server will respond with a conversation.item.deleted event, unless the item does not exist in the conversation history, ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 88900, "end_char": 89500}, "179": {"text": "with a conversation.item.deleted event, unless the item does not exist in the conversation history, in which case the server will respond with an error.\n\nevent_id\nstring\n\nOptional client-generated ID used to identify this event.\n\nitem_id\nstring\n\nThe ID of the item to delete.\n\ntype\nstring\n\nThe event type, must be conversation.item.delete.\n\nOBJECT conversation.item.delete\n{\n    \"event_id\": \"event_901\",\n    \"type\": \"conversation.item.delete\",\n    \"item_id\": \"msg_003\"\n}\nresponse.create\nThis event instructs the server to create a Response, which means triggering model inference. When in Server VAD ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 89400, "end_char": 90000}, "180": {"text": "structs the server to create a Response, which means triggering model inference. When in Server VAD mode, the server will create Responses automatically.\n\nA Response will include at least one Item, and may have two, in which case the second will be a function call. These Items will be appended to the conversation history.\n\nThe server will respond with a response.created event, events for Items and content created, and finally a response.done event to indicate the Response is complete.\n\nThe response.create event includes inference configuration like instructions, and temperature. These fields w", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 89900, "end_char": 90500}, "181": {"text": "nse.create event includes inference configuration like instructions, and temperature. These fields will override the Session's configuration for this Response only.\n\nevent_id\nstring\n\nOptional client-generated ID used to identify this event.\n\nresponse\nobject\n\nCreate a new Realtime response with these parameters\n\n\nShow properties\ntype\nstring\n\nThe event type, must be response.create.\n\nOBJECT response.create\n{\n    \"event_id\": \"event_234\",\n    \"type\": \"response.create\",\n    \"response\": {\n        \"modalities\": [\"text\", \"audio\"],\n        \"instructions\": \"Please assist the user.\",\n        \"voice\": \"sa", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 90400, "end_char": 91000}, "182": {"text": "alities\": [\"text\", \"audio\"],\n        \"instructions\": \"Please assist the user.\",\n        \"voice\": \"sage\",\n        \"output_audio_format\": \"pcm16\",\n        \"tools\": [\n            {\n                \"type\": \"function\",\n                \"name\": \"calculate_sum\",\n                \"description\": \"Calculates the sum of two numbers.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"a\": { \"type\": \"number\" },\n                        \"b\": { \"type\": \"number\" }\n                    },\n                    \"required\": [\"a\", \"b\"]\n   ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 90900, "end_char": 91500}, "183": {"text": "     \"b\": { \"type\": \"number\" }\n                    },\n                    \"required\": [\"a\", \"b\"]\n                }\n            }\n        ],\n        \"tool_choice\": \"auto\",\n        \"temperature\": 0.8,\n        \"max_output_tokens\": 1024\n    }\n}\nresponse.cancel\nSend this event to cancel an in-progress response. The server will respond with a response.cancelled event or an error if there is no response to cancel.\n\nevent_id\nstring\n\nOptional client-generated ID used to identify this event.\n\nresponse_id\nstring\n\nA specific response ID to cancel - if not provided, will cancel an in-progress response in t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 91400, "end_char": 92000}, "184": {"text": "string\n\nA specific response ID to cancel - if not provided, will cancel an in-progress response in the default conversation.\n\ntype\nstring\n\nThe event type, must be response.cancel.\n\nOBJECT response.cancel\n{\n    \"event_id\": \"event_567\",\n    \"type\": \"response.cancel\"\n}\ntranscription_session.update\nSend this event to update a transcription session.\n\nevent_id\nstring\n\nOptional client-generated ID used to identify this event.\n\nsession\nobject\n\nRealtime transcription session object configuration.\n\n\nShow properties\ntype\nstring\n\nThe event type, must be transcription_session.update.\n\nOBJECT transcription_", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 91900, "end_char": 92500}, "185": {"text": "properties\ntype\nstring\n\nThe event type, must be transcription_session.update.\n\nOBJECT transcription_session.update\n{\n  \"type\": \"transcription_session.update\",\n  \"session\": {\n    \"input_audio_format\": \"pcm16\",\n    \"input_audio_transcription\": {\n      \"model\": \"gpt-4o-transcribe\",\n      \"prompt\": \"\",\n      \"language\": \"\"\n    },\n    \"turn_detection\": {\n      \"type\": \"server_vad\",\n      \"threshold\": 0.5,\n      \"prefix_padding_ms\": 300,\n      \"silence_duration_ms\": 500,\n      \"create_response\": true,\n    },\n    \"input_audio_noise_reduction\": {\n      \"type\": \"near_field\"\n    },\n    \"include\": [\n    ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 92400, "end_char": 93000}, "186": {"text": "\n    },\n    \"input_audio_noise_reduction\": {\n      \"type\": \"near_field\"\n    },\n    \"include\": [\n      \"item.input_audio_transcription.logprobs\",\n    ]\n  }\n}\nServer events\nThese are events emitted from the OpenAI Realtime WebSocket server to the client.\n\nerror\nReturned when an error occurs, which could be a client problem or a server problem. Most errors are recoverable and the session will stay open, we recommend to implementors to monitor and log error messages by default.\n\nerror\nobject\n\nDetails of the error.\n\n\nShow properties\nevent_id\nstring\n\nThe unique ID of the server event.\n\ntype\nstring\n\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 92900, "end_char": 93500}, "187": {"text": "s of the error.\n\n\nShow properties\nevent_id\nstring\n\nThe unique ID of the server event.\n\ntype\nstring\n\nThe event type, must be error.\n\nOBJECT error\n{\n    \"event_id\": \"event_890\",\n    \"type\": \"error\",\n    \"error\": {\n        \"type\": \"invalid_request_error\",\n        \"code\": \"invalid_event\",\n        \"message\": \"The 'type' field is missing.\",\n        \"param\": null,\n        \"event_id\": \"event_567\"\n    }\n}\nsession.created\nReturned when a Session is created. Emitted automatically when a new connection is established as the first server event. This event will contain the default Session configuration.\n\nev", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 93400, "end_char": 94000}, "188": {"text": "stablished as the first server event. This event will contain the default Session configuration.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nsession\nobject\n\nRealtime session object configuration.\n\n\nShow properties\ntype\nstring\n\nThe event type, must be session.created.\n\nOBJECT session.created\n{\n    \"event_id\": \"event_1234\",\n    \"type\": \"session.created\",\n    \"session\": {\n        \"id\": \"sess_001\",\n        \"object\": \"realtime.session\",\n        \"model\": \"gpt-4o-realtime-preview\",\n        \"modalities\": [\"text\", \"audio\"],\n        \"instructions\": \"...model instructions here...\",\n        \"voi", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 93900, "end_char": 94500}, "189": {"text": "odalities\": [\"text\", \"audio\"],\n        \"instructions\": \"...model instructions here...\",\n        \"voice\": \"sage\",\n        \"input_audio_format\": \"pcm16\",\n        \"output_audio_format\": \"pcm16\",\n        \"input_audio_transcription\": null,\n        \"turn_detection\": {\n            \"type\": \"server_vad\",\n            \"threshold\": 0.5,\n            \"prefix_padding_ms\": 300,\n            \"silence_duration_ms\": 200\n        },\n        \"tools\": [],\n        \"tool_choice\": \"auto\",\n        \"temperature\": 0.8,\n        \"max_response_output_tokens\": \"inf\"\n    }\n}\nsession.updated\nReturned when a session is updated wi", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 94400, "end_char": 95000}, "190": {"text": "   \"max_response_output_tokens\": \"inf\"\n    }\n}\nsession.updated\nReturned when a session is updated with a session.update event, unless there is an error.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nsession\nobject\n\nRealtime session object configuration.\n\n\nShow properties\ntype\nstring\n\nThe event type, must be session.updated.\n\nOBJECT session.updated\n{\n    \"event_id\": \"event_5678\",\n    \"type\": \"session.updated\",\n    \"session\": {\n        \"id\": \"sess_001\",\n        \"object\": \"realtime.session\",\n        \"model\": \"gpt-4o-realtime-preview\",\n        \"modalities\": [\"text\"],\n        \"instructions\"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 94900, "end_char": 95500}, "191": {"text": ",\n        \"model\": \"gpt-4o-realtime-preview\",\n        \"modalities\": [\"text\"],\n        \"instructions\": \"New instructions\",\n        \"voice\": \"sage\",\n        \"input_audio_format\": \"pcm16\",\n        \"output_audio_format\": \"pcm16\",\n        \"input_audio_transcription\": {\n            \"model\": \"whisper-1\"\n        },\n        \"turn_detection\": null,\n        \"tools\": [],\n        \"tool_choice\": \"none\",\n        \"temperature\": 0.7,\n        \"max_response_output_tokens\": 200\n    }\n}\nconversation.created\nReturned when a conversation is created. Emitted right after session creation.\n\nconversation\nobject\n\nThe con", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 95400, "end_char": 96000}, "192": {"text": " when a conversation is created. Emitted right after session creation.\n\nconversation\nobject\n\nThe conversation resource.\n\n\nShow properties\nevent_id\nstring\n\nThe unique ID of the server event.\n\ntype\nstring\n\nThe event type, must be conversation.created.\n\nOBJECT conversation.created\n{\n    \"event_id\": \"event_9101\",\n    \"type\": \"conversation.created\",\n    \"conversation\": {\n        \"id\": \"conv_001\",\n        \"object\": \"realtime.conversation\"\n    }\n}\nconversation.item.created\nReturned when a conversation item is created. There are several scenarios that produce this event:\n\nThe server is generating a Re", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 95900, "end_char": 96500}, "193": {"text": "item is created. There are several scenarios that produce this event:\n\nThe server is generating a Response, which if successful will produce either one or two Items, which will be of type message (role assistant) or type function_call.\nThe input audio buffer has been committed, either by the client or the server (in server_vad mode). The server will take the content of the input audio buffer and add it to a new user message Item.\nThe client has sent a conversation.item.create event to add a new Item to the Conversation.\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem\nobject\n\nThe item", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 96400, "end_char": 97000}, "194": {"text": "Item to the Conversation.\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem\nobject\n\nThe item to add to the conversation.\n\n\nShow properties\nprevious_item_id\nstring\n\nThe ID of the preceding item in the Conversation context, allows the client to understand the order of the conversation.\n\ntype\nstring\n\nThe event type, must be conversation.item.created.\n\nOBJECT conversation.item.created\n{\n    \"event_id\": \"event_1920\",\n    \"type\": \"conversation.item.created\",\n    \"previous_item_id\": \"msg_002\",\n    \"item\": {\n        \"id\": \"msg_003\",\n        \"object\": \"realtime.item\",\n        \"type\": \"message\",", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 96900, "end_char": 97500}, "195": {"text": "    \"item\": {\n        \"id\": \"msg_003\",\n        \"object\": \"realtime.item\",\n        \"type\": \"message\",\n        \"status\": \"completed\",\n        \"role\": \"user\",\n        \"content\": []\n    }\n}\nconversation.item.retrieved\nReturned when a conversation item is retrieved with conversation.item.retrieve.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem\nobject\n\nThe item to add to the conversation.\n\n\nShow properties\ntype\nstring\n\nThe event type, must be conversation.item.retrieved.\n\nOBJECT conversation.item.retrieved\n{\n    \"event_id\": \"event_1920\",\n    \"type\": \"conversation.item.created\",\n    \"prev", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 97400, "end_char": 98000}, "196": {"text": "on.item.retrieved\n{\n    \"event_id\": \"event_1920\",\n    \"type\": \"conversation.item.created\",\n    \"previous_item_id\": \"msg_002\",\n    \"item\": {\n        \"id\": \"msg_003\",\n        \"object\": \"realtime.item\",\n        \"type\": \"message\",\n        \"status\": \"completed\",\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"input_audio\",\n                \"transcript\": \"hello how are you\",\n                \"audio\": \"base64encodedaudio==\"\n            }\n        ]\n    }\n}\nconversation.item.input_audio_transcription.completed\nThis event is the output of audio transcription for user au", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 97900, "end_char": 98500}, "197": {"text": "item.input_audio_transcription.completed\nThis event is the output of audio transcription for user audio written to the user audio buffer. Transcription begins when the input audio buffer is committed by the client or server (in server_vad mode). Transcription runs asynchronously with Response creation, so this event may come before or after the Response events.\n\nRealtime API models accept audio natively, and thus input transcription is a separate process run on a separate ASR (Automatic Speech Recognition) model, currently always whisper-1. Thus the transcript may diverge somewhat from the mod", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 98400, "end_char": 99000}, "198": {"text": "ecognition) model, currently always whisper-1. Thus the transcript may diverge somewhat from the model's interpretation, and should be treated as a rough guide.\n\ncontent_index\ninteger\n\nThe index of the content part containing the audio.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the user message item containing the audio.\n\nlogprobs\narray or null\n\nThe log probabilities of the transcription.\n\n\nShow properties\ntranscript\nstring\n\nThe transcribed text.\n\ntype\nstring\n\nThe event type, must be conversation.item.input_audio_transcription.completed.\n\nOBJECT conversati", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 98900, "end_char": 99500}, "199": {"text": "g\n\nThe event type, must be conversation.item.input_audio_transcription.completed.\n\nOBJECT conversation.item.input_audio_transcription.completed\n{\n    \"event_id\": \"event_2122\",\n    \"type\": \"conversation.item.input_audio_transcription.completed\",\n    \"item_id\": \"msg_003\",\n    \"content_index\": 0,\n    \"transcript\": \"Hello, how are you?\"\n}\nconversation.item.input_audio_transcription.delta\nReturned when the text value of an input audio transcription content part is updated.\n\ncontent_index\ninteger\n\nThe index of the content part in the item's content array.\n\ndelta\nstring\n\nThe text delta.\n\nevent_id\nstr", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 99400, "end_char": 100000}, "200": {"text": " index of the content part in the item's content array.\n\ndelta\nstring\n\nThe text delta.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the item.\n\nlogprobs\narray or null\n\nThe log probabilities of the transcription.\n\n\nShow properties\ntype\nstring\n\nThe event type, must be conversation.item.input_audio_transcription.delta.\n\nOBJECT conversation.item.input_audio_transcription.delta\n{\n  \"type\": \"conversation.item.input_audio_transcription.delta\",\n  \"event_id\": \"event_001\",\n  \"item_id\": \"item_001\",\n  \"content_index\": 0,\n  \"delta\": \"Hello\"\n}\nconversation.item.input_audio_", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 99900, "end_char": 100500}, "201": {"text": ",\n  \"item_id\": \"item_001\",\n  \"content_index\": 0,\n  \"delta\": \"Hello\"\n}\nconversation.item.input_audio_transcription.failed\nReturned when input audio transcription is configured, and a transcription request for a user message failed. These events are separate from other error events so that the client can identify the related Item.\n\ncontent_index\ninteger\n\nThe index of the content part containing the audio.\n\nerror\nobject\n\nDetails of the transcription error.\n\n\nShow properties\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the user message item.\n\ntype\nstring\n\nThe even", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 100400, "end_char": 101000}, "202": {"text": "que ID of the server event.\n\nitem_id\nstring\n\nThe ID of the user message item.\n\ntype\nstring\n\nThe event type, must be conversation.item.input_audio_transcription.failed.\n\nOBJECT conversation.item.input_audio_transcription.failed\n{\n    \"event_id\": \"event_2324\",\n    \"type\": \"conversation.item.input_audio_transcription.failed\",\n    \"item_id\": \"msg_003\",\n    \"content_index\": 0,\n    \"error\": {\n        \"type\": \"transcription_error\",\n        \"code\": \"audio_unintelligible\",\n        \"message\": \"The audio could not be transcribed.\",\n        \"param\": null\n    }\n}\nconversation.item.truncated\nReturned when a", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 100900, "end_char": 101500}, "203": {"text": "ould not be transcribed.\",\n        \"param\": null\n    }\n}\nconversation.item.truncated\nReturned when an earlier assistant audio message item is truncated by the client with a conversation.item.truncate event. This event is used to synchronize the server's understanding of the audio with the client's playback.\n\nThis action will truncate the audio and remove the server-side text transcript to ensure there is no text in the context that hasn't been heard by the user.\n\naudio_end_ms\ninteger\n\nThe duration up to which the audio was truncated, in milliseconds.\n\ncontent_index\ninteger\n\nThe index of the co", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 101400, "end_char": 102000}, "204": {"text": "on up to which the audio was truncated, in milliseconds.\n\ncontent_index\ninteger\n\nThe index of the content part that was truncated.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the assistant message item that was truncated.\n\ntype\nstring\n\nThe event type, must be conversation.item.truncated.\n\nOBJECT conversation.item.truncated\n{\n    \"event_id\": \"event_2526\",\n    \"type\": \"conversation.item.truncated\",\n    \"item_id\": \"msg_004\",\n    \"content_index\": 0,\n    \"audio_end_ms\": 1500\n}\nconversation.item.deleted\nReturned when an item in the conversation is deleted by the c", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 101900, "end_char": 102500}, "205": {"text": "_ms\": 1500\n}\nconversation.item.deleted\nReturned when an item in the conversation is deleted by the client with a conversation.item.delete event. This event is used to synchronize the server's understanding of the conversation history with the client's view.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the item that was deleted.\n\ntype\nstring\n\nThe event type, must be conversation.item.deleted.\n\nOBJECT conversation.item.deleted\n{\n    \"event_id\": \"event_2728\",\n    \"type\": \"conversation.item.deleted\",\n    \"item_id\": \"msg_005\"\n}\ninput_audio_buffer.committed\nReturne", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 102400, "end_char": 103000}, "206": {"text": "\"type\": \"conversation.item.deleted\",\n    \"item_id\": \"msg_005\"\n}\ninput_audio_buffer.committed\nReturned when an input audio buffer is committed, either by the client or automatically in server VAD mode. The item_id property is the ID of the user message item that will be created, thus a conversation.item.created event will also be sent to the client.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the user message item that will be created.\n\nprevious_item_id\nstring\n\nThe ID of the preceding item after which the new item will be inserted.\n\ntype\nstring\n\nThe event typ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 102900, "end_char": 103500}, "207": {"text": "\nThe ID of the preceding item after which the new item will be inserted.\n\ntype\nstring\n\nThe event type, must be input_audio_buffer.committed.\n\nOBJECT input_audio_buffer.committed\n{\n    \"event_id\": \"event_1121\",\n    \"type\": \"input_audio_buffer.committed\",\n    \"previous_item_id\": \"msg_001\",\n    \"item_id\": \"msg_002\"\n}\ninput_audio_buffer.cleared\nReturned when the input audio buffer is cleared by the client with a input_audio_buffer.clear event.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\ntype\nstring\n\nThe event type, must be input_audio_buffer.cleared.\n\nOBJECT input_audio_buffer.cleared\n{\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 103400, "end_char": 104000}, "208": {"text": "pe\nstring\n\nThe event type, must be input_audio_buffer.cleared.\n\nOBJECT input_audio_buffer.cleared\n{\n    \"event_id\": \"event_1314\",\n    \"type\": \"input_audio_buffer.cleared\"\n}\ninput_audio_buffer.speech_started\nSent by the server when in server_vad mode to indicate that speech has been detected in the audio buffer. This can happen any time audio is added to the buffer (unless speech is already detected). The client may want to use this event to interrupt audio playback or provide visual feedback to the user.\n\nThe client should expect to receive a input_audio_buffer.speech_stopped event when speech", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 103900, "end_char": 104500}, "209": {"text": "the user.\n\nThe client should expect to receive a input_audio_buffer.speech_stopped event when speech stops. The item_id property is the ID of the user message item that will be created when speech stops and will also be included in the input_audio_buffer.speech_stopped event (unless the client manually commits the audio buffer during VAD activation).\n\naudio_start_ms\ninteger\n\nMilliseconds from the start of all audio written to the buffer during the session when speech was first detected. This will correspond to the beginning of audio sent to the model, and thus includes the prefix_padding_ms co", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 104400, "end_char": 105000}, "210": {"text": "l correspond to the beginning of audio sent to the model, and thus includes the prefix_padding_ms configured in the Session.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the user message item that will be created when speech stops.\n\ntype\nstring\n\nThe event type, must be input_audio_buffer.speech_started.\n\nOBJECT input_audio_buffer.speech_started\n{\n    \"event_id\": \"event_1516\",\n    \"type\": \"input_audio_buffer.speech_started\",\n    \"audio_start_ms\": 1000,\n    \"item_id\": \"msg_003\"\n}\ninput_audio_buffer.speech_stopped\nReturned in server_vad mode when the server dete", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 104900, "end_char": 105500}, "211": {"text": "_id\": \"msg_003\"\n}\ninput_audio_buffer.speech_stopped\nReturned in server_vad mode when the server detects the end of speech in the audio buffer. The server will also send an conversation.item.created event with the user message item that is created from the audio buffer.\n\naudio_end_ms\ninteger\n\nMilliseconds since the session started when speech stopped. This will correspond to the end of audio sent to the model, and thus includes the min_silence_duration_ms configured in the Session.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the user message item that will be", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 105400, "end_char": 106000}, "212": {"text": "ng\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the user message item that will be created.\n\ntype\nstring\n\nThe event type, must be input_audio_buffer.speech_stopped.\n\nOBJECT input_audio_buffer.speech_stopped\n{\n    \"event_id\": \"event_1718\",\n    \"type\": \"input_audio_buffer.speech_stopped\",\n    \"audio_end_ms\": 2000,\n    \"item_id\": \"msg_003\"\n}\nresponse.created\nReturned when a new Response is created. The first event of response creation, where the response is in an initial state of in_progress.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nresponse\nobject\n\nThe response res", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 105900, "end_char": 106500}, "213": {"text": "in_progress.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nresponse\nobject\n\nThe response resource.\n\n\nShow properties\ntype\nstring\n\nThe event type, must be response.created.\n\nOBJECT response.created\n{\n    \"event_id\": \"event_2930\",\n    \"type\": \"response.created\",\n    \"response\": {\n        \"id\": \"resp_001\",\n        \"object\": \"realtime.response\",\n        \"status\": \"in_progress\",\n        \"status_details\": null,\n        \"output\": [],\n        \"usage\": null\n    }\n}\nresponse.done\nReturned when a Response is done streaming. Always emitted, no matter the final state. The Response object included i", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 106400, "end_char": 107000}, "214": {"text": "esponse is done streaming. Always emitted, no matter the final state. The Response object included in the response.done event will include all output Items in the Response but will omit the raw audio data.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nresponse\nobject\n\nThe response resource.\n\n\nShow properties\ntype\nstring\n\nThe event type, must be response.done.\n\nOBJECT response.done\n{\n    \"event_id\": \"event_3132\",\n    \"type\": \"response.done\",\n    \"response\": {\n        \"id\": \"resp_001\",\n        \"object\": \"realtime.response\",\n        \"status\": \"completed\",\n        \"status_details\": null,\n ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 106900, "end_char": 107500}, "215": {"text": "     \"object\": \"realtime.response\",\n        \"status\": \"completed\",\n        \"status_details\": null,\n        \"output\": [\n            {\n                \"id\": \"msg_006\",\n                \"object\": \"realtime.item\",\n                \"type\": \"message\",\n                \"status\": \"completed\",\n                \"role\": \"assistant\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"Sure, how can I assist you today?\"\n                    }\n                ]\n            }\n        ],\n        \"usage\": {\n            \"total_tokens\":275,\n     ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 107400, "end_char": 108000}, "216": {"text": "\n                ]\n            }\n        ],\n        \"usage\": {\n            \"total_tokens\":275,\n            \"input_tokens\":127,\n            \"output_tokens\":148,\n            \"input_token_details\": {\n                \"cached_tokens\":384,\n                \"text_tokens\":119,\n                \"audio_tokens\":8,\n                \"cached_tokens_details\": {\n                    \"text_tokens\": 128,\n                    \"audio_tokens\": 256\n                }\n            },\n            \"output_token_details\": {\n              \"text_tokens\":36,\n              \"audio_tokens\":112\n            }\n        }\n    }\n}\nrespon", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 107900, "end_char": 108500}, "217": {"text": "           \"text_tokens\":36,\n              \"audio_tokens\":112\n            }\n        }\n    }\n}\nresponse.output_item.added\nReturned when a new Item is created during Response generation.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem\nobject\n\nThe item to add to the conversation.\n\n\nShow properties\noutput_index\ninteger\n\nThe index of the output item in the Response.\n\nresponse_id\nstring\n\nThe ID of the Response to which the item belongs.\n\ntype\nstring\n\nThe event type, must be response.output_item.added.\n\nOBJECT response.output_item.added\n{\n    \"event_id\": \"event_3334\",\n    \"type\": \"response", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 108400, "end_char": 109000}, "218": {"text": "item.added.\n\nOBJECT response.output_item.added\n{\n    \"event_id\": \"event_3334\",\n    \"type\": \"response.output_item.added\",\n    \"response_id\": \"resp_001\",\n    \"output_index\": 0,\n    \"item\": {\n        \"id\": \"msg_007\",\n        \"object\": \"realtime.item\",\n        \"type\": \"message\",\n        \"status\": \"in_progress\",\n        \"role\": \"assistant\",\n        \"content\": []\n    }\n}\nresponse.output_item.done\nReturned when an Item is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem\nobject\n\nThe item to add to the conv", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 108900, "end_char": 109500}, "219": {"text": "lled.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem\nobject\n\nThe item to add to the conversation.\n\n\nShow properties\noutput_index\ninteger\n\nThe index of the output item in the Response.\n\nresponse_id\nstring\n\nThe ID of the Response to which the item belongs.\n\ntype\nstring\n\nThe event type, must be response.output_item.done.\n\nOBJECT response.output_item.done\n{\n    \"event_id\": \"event_3536\",\n    \"type\": \"response.output_item.done\",\n    \"response_id\": \"resp_001\",\n    \"output_index\": 0,\n    \"item\": {\n        \"id\": \"msg_007\",\n        \"object\": \"realtime.item\",\n        \"type\": \"message\",\n      ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 109400, "end_char": 110000}, "220": {"text": "em\": {\n        \"id\": \"msg_007\",\n        \"object\": \"realtime.item\",\n        \"type\": \"message\",\n        \"status\": \"completed\",\n        \"role\": \"assistant\",\n        \"content\": [\n            {\n                \"type\": \"text\",\n                \"text\": \"Sure, I can help with that.\"\n            }\n        ]\n    }\n}\nresponse.content_part.added\nReturned when a new content part is added to an assistant message item during response generation.\n\ncontent_index\ninteger\n\nThe index of the content part in the item's content array.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 109900, "end_char": 110500}, "221": {"text": "s content array.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the item to which the content part was added.\n\noutput_index\ninteger\n\nThe index of the output item in the response.\n\npart\nobject\n\nThe content part that was added.\n\n\nShow properties\nresponse_id\nstring\n\nThe ID of the response.\n\ntype\nstring\n\nThe event type, must be response.content_part.added.\n\nOBJECT response.content_part.added\n{\n    \"event_id\": \"event_3738\",\n    \"type\": \"response.content_part.added\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_007\",\n    \"output_index\": 0,\n    \"content_index\": ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 110400, "end_char": 111000}, "222": {"text": "   \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_007\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"part\": {\n        \"type\": \"text\",\n        \"text\": \"\"\n    }\n}\nresponse.content_part.done\nReturned when a content part is done streaming in an assistant message item. Also emitted when a Response is interrupted, incomplete, or cancelled.\n\ncontent_index\ninteger\n\nThe index of the content part in the item's content array.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the item.\n\noutput_index\ninteger\n\nThe index of the output item in the response.\n\npart\nobject\n\nT", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 110900, "end_char": 111500}, "223": {"text": "ID of the item.\n\noutput_index\ninteger\n\nThe index of the output item in the response.\n\npart\nobject\n\nThe content part that is done.\n\n\nShow properties\nresponse_id\nstring\n\nThe ID of the response.\n\ntype\nstring\n\nThe event type, must be response.content_part.done.\n\nOBJECT response.content_part.done\n{\n    \"event_id\": \"event_3940\",\n    \"type\": \"response.content_part.done\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_007\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"part\": {\n        \"type\": \"text\",\n        \"text\": \"Sure, I can help with that.\"\n    }\n}\nresponse.text.delta\nReturned when the", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 111400, "end_char": 112000}, "224": {"text": " \"text\",\n        \"text\": \"Sure, I can help with that.\"\n    }\n}\nresponse.text.delta\nReturned when the text value of a \"text\" content part is updated.\n\ncontent_index\ninteger\n\nThe index of the content part in the item's content array.\n\ndelta\nstring\n\nThe text delta.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the item.\n\noutput_index\ninteger\n\nThe index of the output item in the response.\n\nresponse_id\nstring\n\nThe ID of the response.\n\ntype\nstring\n\nThe event type, must be response.text.delta.\n\nOBJECT response.text.delta\n{\n    \"event_id\": \"event_4142\",\n    \"type\": \"r", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 111900, "end_char": 112500}, "225": {"text": "t be response.text.delta.\n\nOBJECT response.text.delta\n{\n    \"event_id\": \"event_4142\",\n    \"type\": \"response.text.delta\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_007\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"delta\": \"Sure, I can h\"\n}\nresponse.text.done\nReturned when the text value of a \"text\" content part is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.\n\ncontent_index\ninteger\n\nThe index of the content part in the item's content array.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the item.\n\noutput_", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 112400, "end_char": 113000}, "226": {"text": ".\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the item.\n\noutput_index\ninteger\n\nThe index of the output item in the response.\n\nresponse_id\nstring\n\nThe ID of the response.\n\ntext\nstring\n\nThe final text content.\n\ntype\nstring\n\nThe event type, must be response.text.done.\n\nOBJECT response.text.done\n{\n    \"event_id\": \"event_4344\",\n    \"type\": \"response.text.done\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_007\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"text\": \"Sure, I can help with that.\"\n}\nresponse.audio_transcript.delta\nReturned when the model-g", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 112900, "end_char": 113500}, "227": {"text": "   \"text\": \"Sure, I can help with that.\"\n}\nresponse.audio_transcript.delta\nReturned when the model-generated transcription of audio output is updated.\n\ncontent_index\ninteger\n\nThe index of the content part in the item's content array.\n\ndelta\nstring\n\nThe transcript delta.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the item.\n\noutput_index\ninteger\n\nThe index of the output item in the response.\n\nresponse_id\nstring\n\nThe ID of the response.\n\ntype\nstring\n\nThe event type, must be response.audio_transcript.delta.\n\nOBJECT response.audio_transcript.delta\n{\n    \"event_i", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 113400, "end_char": 114000}, "228": {"text": "ype, must be response.audio_transcript.delta.\n\nOBJECT response.audio_transcript.delta\n{\n    \"event_id\": \"event_4546\",\n    \"type\": \"response.audio_transcript.delta\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_008\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"delta\": \"Hello, how can I a\"\n}\nresponse.audio_transcript.done\nReturned when the model-generated transcription of audio output is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.\n\ncontent_index\ninteger\n\nThe index of the content part in the item's content array.\n\nevent_id\nstring\n\nThe uniqu", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 113900, "end_char": 114500}, "229": {"text": "ndex\ninteger\n\nThe index of the content part in the item's content array.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the item.\n\noutput_index\ninteger\n\nThe index of the output item in the response.\n\nresponse_id\nstring\n\nThe ID of the response.\n\ntranscript\nstring\n\nThe final transcript of the audio.\n\ntype\nstring\n\nThe event type, must be response.audio_transcript.done.\n\nOBJECT response.audio_transcript.done\n{\n    \"event_id\": \"event_4748\",\n    \"type\": \"response.audio_transcript.done\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_008\",\n    \"output_index\": 0,\n ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 114400, "end_char": 115000}, "230": {"text": "_transcript.done\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_008\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"transcript\": \"Hello, how can I assist you today?\"\n}\nresponse.audio.delta\nReturned when the model-generated audio is updated.\n\ncontent_index\ninteger\n\nThe index of the content part in the item's content array.\n\ndelta\nstring\n\nBase64-encoded audio data delta.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the item.\n\noutput_index\ninteger\n\nThe index of the output item in the response.\n\nresponse_id\nstring\n\nThe ID of the response.\n\ntype\nstring", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 114900, "end_char": 115500}, "231": {"text": " index of the output item in the response.\n\nresponse_id\nstring\n\nThe ID of the response.\n\ntype\nstring\n\nThe event type, must be response.audio.delta.\n\nOBJECT response.audio.delta\n{\n    \"event_id\": \"event_4950\",\n    \"type\": \"response.audio.delta\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_008\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"delta\": \"Base64EncodedAudioDelta\"\n}\nresponse.audio.done\nReturned when the model-generated audio is done. Also emitted when a Response is interrupted, incomplete, or cancelled.\n\ncontent_index\ninteger\n\nThe index of the content part in the item's co", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 115400, "end_char": 116000}, "232": {"text": "ed, incomplete, or cancelled.\n\ncontent_index\ninteger\n\nThe index of the content part in the item's content array.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the item.\n\noutput_index\ninteger\n\nThe index of the output item in the response.\n\nresponse_id\nstring\n\nThe ID of the response.\n\ntype\nstring\n\nThe event type, must be response.audio.done.\n\nOBJECT response.audio.done\n{\n    \"event_id\": \"event_5152\",\n    \"type\": \"response.audio.done\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_008\",\n    \"output_index\": 0,\n    \"content_index\": 0\n}\nresponse.function_call_a", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 115900, "end_char": 116500}, "233": {"text": ",\n    \"item_id\": \"msg_008\",\n    \"output_index\": 0,\n    \"content_index\": 0\n}\nresponse.function_call_arguments.delta\nReturned when the model-generated function call arguments are updated.\n\ncall_id\nstring\n\nThe ID of the function call.\n\ndelta\nstring\n\nThe arguments delta as a JSON string.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the function call item.\n\noutput_index\ninteger\n\nThe index of the output item in the response.\n\nresponse_id\nstring\n\nThe ID of the response.\n\ntype\nstring\n\nThe event type, must be response.function_call_arguments.delta.\n\nOBJECT response.fu", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 116400, "end_char": 117000}, "234": {"text": "e.\n\ntype\nstring\n\nThe event type, must be response.function_call_arguments.delta.\n\nOBJECT response.function_call_arguments.delta\n{\n    \"event_id\": \"event_5354\",\n    \"type\": \"response.function_call_arguments.delta\",\n    \"response_id\": \"resp_002\",\n    \"item_id\": \"fc_001\",\n    \"output_index\": 0,\n    \"call_id\": \"call_001\",\n    \"delta\": \"{\\\"location\\\": \\\"San\\\"\"\n}\nresponse.function_call_arguments.done\nReturned when the model-generated function call arguments are done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.\n\narguments\nstring\n\nThe final arguments as a JSON stri", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 116900, "end_char": 117500}, "235": {"text": "onse is interrupted, incomplete, or cancelled.\n\narguments\nstring\n\nThe final arguments as a JSON string.\n\ncall_id\nstring\n\nThe ID of the function call.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nitem_id\nstring\n\nThe ID of the function call item.\n\noutput_index\ninteger\n\nThe index of the output item in the response.\n\nresponse_id\nstring\n\nThe ID of the response.\n\ntype\nstring\n\nThe event type, must be response.function_call_arguments.done.\n\nOBJECT response.function_call_arguments.done\n{\n    \"event_id\": \"event_5556\",\n    \"type\": \"response.function_call_arguments.done\",\n    \"response_id\": \"resp", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 117400, "end_char": 118000}, "236": {"text": "ent_id\": \"event_5556\",\n    \"type\": \"response.function_call_arguments.done\",\n    \"response_id\": \"resp_002\",\n    \"item_id\": \"fc_001\",\n    \"output_index\": 0,\n    \"call_id\": \"call_001\",\n    \"arguments\": \"{\\\"location\\\": \\\"San Francisco\\\"}\"\n}\ntranscription_session.updated\nReturned when a transcription session is updated with a transcription_session.update event, unless there is an error.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nsession\nobject\n\nA new Realtime transcription session configuration.\n\nWhen a session is created on the server via REST API, the session object also contains an ep", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 117900, "end_char": 118500}, "237": {"text": "ation.\n\nWhen a session is created on the server via REST API, the session object also contains an ephemeral key. Default TTL for keys is one minute. This property is not present when a session is updated via the WebSocket API.\n\n\nShow properties\ntype\nstring\n\nThe event type, must be transcription_session.updated.\n\nOBJECT transcription_session.updated\n{\n  \"event_id\": \"event_5678\",\n  \"type\": \"transcription_session.updated\",\n  \"session\": {\n    \"id\": \"sess_001\",\n    \"object\": \"realtime.transcription_session\",\n    \"input_audio_format\": \"pcm16\",\n    \"input_audio_transcription\": {\n      \"model\": \"gpt-4", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 118400, "end_char": 119000}, "238": {"text": "ession\",\n    \"input_audio_format\": \"pcm16\",\n    \"input_audio_transcription\": {\n      \"model\": \"gpt-4o-transcribe\",\n      \"prompt\": \"\",\n      \"language\": \"\"\n    },\n    \"turn_detection\": {\n      \"type\": \"server_vad\",\n      \"threshold\": 0.5,\n      \"prefix_padding_ms\": 300,\n      \"silence_duration_ms\": 500,\n      \"create_response\": true,\n      // \"interrupt_response\": false  -- this will NOT be returned\n    },\n    \"input_audio_noise_reduction\": {\n      \"type\": \"near_field\"\n    },\n    \"include\": [\n      \"item.input_audio_transcription.avg_logprob\",\n    ],\n  }\n}\nrate_limits.updated\nEmitted at the be", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 118900, "end_char": 119500}, "239": {"text": "    \"item.input_audio_transcription.avg_logprob\",\n    ],\n  }\n}\nrate_limits.updated\nEmitted at the beginning of a Response to indicate the updated rate limits. When a Response is created some tokens will be \"reserved\" for the output tokens, the rate limits shown here reflect that reservation, which is then adjusted accordingly once the Response is completed.\n\nevent_id\nstring\n\nThe unique ID of the server event.\n\nrate_limits\narray\n\nList of rate limit information.\n\n\nShow properties\ntype\nstring\n\nThe event type, must be rate_limits.updated.\n\nOBJECT rate_limits.updated\n{\n    \"event_id\": \"event_5758\",", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 119400, "end_char": 120000}, "240": {"text": "event type, must be rate_limits.updated.\n\nOBJECT rate_limits.updated\n{\n    \"event_id\": \"event_5758\",\n    \"type\": \"rate_limits.updated\",\n    \"rate_limits\": [\n        {\n            \"name\": \"requests\",\n            \"limit\": 1000,\n            \"remaining\": 999,\n            \"reset_seconds\": 60\n        },\n        {\n            \"name\": \"tokens\",\n            \"limit\": 50000,\n            \"remaining\": 49950,\n            \"reset_seconds\": 60\n        }\n    ]\n}\nAudio\nLearn how to turn audio into text or text into audio.\n\nRelated guide: Speech to text\n\nCreate speech\npost\n \nhttps://api.openai.com/v1/audio/speech", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 119900, "end_char": 120500}, "241": {"text": "o audio.\n\nRelated guide: Speech to text\n\nCreate speech\npost\n \nhttps://api.openai.com/v1/audio/speech\nGenerates audio from the input text.\n\nRequest body\ninput\nstring\n\nRequired\nThe text to generate audio for. The maximum length is 4096 characters.\n\nmodel\nstring\n\nRequired\nOne of the available TTS models: tts-1, tts-1-hd or gpt-4o-mini-tts.\n\nvoice\nstring\n\nRequired\nThe voice to use when generating the audio. Supported voices are alloy, ash, ballad, coral, echo, fable, onyx, nova, sage, shimmer, and verse. Previews of the voices are available in the Text to speech guide.\n\ninstructions\nstring\n\nOption", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 120400, "end_char": 121000}, "242": {"text": "erse. Previews of the voices are available in the Text to speech guide.\n\ninstructions\nstring\n\nOptional\nControl the voice of your generated audio with additional instructions. Does not work with tts-1 or tts-1-hd.\n\nresponse_format\nstring\n\nOptional\nDefaults to mp3\nThe format to audio in. Supported formats are mp3, opus, aac, flac, wav, and pcm.\n\nspeed\nnumber\n\nOptional\nDefaults to 1\nThe speed of the generated audio. Select a value from 0.25 to 4.0. 1.0 is the default.\n\nReturns\nThe audio file content.\n\nExample request\nfrom pathlib import Path\nimport openai\n\nspeech_file_path = Path(__file__).parent", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 120900, "end_char": 121500}, "243": {"text": "t.\n\nExample request\nfrom pathlib import Path\nimport openai\n\nspeech_file_path = Path(__file__).parent / \"speech.mp3\"\nwith openai.audio.speech.with_streaming_response.create(\n  model=\"gpt-4o-mini-tts\",\n  voice=\"alloy\",\n  input=\"The quick brown fox jumped over the lazy dog.\"\n) as response:\n  response.stream_to_file(speech_file_path)\nCreate transcription\npost\n \nhttps://api.openai.com/v1/audio/transcriptions\nTranscribes audio into the input language.\n\nRequest body\nfile\nfile\n\nRequired\nThe audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 121400, "end_char": 122000}, "244": {"text": "bject (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n\nmodel\nstring\n\nRequired\nID of the model to use. The options are gpt-4o-transcribe, gpt-4o-mini-transcribe, and whisper-1 (which is powered by our open source Whisper V2 model).\n\ninclude[]\narray\n\nOptional\nAdditional information to include in the transcription response. logprobs will return the log probabilities of the tokens in the response to understand the model's confidence in the transcription. logprobs only works with response_format set to json and only with the models gpt-4o-", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 121900, "end_char": 122500}, "245": {"text": "transcription. logprobs only works with response_format set to json and only with the models gpt-4o-transcribe and gpt-4o-mini-transcribe.\n\nlanguage\nstring\n\nOptional\nThe language of the input audio. Supplying the input language in ISO-639-1 (e.g. en) format will improve accuracy and latency.\n\nprompt\nstring\n\nOptional\nAn optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language.\n\nresponse_format\nstring\n\nOptional\nDefaults to json\nThe format of the output, in one of these options: json, text, srt, verbose_json, or vtt. For gpt-4o-tran", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 122400, "end_char": 123000}, "246": {"text": "ormat of the output, in one of these options: json, text, srt, verbose_json, or vtt. For gpt-4o-transcribe and gpt-4o-mini-transcribe, the only supported format is json.\n\nstream\nboolean or null\n\nOptional\nDefaults to false\nIf set to true, the model response data will be streamed to the client as it is generated using server-sent events. See the Streaming section of the Speech-to-Text guide for more information.\n\nNote: Streaming is not supported for the whisper-1 model and will be ignored.\n\ntemperature\nnumber\n\nOptional\nDefaults to 0\nThe sampling temperature, between 0 and 1. Higher values like 0", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 122900, "end_char": 123500}, "247": {"text": "ature\nnumber\n\nOptional\nDefaults to 0\nThe sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n\ntimestamp_granularities[]\narray\n\nOptional\nDefaults to segment\nThe timestamp granularities to populate for this transcription. response_format must be set verbose_json to use timestamp granularities. Either or both of these options are supported: word, or segment. N", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 123400, "end_char": 124000}, "248": {"text": "n to use timestamp granularities. Either or both of these options are supported: word, or segment. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.\n\nReturns\nThe transcription object, a verbose transcription object or a stream of transcript events.\n\n\nDefault\n\nStreaming\n\nLogprobs\n\nWord timestamps\n\nSegment timestamps\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\naudio_file = open(\"speech.mp3\", \"rb\")\ntranscript = client.audio.transcriptions.create(\n  model=\"gpt-4o-transcribe\",\n  file=audio_file\n)\nResponse\n{\n  \"tex", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 123900, "end_char": 124500}, "249": {"text": "ient.audio.transcriptions.create(\n  model=\"gpt-4o-transcribe\",\n  file=audio_file\n)\nResponse\n{\n  \"text\": \"Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that.\"\n}\nCreate translation\npost\n \nhttps://api.openai.com/v1/audio/translations\nTranslates audio into English.\n\nRequest body\nfile\nfile\n\nRequired\nThe audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n\nmodel\nstring or \"whisper-1\"\n\nRequired\nID of", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 124400, "end_char": 125000}, "250": {"text": "ts: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n\nmodel\nstring or \"whisper-1\"\n\nRequired\nID of the model to use. Only whisper-1 (which is powered by our open source Whisper V2 model) is currently available.\n\nprompt\nstring\n\nOptional\nAn optional text to guide the model's style or continue a previous audio segment. The prompt should be in English.\n\nresponse_format\nstring\n\nOptional\nDefaults to json\nThe format of the output, in one of these options: json, text, srt, verbose_json, or vtt.\n\ntemperature\nnumber\n\nOptional\nDefaults to 0\nThe sampling temperature, between 0 and 1. Higher values like ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 124900, "end_char": 125500}, "251": {"text": "rature\nnumber\n\nOptional\nDefaults to 0\nThe sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n\nReturns\nThe translated text.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\naudio_file = open(\"speech.mp3\", \"rb\")\ntranscript = client.audio.translations.create(\n  model=\"whisper-1\",\n  file=audio_file\n)\nResponse\n{\n  \"text\": \"Hello, my name is Wolfgan", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 125400, "end_char": 126000}, "252": {"text": "ons.create(\n  model=\"whisper-1\",\n  file=audio_file\n)\nResponse\n{\n  \"text\": \"Hello, my name is Wolfgang and I come from Germany. Where are you heading today?\"\n}\nThe transcription object (JSON)\nRepresents a transcription response returned by model, based on the provided input.\n\nlogprobs\narray\n\nThe log probabilities of the tokens in the transcription. Only returned with the models gpt-4o-transcribe and gpt-4o-mini-transcribe if logprobs is added to the include array.\n\n\nShow properties\ntext\nstring\n\nThe transcribed text.\n\nOBJECT The transcription object (JSON)\n{\n  \"text\": \"Imagine the wildest idea t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 125900, "end_char": 126500}, "253": {"text": "he transcribed text.\n\nOBJECT The transcription object (JSON)\n{\n  \"text\": \"Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that.\"\n}\nThe transcription object (Verbose JSON)\nRepresents a verbose json transcription response returned by model, based on the provided input.\n\nduration\nnumber\n\nThe duration of the input audio.\n\nlanguage\nstring\n\nThe language of the input audio.\n\nsegments\narray\n\nSegments of the transcribed text and their corresponding details.\n\n\nShow properti", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 126400, "end_char": 127000}, "254": {"text": ".\n\nsegments\narray\n\nSegments of the transcribed text and their corresponding details.\n\n\nShow properties\ntext\nstring\n\nThe transcribed text.\n\nwords\narray\n\nExtracted words and their corresponding timestamps.\n\n\nShow properties\nOBJECT The transcription object (Verbose JSON)\n{\n  \"task\": \"transcribe\",\n  \"language\": \"english\",\n  \"duration\": 8.470000267028809,\n  \"text\": \"The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.\",\n  \"segments\": [\n    {\n      \"id\": 0,\n      \"seek\": 0,\n      \"start\": 0.0,\n      \"end\": 3.31999993", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 126900, "end_char": 127500}, "255": {"text": "\",\n  \"segments\": [\n    {\n      \"id\": 0,\n      \"seek\": 0,\n      \"start\": 0.0,\n      \"end\": 3.319999933242798,\n      \"text\": \" The beach was a popular spot on a hot summer day.\",\n      \"tokens\": [\n        50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530\n      ],\n      \"temperature\": 0.0,\n      \"avg_logprob\": -0.2860786020755768,\n      \"compression_ratio\": 1.2363636493682861,\n      \"no_speech_prob\": 0.00985979475080967\n    },\n    ...\n  ]\n}\nStream Event (transcript.text.delta)\nEmitted when there is an additional text delta. This is also the first event emitted when the ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 127400, "end_char": 128000}, "256": {"text": "elta)\nEmitted when there is an additional text delta. This is also the first event emitted when the transcription starts. Only emitted when you create a transcription with the Stream parameter set to true.\n\ndelta\nstring\n\nThe text delta that was additionally transcribed.\n\nlogprobs\narray\n\nThe log probabilities of the delta. Only included if you create a transcription with the include[] parameter set to logprobs.\n\n\nShow properties\ntype\nstring\n\nThe type of the event. Always transcript.text.delta.\n\nOBJECT Stream Event (transcript.text.delta)\n{\n  \"type\": \"transcript.text.delta\",\n  \"delta\": \" wonderf", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 127900, "end_char": 128500}, "257": {"text": "BJECT Stream Event (transcript.text.delta)\n{\n  \"type\": \"transcript.text.delta\",\n  \"delta\": \" wonderful\"\n}\nStream Event (transcript.text.done)\nEmitted when the transcription is complete. Contains the complete transcription text. Only emitted when you create a transcription with the Stream parameter set to true.\n\nlogprobs\narray\n\nThe log probabilities of the individual tokens in the transcription. Only included if you create a transcription with the include[] parameter set to logprobs.\n\n\nShow properties\ntext\nstring\n\nThe text that was transcribed.\n\ntype\nstring\n\nThe type of the event. Always transc", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 128400, "end_char": 129000}, "258": {"text": "rties\ntext\nstring\n\nThe text that was transcribed.\n\ntype\nstring\n\nThe type of the event. Always transcript.text.done.\n\nOBJECT Stream Event (transcript.text.done)\n{\n  \"type\": \"transcript.text.done\",\n  \"text\": \"I see skies of blue and clouds of white, the bright blessed days, the dark sacred nights, and I think to myself, what a wonderful world.\"\n}\nEmbeddings\nGet a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Related guide: Embeddings\n\nCreate embeddings\npost\n \nhttps://api.openai.com/v1/embeddings\nCreates an embedding vector represent", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 128900, "end_char": 129500}, "259": {"text": "\nCreate embeddings\npost\n \nhttps://api.openai.com/v1/embeddings\nCreates an embedding vector representing the input text.\n\nRequest body\ninput\nstring or array\n\nRequired\nInput text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for text-embedding-ada-002), cannot be an empty string, and any array must be 2048 dimensions or less. Example Python code for counting tokens. Some models may also impose a limit on total number of tok", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 129400, "end_char": 130000}, "260": {"text": " Example Python code for counting tokens. Some models may also impose a limit on total number of tokens summed across inputs.\n\n\nShow possible types\nmodel\nstring\n\nRequired\nID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.\n\ndimensions\ninteger\n\nOptional\nThe number of dimensions the resulting output embeddings should have. Only supported in text-embedding-3 and later models.\n\nencoding_format\nstring\n\nOptional\nDefaults to float\nThe format to return the embeddings in. Can be either float or base64.\n\nuser\nst", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 129900, "end_char": 130500}, "261": {"text": "al\nDefaults to float\nThe format to return the embeddings in. Can be either float or base64.\n\nuser\nstring\n\nOptional\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.\n\nReturns\nA list of embedding objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.embeddings.create(\n  model=\"text-embedding-ada-002\",\n  input=\"The food was delicious and the waiter...\",\n  encoding_format=\"float\"\n)\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"embedding\",\n      \"embedding\": [\n        0.0023064255,\n        -0.00", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 130400, "end_char": 131000}, "262": {"text": "data\": [\n    {\n      \"object\": \"embedding\",\n      \"embedding\": [\n        0.0023064255,\n        -0.009327292,\n        .... (1536 floats total for ada-002)\n        -0.0028842222,\n      ],\n      \"index\": 0\n    }\n  ],\n  \"model\": \"text-embedding-ada-002\",\n  \"usage\": {\n    \"prompt_tokens\": 8,\n    \"total_tokens\": 8\n  }\n}\nThe embedding object\nRepresents an embedding vector returned by embedding endpoint.\n\nembedding\narray\n\nThe embedding vector, which is a list of floats. The length of vector depends on the model as listed in the embedding guide.\n\nindex\ninteger\n\nThe index of the embedding in the list of", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 130900, "end_char": 131500}, "263": {"text": "he model as listed in the embedding guide.\n\nindex\ninteger\n\nThe index of the embedding in the list of embeddings.\n\nobject\nstring\n\nThe object type, which is always \"embedding\".\n\nOBJECT The embedding object\n{\n  \"object\": \"embedding\",\n  \"embedding\": [\n    0.0023064255,\n    -0.009327292,\n    .... (1536 floats total for ada-002)\n    -0.0028842222,\n  ],\n  \"index\": 0\n}\nEvals\nCreate, manage, and run evals in the OpenAI platform. Related guide: Evals\n\nCreate eval\npost\n \nhttps://api.openai.com/v1/evals\nCreate the structure of an evaluation that can be used to test a model's performance. An evaluation is ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 131400, "end_char": 132000}, "264": {"text": "ate the structure of an evaluation that can be used to test a model's performance. An evaluation is a set of testing criteria and a datasource. After creating an evaluation, you can run it on different models and model parameters. We support several types of graders and datasources. For more information, see the Evals guide.\n\nRequest body\ndata_source_config\nobject\n\nRequired\nThe configuration for the data source used for the evaluation runs.\n\n\nShow possible types\ntesting_criteria\narray\n\nRequired\nA list of graders for all eval runs in this group.\n\n\nShow possible types\nmetadata\nmap\n\nOptional\nSet ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 131900, "end_char": 132500}, "265": {"text": "A list of graders for all eval runs in this group.\n\n\nShow possible types\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nname\nstring\n\nOptional\nThe name of the evaluation.\n\nReturns\nThe created Eval object.\n\nExample request\ncurl https://api.openai.com/v1/evals \\\n  -H \"Authorization: Bearer $OPENAI_AP", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 132400, "end_char": 133000}, "266": {"text": "ject.\n\nExample request\ncurl https://api.openai.com/v1/evals \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n        \"name\": \"Sentiment\",\n        \"data_source_config\": {\n          \"type\": \"stored_completions\",\n          \"metadata\": {\n              \"usecase\": \"chatbot\"\n          }\n        },\n        \"testing_criteria\": [\n          {\n            \"type\": \"label_model\",\n            \"model\": \"o3-mini\",\n            \"input\": [\n              {\n                \"role\": \"developer\",\n                \"content\": \"Classify the sentiment of the following stateme", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 132900, "end_char": 133500}, "267": {"text": "    \"role\": \"developer\",\n                \"content\": \"Classify the sentiment of the following statement as one of 'positive', 'neutral', or 'negative'\"\n              },\n              {\n                \"role\": \"user\",\n                \"content\": \"Statement: {{item.input}}\"\n              }\n            ],\n            \"passing_labels\": [\n              \"positive\"\n            ],\n            \"labels\": [\n              \"positive\",\n              \"neutral\",\n              \"negative\"\n            ],\n            \"name\": \"Example label grader\"\n          }\n        ]\n      }'\nResponse\n{\n  \"object\": \"eval\",\n  \"id\"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 133400, "end_char": 134000}, "268": {"text": " \"name\": \"Example label grader\"\n          }\n        ]\n      }'\nResponse\n{\n  \"object\": \"eval\",\n  \"id\": \"eval_67b7fa9a81a88190ab4aa417e397ea21\",\n  \"data_source_config\": {\n    \"type\": \"stored_completions\",\n    \"metadata\": {\n      \"usecase\": \"chatbot\"\n    },\n    \"schema\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"item\": {\n          \"type\": \"object\"\n        },\n        \"sample\": {\n          \"type\": \"object\"\n        }\n      },\n      \"required\": [\n        \"item\",\n        \"sample\"\n      ]\n  },\n  \"testing_criteria\": [\n    {\n      \"name\": \"Example label grader\",\n      \"type\": \"label_model\"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 133900, "end_char": 134500}, "269": {"text": "  },\n  \"testing_criteria\": [\n    {\n      \"name\": \"Example label grader\",\n      \"type\": \"label_model\",\n      \"model\": \"o3-mini\",\n      \"input\": [\n        {\n          \"type\": \"message\",\n          \"role\": \"developer\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"Classify the sentiment of the following statement as one of positive, neutral, or negative\"\n          }\n        },\n        {\n          \"type\": \"message\",\n          \"role\": \"user\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"Statement: {{item.input}}\"\n          }\n        }\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 134400, "end_char": 135000}, "270": {"text": "        \"type\": \"input_text\",\n            \"text\": \"Statement: {{item.input}}\"\n          }\n        }\n      ],\n      \"passing_labels\": [\n        \"positive\"\n      ],\n      \"labels\": [\n        \"positive\",\n        \"neutral\",\n        \"negative\"\n      ]\n    }\n  ],\n  \"name\": \"Sentiment\",\n  \"created_at\": 1740110490,\n  \"metadata\": {\n    \"description\": \"An eval for sentiment analysis\"\n  }\n}\nGet an eval\nget\n \nhttps://api.openai.com/v1/evals/{eval_id}\nGet an evaluation by ID.\n\nPath parameters\neval_id\nstring\n\nRequired\nThe ID of the evaluation to retrieve.\n\nReturns\nThe Eval object matching the specified ID.\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 134900, "end_char": 135500}, "271": {"text": "\nRequired\nThe ID of the evaluation to retrieve.\n\nReturns\nThe Eval object matching the specified ID.\n\nExample request\ncurl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n  \"object\": \"eval\",\n  \"id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"data_source_config\": {\n    \"type\": \"custom\",\n    \"schema\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"item\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"input\": {\n              \"type\": \"string\"\n     ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 135400, "end_char": 136000}, "272": {"text": "pe\": \"object\",\n          \"properties\": {\n            \"input\": {\n              \"type\": \"string\"\n            },\n            \"ground_truth\": {\n              \"type\": \"string\"\n            }\n          },\n          \"required\": [\n            \"input\",\n            \"ground_truth\"\n          ]\n        }\n      },\n      \"required\": [\n        \"item\"\n      ]\n    }\n  },\n  \"testing_criteria\": [\n    {\n      \"name\": \"String check\",\n      \"id\": \"String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2\",\n      \"type\": \"string_check\",\n      \"input\": \"{{item.input}}\",\n      \"reference\": \"{{item.ground_truth}}\",\n      \"operat", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 135900, "end_char": 136500}, "273": {"text": "g_check\",\n      \"input\": \"{{item.input}}\",\n      \"reference\": \"{{item.ground_truth}}\",\n      \"operation\": \"eq\"\n    }\n  ],\n  \"name\": \"External Data Eval\",\n  \"created_at\": 1739314509,\n  \"metadata\": {},\n}\nUpdate an eval\npost\n \nhttps://api.openai.com/v1/evals/{eval_id}\nUpdate certain properties of an evaluation.\n\nPath parameters\neval_id\nstring\n\nRequired\nThe ID of the evaluation to update.\n\nRequest body\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for ob", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 136400, "end_char": 137000}, "274": {"text": "eful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nname\nstring\n\nOptional\nRename the evaluation.\n\nReturns\nThe Eval object matching the updated version.\n\nExample request\ncurl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\": \"Updated Eval\", \"metadata\": {\"description\": \"Updated ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 136900, "end_char": 137500}, "275": {"text": "ntent-Type: application/json\" \\\n  -d '{\"name\": \"Updated Eval\", \"metadata\": {\"description\": \"Updated description\"}}'\nResponse\n{\n  \"object\": \"eval\",\n  \"id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"data_source_config\": {\n    \"type\": \"custom\",\n    \"schema\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"item\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"input\": {\n              \"type\": \"string\"\n            },\n            \"ground_truth\": {\n              \"type\": \"string\"\n            }\n          },\n          \"required\": [\n            \"input\",\n            \"ground_", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 137400, "end_char": 138000}, "276": {"text": "string\"\n            }\n          },\n          \"required\": [\n            \"input\",\n            \"ground_truth\"\n          ]\n        }\n      },\n      \"required\": [\n        \"item\"\n      ]\n    }\n  },\n  \"testing_criteria\": [\n    {\n      \"name\": \"String check\",\n      \"id\": \"String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2\",\n      \"type\": \"string_check\",\n      \"input\": \"{{item.input}}\",\n      \"reference\": \"{{item.ground_truth}}\",\n      \"operation\": \"eq\"\n    }\n  ],\n  \"name\": \"Updated Eval\",\n  \"created_at\": 1739314509,\n  \"metadata\": {\"description\": \"Updated description\"},\n}\nDelete an eval\ndelete\n \nhttps:/", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 137900, "end_char": 138500}, "277": {"text": " 1739314509,\n  \"metadata\": {\"description\": \"Updated description\"},\n}\nDelete an eval\ndelete\n \nhttps://api.openai.com/v1/evals/{eval_id}\nDelete an evaluation.\n\nPath parameters\neval_id\nstring\n\nRequired\nThe ID of the evaluation to delete.\n\nReturns\nA deletion confirmation object.\n\nExample request\ncurl https://api.openai.com/v1/evals/eval_abc123 \\\n  -X DELETE \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\n{\n  \"object\": \"eval.deleted\",\n  \"deleted\": true,\n  \"eval_id\": \"eval_abc123\"\n}\nList evals\nget\n \nhttps://api.openai.com/v1/evals\nList evaluations for a project.\n\nQuery parameters\nafter\nstrin", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 138400, "end_char": 139000}, "278": {"text": "\nget\n \nhttps://api.openai.com/v1/evals\nList evaluations for a project.\n\nQuery parameters\nafter\nstring\n\nOptional\nIdentifier for the last eval from the previous pagination request.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nNumber of evals to retrieve.\n\norder\nstring\n\nOptional\nDefaults to asc\nSort order for evals by timestamp. Use asc for ascending order or desc for descending order.\n\norder_by\nstring\n\nOptional\nDefaults to created_at\nEvals can be ordered by creation time or last updated time. Use created_at for creation time or updated_at for last updated time.\n\nReturns\nA list of evals matching the s", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 138900, "end_char": 139500}, "279": {"text": "ed_at for creation time or updated_at for last updated time.\n\nReturns\nA list of evals matching the specified filters.\n\nExample request\ncurl https://api.openai.com/v1/evals?limit=1 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n      \"object\": \"eval\",\n      \"data_source_config\": {\n        \"type\": \"stored_completions\",\n        \"metadata\": {\n          \"usecase\": \"push_notifications_summarizer\"\n        },\n        \"schema\": {\n          \"type\": \"object\",\n     ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 139400, "end_char": 140000}, "280": {"text": "e\": \"push_notifications_summarizer\"\n        },\n        \"schema\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"item\": {\n              \"type\": \"object\"\n            },\n            \"sample\": {\n              \"type\": \"object\"\n            }\n          },\n          \"required\": [\n            \"item\",\n            \"sample\"\n          ]\n        }\n      },\n      \"testing_criteria\": [\n        {\n          \"name\": \"Push Notification Summary Grader\",\n          \"id\": \"Push Notification Summary Grader-9b876f24-4762-4be9-aff4-db7a9b31c673\",\n          \"type\": \"label_model\",\n          \"model\": ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 139900, "end_char": 140500}, "281": {"text": "y Grader-9b876f24-4762-4be9-aff4-db7a9b31c673\",\n          \"type\": \"label_model\",\n          \"model\": \"o3-mini\",\n          \"input\": [\n            {\n              \"type\": \"message\",\n              \"role\": \"developer\",\n              \"content\": {\n                \"type\": \"input_text\",\n                \"text\": \"\\nLabel the following push notification summary as either correct or incorrect.\\nThe push notification and the summary will be provided below.\\nA good push notificiation summary is concise and snappy.\\nIf it is good, then label it as correct, if not, then incorrect.\\n\"\n              }\n          ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 140400, "end_char": 141000}, "282": {"text": "ppy.\\nIf it is good, then label it as correct, if not, then incorrect.\\n\"\n              }\n            },\n            {\n              \"type\": \"message\",\n              \"role\": \"user\",\n              \"content\": {\n                \"type\": \"input_text\",\n                \"text\": \"\\nPush notifications: {{item.input}}\\nSummary: {{sample.output_text}}\\n\"\n              }\n            }\n          ],\n          \"passing_labels\": [\n            \"correct\"\n          ],\n          \"labels\": [\n            \"correct\",\n            \"incorrect\"\n          ],\n          \"sampling_params\": null\n        }\n      ],\n      \"name\"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 140900, "end_char": 141500}, "283": {"text": "          \"incorrect\"\n          ],\n          \"sampling_params\": null\n        }\n      ],\n      \"name\": \"Push Notification Summary Grader\",\n      \"created_at\": 1739314509,\n      \"metadata\": {\n        \"description\": \"A stored completions eval for push notification summaries\"\n      }\n    }\n  ],\n  \"first_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"last_id\": \"eval_67aa884cf6688190b58f657d4441c8b7\",\n  \"has_more\": true\n}\nGet eval runs\nget\n \nhttps://api.openai.com/v1/evals/{eval_id}/runs\nGet a list of runs for an evaluation.\n\nPath parameters\neval_id\nstring\n\nRequired\nThe ID of the evaluation to ret", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 141400, "end_char": 142000}, "284": {"text": "of runs for an evaluation.\n\nPath parameters\neval_id\nstring\n\nRequired\nThe ID of the evaluation to retrieve runs for.\n\nQuery parameters\nafter\nstring\n\nOptional\nIdentifier for the last run from the previous pagination request.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nNumber of runs to retrieve.\n\norder\nstring\n\nOptional\nDefaults to asc\nSort order for runs by timestamp. Use asc for ascending order or desc for descending order. Defaults to asc.\n\nstatus\nstring\n\nOptional\nFilter runs by status. One of queued | in_progress | failed | completed | canceled.\n\nReturns\nA list of EvalRun objects matching the spe", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 141900, "end_char": 142500}, "285": {"text": "d | in_progress | failed | completed | canceled.\n\nReturns\nA list of EvalRun objects matching the specified ID.\n\nExample request\ncurl https://api.openai.com/v1/evals/egroup_67abd54d9b0081909a86353f6fb9317a/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"eval.run\",\n      \"id\": \"evalrun_67e0c7d31560819090d60c0780591042\",\n      \"eval_id\": \"eval_67e0c726d560819083f19a957c4c640b\",\n      \"report_url\": \"https://platform.openai.com/evaluations/eval_67e0c726d560819083f19a957c4c640b\",\n      \"stat", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 142400, "end_char": 143000}, "286": {"text": "t_url\": \"https://platform.openai.com/evaluations/eval_67e0c726d560819083f19a957c4c640b\",\n      \"status\": \"completed\",\n      \"model\": \"o3-mini\",\n      \"name\": \"bulk_with_negative_examples_o3-mini\",\n      \"created_at\": 1742784467,\n      \"result_counts\": {\n        \"total\": 1,\n        \"errored\": 0,\n        \"failed\": 0,\n        \"passed\": 1\n      },\n      \"per_model_usage\": [\n        {\n          \"model_name\": \"o3-mini\",\n          \"invocation_count\": 1,\n          \"prompt_tokens\": 563,\n          \"completion_tokens\": 874,\n          \"total_tokens\": 1437,\n          \"cached_tokens\": 0\n        }\n      ],\n ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 142900, "end_char": 143500}, "287": {"text": "tion_tokens\": 874,\n          \"total_tokens\": 1437,\n          \"cached_tokens\": 0\n        }\n      ],\n      \"per_testing_criteria_results\": [\n        {\n          \"testing_criteria\": \"Push Notification Summary Grader-1808cd0b-eeec-4e0b-a519-337e79f4f5d1\",\n          \"passed\": 1,\n          \"failed\": 0\n        }\n      ],\n      \"data_source\": {\n        \"type\": \"completions\",\n        \"source\": {\n          \"type\": \"file_content\",\n          \"content\": [\n            {\n              \"item\": {\n                \"notifications\": \"\\n- New message from Sarah: \\\"Can you call me later?\\\"\\n- Your package has been d", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 143400, "end_char": 144000}, "288": {"text": " \"notifications\": \"\\n- New message from Sarah: \\\"Can you call me later?\\\"\\n- Your package has been delivered!\\n- Flash sale: 20% off electronics for the next 2 hours!\\n\"\n              }\n            }\n          ]\n        },\n        \"input_messages\": {\n          \"type\": \"template\",\n          \"template\": [\n            {\n              \"type\": \"message\",\n              \"role\": \"developer\",\n              \"content\": {\n                \"type\": \"input_text\",\n                \"text\": \"\\n\\n\\n\\nYou are a helpful assistant that takes in an array of push notifications and returns a collapsed summary of them.\\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 143900, "end_char": 144500}, "289": {"text": "ul assistant that takes in an array of push notifications and returns a collapsed summary of them.\\nThe push notification will be provided as follows:\\n<push_notifications>\\n...notificationlist...\\n</push_notifications>\\n\\nYou should return just the summary and nothing else.\\n\\n\\nYou should return a summary that is concise and snappy.\\n\\n\\nHere is an example of a good summary:\\n<push_notifications>\\n- Traffic alert: Accident reported on Main Street.- Package out for delivery: Expected by 5 PM.- New friend suggestion: Connect with Emma.\\n</push_notifications>\\n<summary>\\nTraffic alert, package ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 144400, "end_char": 145000}, "290": {"text": "New friend suggestion: Connect with Emma.\\n</push_notifications>\\n<summary>\\nTraffic alert, package expected by 5pm, suggestion for new friend (Emily).\\n</summary>\\n\\n\\nHere is an example of a bad summary:\\n<push_notifications>\\n- Traffic alert: Accident reported on Main Street.- Package out for delivery: Expected by 5 PM.- New friend suggestion: Connect with Emma.\\n</push_notifications>\\n<summary>\\nTraffic alert reported on main street. You have a package that will arrive by 5pm, Emily is a new friend suggested for you.\\n</summary>\\n\"\n              }\n            },\n            {\n             ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 144900, "end_char": 145500}, "291": {"text": " friend suggested for you.\\n</summary>\\n\"\n              }\n            },\n            {\n              \"type\": \"message\",\n              \"role\": \"user\",\n              \"content\": {\n                \"type\": \"input_text\",\n                \"text\": \"<push_notifications>{{item.notifications}}</push_notifications>\"\n              }\n            }\n          ]\n        },\n        \"model\": \"o3-mini\",\n        \"sampling_params\": null\n      },\n      \"error\": null,\n      \"metadata\": {}\n    }\n  ],\n  \"first_id\": \"evalrun_67e0c7d31560819090d60c0780591042\",\n  \"last_id\": \"evalrun_67e0c7d31560819090d60c0780591042\",\n  \"ha", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 145400, "end_char": 146000}, "292": {"text": "un_67e0c7d31560819090d60c0780591042\",\n  \"last_id\": \"evalrun_67e0c7d31560819090d60c0780591042\",\n  \"has_more\": true\n}\nGet an eval run\nget\n \nhttps://api.openai.com/v1/evals/{eval_id}/runs/{run_id}\nGet an evaluation run by ID.\n\nPath parameters\neval_id\nstring\n\nRequired\nThe ID of the evaluation to retrieve runs for.\n\nrun_id\nstring\n\nRequired\nThe ID of the run to retrieve.\n\nReturns\nThe EvalRun object matching the specified ID.\n\nExample request\ncurl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7 \\\n  -H \"Authorization: Bearer $OPENAI_A", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 145900, "end_char": 146500}, "293": {"text": "86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n  \"object\": \"eval.run\",\n  \"id\": \"evalrun_67abd54d60ec8190832b46859da808f7\",\n  \"eval_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"report_url\": \"https://platform.openai.com/evaluations/eval_67abd54d9b0081909a86353f6fb9317a?run_id=evalrun_67abd54d60ec8190832b46859da808f7\",\n  \"status\": \"queued\",\n  \"model\": \"gpt-4o-mini\",\n  \"name\": \"gpt-4o-mini\",\n  \"created_at\": 1743092069,\n  \"result_counts\": {\n    \"total\": 0,\n    \"errored\": 0,\n    \"faile", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 146400, "end_char": 147000}, "294": {"text": "mini\",\n  \"created_at\": 1743092069,\n  \"result_counts\": {\n    \"total\": 0,\n    \"errored\": 0,\n    \"failed\": 0,\n    \"passed\": 0\n  },\n  \"per_model_usage\": null,\n  \"per_testing_criteria_results\": null,\n  \"data_source\": {\n    \"type\": \"completions\",\n    \"source\": {\n      \"type\": \"file_content\",\n      \"content\": [\n        {\n          \"item\": {\n            \"input\": \"Tech Company Launches Advanced Artificial Intelligence Platform\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Central Bank Increases Interest Rates Amid Inflation Concern", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 146900, "end_char": 147500}, "295": {"text": "        \"item\": {\n            \"input\": \"Central Bank Increases Interest Rates Amid Inflation Concerns\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"International Summit Addresses Climate Change Strategies\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Major Retailer Reports Record-Breaking Holiday Sales\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"National Team Qualifies for World Championsh", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 147400, "end_char": 148000}, "296": {"text": " },\n        {\n          \"item\": {\n            \"input\": \"National Team Qualifies for World Championship Finals\",\n            \"ground_truth\": \"Sports\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Stock Markets Rally After Positive Economic Data Released\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Global Manufacturer Announces Merger with Competitor\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Breakthrough in Renewable Energy T", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 147900, "end_char": 148500}, "297": {"text": " }\n        },\n        {\n          \"item\": {\n            \"input\": \"Breakthrough in Renewable Energy Technology Unveiled\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"World Leaders Sign Historic Climate Agreement\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Professional Athlete Sets New Record in Championship Event\",\n            \"ground_truth\": \"Sports\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Financial Institutions Adapt to", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 148400, "end_char": 149000}, "298": {"text": "    }\n        },\n        {\n          \"item\": {\n            \"input\": \"Financial Institutions Adapt to New Regulatory Requirements\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Tech Conference Showcases Advances in Artificial Intelligence\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Global Markets Respond to Oil Price Fluctuations\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Internation", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 148900, "end_char": 149500}, "299": {"text": "h\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"International Cooperation Strengthened Through New Treaty\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Sports League Announces Revised Schedule for Upcoming Season\",\n            \"ground_truth\": \"Sports\"\n          }\n        }\n      ]\n    },\n    \"input_messages\": {\n      \"type\": \"template\",\n      \"template\": [\n        {\n          \"type\": \"message\",\n          \"role\": \"developer\",\n          \"content\": {\n            \"type\": \"input_text\",\n      ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 149400, "end_char": 150000}, "300": {"text": "age\",\n          \"role\": \"developer\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key indicators or keywords.\\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 149900, "end_char": 150500}, "301": {"text": "hnology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output Format\\n\\nRespond with the chosen category as a single word. For instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Technology\\\"\\n\\n**Input**: \\\"Global Stocks Mixed as Investors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 150400, "end_char": 151000}, "302": {"text": "*: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in Talks to Acquire Gaming Company for $2 Billion\\\"  \\n**Output**: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category, choose the most dominant theme.\\n- Keywords or phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good indicators for classification.\\n\"\n          }\n        },\n        {\n          \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 150900, "end_char": 151500}, "303": {"text": "al brands can be good indicators for classification.\\n\"\n          }\n        },\n        {\n          \"type\": \"message\",\n          \"role\": \"user\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"{{item.input}}\"\n          }\n        }\n      ]\n    },\n    \"model\": \"gpt-4o-mini\",\n    \"sampling_params\": {\n      \"seed\": 42,\n      \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_completions_tokens\": 2048\n    }\n  },\n  \"error\": null,\n  \"metadata\": {}\n}\nCreate eval run\npost\n \nhttps://api.openai.com/v1/evals/{eval_id}/runs\nCreate a new evaluation run. This is the endpoint that", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 151400, "end_char": 152000}, "304": {"text": "ttps://api.openai.com/v1/evals/{eval_id}/runs\nCreate a new evaluation run. This is the endpoint that will kick off grading.\n\nPath parameters\neval_id\nstring\n\nRequired\nThe ID of the evaluation to create a run for.\n\nRequest body\ndata_source\nobject\n\nRequired\nDetails about the run's data source.\n\n\nShow possible types\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 151900, "end_char": 152500}, "305": {"text": "rying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nname\nstring\n\nOptional\nThe name of the run.\n\nReturns\nThe EvalRun object matching the specified ID.\n\nExample request\ncurl https://api.openai.com/v1/evals/eval_67e579652b548190aaa83ada4b125f47/runs \\\n  -X POST \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\":\"gpt-4o-mini\",\"data_source\":{\"type\":\"completions\",\"input_messages\":{\"type\":\"template\",\"template\":[{\"role\":\"developer\",\"content\"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 152400, "end_char": 153000}, "306": {"text": ":{\"type\":\"completions\",\"input_messages\":{\"type\":\"template\",\"template\":[{\"role\":\"developer\",\"content\":\"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key indicators or keywords.\\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 152900, "end_char": 153500}, "307": {"text": "ets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output Format\\n\\nRespond with the chosen category as a single word. For instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Technology\\\"\\n\\n**Input**: \\\"Global Stocks Mixed as Investors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 153400, "end_char": 154000}, "308": {"text": "kraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in Talks to Acquire Gaming Company for $2 Billion\\\"  \\n**Output**: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category, choose the most dominant theme.\\n- Keywords or phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good indicators for classification.\\n\"} , {\"role\":\"user\",\"content\":\"{{item.input}}\"}]},\"sampling", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 153900, "end_char": 154500}, "309": {"text": " be good indicators for classification.\\n\"} , {\"role\":\"user\",\"content\":\"{{item.input}}\"}]},\"sampling_params\":{\"temperature\":1,\"max_completions_tokens\":2048,\"top_p\":1,\"seed\":42},\"model\":\"gpt-4o-mini\",\"source\":{\"type\":\"file_content\",\"content\":[{\"item\":{\"input\":\"Tech Company Launches Advanced Artificial Intelligence Platform\",\"ground_truth\":\"Technology\"}}]}}'\nResponse\n{\n  \"object\": \"eval.run\",\n  \"id\": \"evalrun_67e57965b480819094274e3a32235e4c\",\n  \"eval_id\": \"eval_67e579652b548190aaa83ada4b125f47\",\n  \"report_url\": \"https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47&run_i", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 154400, "end_char": 155000}, "310": {"text": "  \"report_url\": \"https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47&run_id=evalrun_67e57965b480819094274e3a32235e4c\",\n  \"status\": \"queued\",\n  \"model\": \"gpt-4o-mini\",\n  \"name\": \"gpt-4o-mini\",\n  \"created_at\": 1743092069,\n  \"result_counts\": {\n    \"total\": 0,\n    \"errored\": 0,\n    \"failed\": 0,\n    \"passed\": 0\n  },\n  \"per_model_usage\": null,\n  \"per_testing_criteria_results\": null,\n  \"data_source\": {\n    \"type\": \"completions\",\n    \"source\": {\n      \"type\": \"file_content\",\n      \"content\": [\n        {\n          \"item\": {\n            \"input\": \"Tech Company Launches Advanced ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 154900, "end_char": 155500}, "311": {"text": "    \"content\": [\n        {\n          \"item\": {\n            \"input\": \"Tech Company Launches Advanced Artificial Intelligence Platform\",\n            \"ground_truth\": \"Technology\"\n          }\n        }\n      ]\n    },\n    \"input_messages\": {\n      \"type\": \"template\",\n      \"template\": [\n        {\n          \"type\": \"message\",\n          \"role\": \"developer\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news head", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 155400, "end_char": 156000}, "312": {"text": "chnology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key indicators or keywords.\\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output Format\\n\\nRespond with the chosen category as a single word. For instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**:", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 155900, "end_char": 156500}, "313": {"text": "ce: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Technology\\\"\\n\\n**Input**: \\\"Global Stocks Mixed as Investors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in Talks to Acquire Gaming Company for $2 Billion\\\"  \\n**Output**: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output*", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 156400, "end_char": 157000}, "314": {"text": "ness\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category, choose the most dominant theme.\\n- Keywords or phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good indicators for classification.\\n\"\n          }\n        },\n        {\n          \"type\": \"message\",\n          \"role\": \"user\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"{{item.input}}\"\n          }\n        }\n      ]\n    },\n    \"mode", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 156900, "end_char": 157500}, "315": {"text": "\": \"input_text\",\n            \"text\": \"{{item.input}}\"\n          }\n        }\n      ]\n    },\n    \"model\": \"gpt-4o-mini\",\n    \"sampling_params\": {\n      \"seed\": 42,\n      \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_completions_tokens\": 2048\n    }\n  },\n  \"error\": null,\n  \"metadata\": {}\n}\nCancel eval run\npost\n \nhttps://api.openai.com/v1/evals/{eval_id}/runs/{run_id}\nCancel an ongoing evaluation run.\n\nPath parameters\neval_id\nstring\n\nRequired\nThe ID of the evaluation whose run you want to cancel.\n\nrun_id\nstring\n\nRequired\nThe ID of the run to cancel.\n\nReturns\nThe updated EvalRun object reflecti", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 157400, "end_char": 158000}, "316": {"text": ".\n\nrun_id\nstring\n\nRequired\nThe ID of the run to cancel.\n\nReturns\nThe updated EvalRun object reflecting that the run is canceled.\n\nExample request\ncurl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7/cancel \\\n  -X POST \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n  \"object\": \"eval.run\",\n  \"id\": \"evalrun_67abd54d60ec8190832b46859da808f7\",\n  \"eval_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"report_url\": \"https://platform.openai.com/evaluations/eval_67abd54d9b0081909a86353f", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 157900, "end_char": 158500}, "317": {"text": "53f6fb9317a\",\n  \"report_url\": \"https://platform.openai.com/evaluations/eval_67abd54d9b0081909a86353f6fb9317a?run_id=evalrun_67abd54d60ec8190832b46859da808f7\",\n  \"status\": \"canceled\",\n  \"model\": \"gpt-4o-mini\",\n  \"name\": \"gpt-4o-mini\",\n  \"created_at\": 1743092069,\n  \"result_counts\": {\n    \"total\": 0,\n    \"errored\": 0,\n    \"failed\": 0,\n    \"passed\": 0\n  },\n  \"per_model_usage\": null,\n  \"per_testing_criteria_results\": null,\n  \"data_source\": {\n    \"type\": \"completions\",\n    \"source\": {\n      \"type\": \"file_content\",\n      \"content\": [\n        {\n          \"item\": {\n            \"input\": \"Tech Company La", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 158400, "end_char": 159000}, "318": {"text": "ile_content\",\n      \"content\": [\n        {\n          \"item\": {\n            \"input\": \"Tech Company Launches Advanced Artificial Intelligence Platform\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Central Bank Increases Interest Rates Amid Inflation Concerns\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"International Summit Addresses Climate Change Strategies\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n        ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 158900, "end_char": 159500}, "319": {"text": "\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Major Retailer Reports Record-Breaking Holiday Sales\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"National Team Qualifies for World Championship Finals\",\n            \"ground_truth\": \"Sports\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Stock Markets Rally After Positive Economic Data Released\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 159400, "end_char": 160000}, "320": {"text": "Released\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Global Manufacturer Announces Merger with Competitor\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Breakthrough in Renewable Energy Technology Unveiled\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"World Leaders Sign Historic Climate Agreement\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 159900, "end_char": 160500}, "321": {"text": "Agreement\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Professional Athlete Sets New Record in Championship Event\",\n            \"ground_truth\": \"Sports\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Financial Institutions Adapt to New Regulatory Requirements\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Tech Conference Showcases Advances in Artificial Intelligence\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 160400, "end_char": 161000}, "322": {"text": "vances in Artificial Intelligence\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Global Markets Respond to Oil Price Fluctuations\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"International Cooperation Strengthened Through New Treaty\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Sports League Announces Revised Schedule for Upcoming Season\",\n            \"ground_truth\": \"Sports\"\n          }\n ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 160900, "end_char": 161500}, "323": {"text": " Announces Revised Schedule for Upcoming Season\",\n            \"ground_truth\": \"Sports\"\n          }\n        }\n      ]\n    },\n    \"input_messages\": {\n      \"type\": \"template\",\n      \"template\": [\n        {\n          \"type\": \"message\",\n          \"role\": \"developer\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 161400, "end_char": 162000}, "324": {"text": "e news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key indicators or keywords.\\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output Format\\n\\nRespond with the chosen category as a single word. For instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Tech", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 161900, "end_char": 162500}, "325": {"text": "n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Technology\\\"\\n\\n**Input**: \\\"Global Stocks Mixed as Investors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in Talks to Acquire Gaming Company for $2 Billion\\\"  \\n**Output**: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 162400, "end_char": 163000}, "326": {"text": "\\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category, choose the most dominant theme.\\n- Keywords or phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good indicators for classification.\\n\"\n          }\n        },\n        {\n          \"type\": \"message\",\n          \"role\": \"user\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"{{item.input}}\"\n          }\n        }\n      ]\n    },\n    \"model\": \"gpt-4o-mini\",\n    \"sampling_params\": {\n      \"seed\": 42,\n      \"temperature\": 1.0,\n ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 162900, "end_char": 163500}, "327": {"text": ",\n    \"model\": \"gpt-4o-mini\",\n    \"sampling_params\": {\n      \"seed\": 42,\n      \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_completions_tokens\": 2048\n    }\n  },\n  \"error\": null,\n  \"metadata\": {}\n}\nDelete eval run\ndelete\n \nhttps://api.openai.com/v1/evals/{eval_id}/runs/{run_id}\nDelete an eval run.\n\nPath parameters\neval_id\nstring\n\nRequired\nThe ID of the evaluation to delete the run from.\n\nrun_id\nstring\n\nRequired\nThe ID of the run to delete.\n\nReturns\nAn object containing the status of the delete operation.\n\nExample request\ncurl https://api.openai.com/v1/evals/eval_123abc/runs/evalrun_abc456", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 163400, "end_char": 164000}, "328": {"text": "ete operation.\n\nExample request\ncurl https://api.openai.com/v1/evals/eval_123abc/runs/evalrun_abc456 \\\n  -X DELETE \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n  \"object\": \"eval.run.deleted\",\n  \"deleted\": true,\n  \"run_id\": \"evalrun_abc456\"\n}\nGet an output item of an eval run\nget\n \nhttps://api.openai.com/v1/evals/{eval_id}/runs/{run_id}/output_items/{output_item_id}\nGet an evaluation run output item by ID.\n\nPath parameters\neval_id\nstring\n\nRequired\nThe ID of the evaluation to retrieve runs for.\n\noutput_item_id\nstring\n\nRequired\nThe ID of the ou", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 163900, "end_char": 164500}, "329": {"text": "red\nThe ID of the evaluation to retrieve runs for.\n\noutput_item_id\nstring\n\nRequired\nThe ID of the output item to retrieve.\n\nrun_id\nstring\n\nRequired\nThe ID of the run to retrieve.\n\nReturns\nThe EvalRunOutputItem object matching the specified ID.\n\nExample request\ncurl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7/output_items/outputitem_67abd55eb6548190bb580745d5644a33 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n  \"object\": \"eval.run.output_item\",\n  \"id\": \"outputitem_67e5796", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 164400, "end_char": 165000}, "330": {"text": "t-Type: application/json\"\nResponse\n{\n  \"object\": \"eval.run.output_item\",\n  \"id\": \"outputitem_67e5796c28e081909917bf79f6e6214d\",\n  \"created_at\": 1743092076,\n  \"run_id\": \"evalrun_67abd54d60ec8190832b46859da808f7\",\n  \"eval_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"status\": \"pass\",\n  \"datasource_item_id\": 5,\n  \"datasource_item\": {\n    \"input\": \"Stock Markets Rally After Positive Economic Data Released\",\n    \"ground_truth\": \"Markets\"\n  },\n  \"results\": [\n    {\n      \"name\": \"String check-a2486074-d803-4445-b431-ad2262e85d47\",\n      \"sample\": null,\n      \"passed\": true,\n      \"score\": 1.0\n    ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 164900, "end_char": 165500}, "331": {"text": "74-d803-4445-b431-ad2262e85d47\",\n      \"sample\": null,\n      \"passed\": true,\n      \"score\": 1.0\n    }\n  ],\n  \"sample\": {\n    \"input\": [\n      {\n        \"role\": \"developer\",\n        \"content\": \"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key indicators or keywords.\\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, Worl", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 165400, "end_char": 166000}, "332": {"text": "ndicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output Format\\n\\nRespond with the chosen category as a single word. For instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Technology\\\"\\n\\n**Input**: \\\"Global Stocks Mixed as Investors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: L", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 165900, "end_char": 166500}, "333": {"text": "nvestors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in Talks to Acquire Gaming Company for $2 Billion\\\"  \\n**Output**: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category, choose the most dominant theme.\\n- Keywords or phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 166400, "end_char": 167000}, "334": {"text": "phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good indicators for classification.\\n\",\n        \"tool_call_id\": null,\n        \"tool_calls\": null,\n        \"function_call\": null\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"Stock Markets Rally After Positive Economic Data Released\",\n        \"tool_call_id\": null,\n        \"tool_calls\": null,\n        \"function_call\": null\n      }\n    ],\n    \"output\": [\n      {\n        \"role\": \"assistant\",\n        \"content\": \"Markets\",\n        \"tool_call_id\": null,\n        \"tool_calls\": null,\n        \"fun", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 166900, "end_char": 167500}, "335": {"text": "        \"content\": \"Markets\",\n        \"tool_call_id\": null,\n        \"tool_calls\": null,\n        \"function_call\": null\n      }\n    ],\n    \"finish_reason\": \"stop\",\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"usage\": {\n      \"total_tokens\": 325,\n      \"completion_tokens\": 2,\n      \"prompt_tokens\": 323,\n      \"cached_tokens\": 0\n    },\n    \"error\": null,\n    \"temperature\": 1.0,\n    \"max_completion_tokens\": 2048,\n    \"top_p\": 1.0,\n    \"seed\": 42\n  }\n}\nGet eval run output items\nget\n \nhttps://api.openai.com/v1/evals/{eval_id}/runs/{run_id}/output_items\nGet a list of output items for an evaluation run.", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 167400, "end_char": 168000}, "336": {"text": ".com/v1/evals/{eval_id}/runs/{run_id}/output_items\nGet a list of output items for an evaluation run.\n\nPath parameters\neval_id\nstring\n\nRequired\nThe ID of the evaluation to retrieve runs for.\n\nrun_id\nstring\n\nRequired\nThe ID of the run to retrieve output items for.\n\nQuery parameters\nafter\nstring\n\nOptional\nIdentifier for the last output item from the previous pagination request.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nNumber of output items to retrieve.\n\norder\nstring\n\nOptional\nDefaults to asc\nSort order for output items by timestamp. Use asc for ascending order or desc for descending order. Defaul", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 167900, "end_char": 168500}, "337": {"text": "rder for output items by timestamp. Use asc for ascending order or desc for descending order. Defaults to asc.\n\nstatus\nstring\n\nOptional\nFilter output items by status. Use failed to filter by failed output items or pass to filter by passed output items.\n\nReturns\nA list of EvalRunOutputItem objects matching the specified ID.\n\nExample request\ncurl https://api.openai.com/v1/evals/egroup_67abd54d9b0081909a86353f6fb9317a/runs/erun_67abd54d60ec8190832b46859da808f7/output_items \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n  \"object\": \"list\",\n  \"data", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 168400, "end_char": 169000}, "338": {"text": "arer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"eval.run.output_item\",\n      \"id\": \"outputitem_67e5796c28e081909917bf79f6e6214d\",\n      \"created_at\": 1743092076,\n      \"run_id\": \"evalrun_67abd54d60ec8190832b46859da808f7\",\n      \"eval_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n      \"status\": \"pass\",\n      \"datasource_item_id\": 5,\n      \"datasource_item\": {\n        \"input\": \"Stock Markets Rally After Positive Economic Data Released\",\n        \"ground_truth\": \"Markets\"\n      },\n      \"results\": [\n        {\n        ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 168900, "end_char": 169500}, "339": {"text": "mic Data Released\",\n        \"ground_truth\": \"Markets\"\n      },\n      \"results\": [\n        {\n          \"name\": \"String check-a2486074-d803-4445-b431-ad2262e85d47\",\n          \"sample\": null,\n          \"passed\": true,\n          \"score\": 1.0\n        }\n      ],\n      \"sample\": {\n        \"input\": [\n          {\n            \"role\": \"developer\",\n            \"content\": \"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 169400, "end_char": 170000}, "340": {"text": "yze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key indicators or keywords.\\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output Format\\n\\nRespond with the chosen category as a single word. For instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\" ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 169900, "end_char": 170500}, "341": {"text": "s\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Technology\\\"\\n\\n**Input**: \\\"Global Stocks Mixed as Investors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in Talks to Acquire Gaming Company for $2 Billion\\\"  \\n**Output**: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into m", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 170400, "end_char": 171000}, "342": {"text": "ue Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category, choose the most dominant theme.\\n- Keywords or phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good indicators for classification.\\n\",\n            \"tool_call_id\": null,\n            \"tool_calls\": null,\n            \"function_call\": null\n          },\n          {\n            \"role\": \"user\",\n            \"content\": \"Stock Markets Rally After Positive Economic Data Released\",\n            \"tool_call_id\": null,\n            \"tool_calls\"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 170900, "end_char": 171500}, "343": {"text": "y After Positive Economic Data Released\",\n            \"tool_call_id\": null,\n            \"tool_calls\": null,\n            \"function_call\": null\n          }\n        ],\n        \"output\": [\n          {\n            \"role\": \"assistant\",\n            \"content\": \"Markets\",\n            \"tool_call_id\": null,\n            \"tool_calls\": null,\n            \"function_call\": null\n          }\n        ],\n        \"finish_reason\": \"stop\",\n        \"model\": \"gpt-4o-mini-2024-07-18\",\n        \"usage\": {\n          \"total_tokens\": 325,\n          \"completion_tokens\": 2,\n          \"prompt_tokens\": 323,\n          \"cached_tok", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 171400, "end_char": 172000}, "344": {"text": "okens\": 325,\n          \"completion_tokens\": 2,\n          \"prompt_tokens\": 323,\n          \"cached_tokens\": 0\n        },\n        \"error\": null,\n        \"temperature\": 1.0,\n        \"max_completion_tokens\": 2048,\n        \"top_p\": 1.0,\n        \"seed\": 42\n      }\n    }\n  ],\n  \"first_id\": \"outputitem_67e5796c28e081909917bf79f6e6214d\",\n  \"last_id\": \"outputitem_67e5796c28e081909917bf79f6e6214d\",\n  \"has_more\": true\n}\nThe eval object\nAn Eval object with a data source config and testing criteria. An Eval represents a task to be done for your LLM integration. Like:\n\nImprove the quality of my chatbot\nSee ho", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 171900, "end_char": 172500}, "345": {"text": "presents a task to be done for your LLM integration. Like:\n\nImprove the quality of my chatbot\nSee how well my chatbot handles customer support\nCheck if o3-mini is better at my usecase than gpt-4o\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the eval was created.\n\ndata_source_config\nobject\n\nConfiguration of data sources used in runs of the evaluation.\n\n\nShow possible types\nid\nstring\n\nUnique identifier for the evaluation.\n\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structur", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 172400, "end_char": 173000}, "346": {"text": "d to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nname\nstring\n\nThe name of the evaluation.\n\nobject\nstring\n\nThe object type.\n\ntesting_criteria\narray\n\nA list of testing criteria.\n\n\nShow possible types\nOBJECT The eval object\n{\n  \"object\": \"eval\",\n  \"id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"data_source_config\": {\n    \"type\": \"custom\",\n    \"item_schema\": {\n      \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 172900, "end_char": 173500}, "347": {"text": "081909a86353f6fb9317a\",\n  \"data_source_config\": {\n    \"type\": \"custom\",\n    \"item_schema\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"label\": {\"type\": \"string\"},\n      },\n      \"required\": [\"label\"]\n    },\n    \"include_sample_schema\": true\n  },\n  \"testing_criteria\": [\n    {\n      \"name\": \"My string check grader\",\n      \"type\": \"string_check\",\n      \"input\": \"{{sample.output_text}}\",\n      \"reference\": \"{{item.label}}\",\n      \"operation\": \"eq\",\n    }\n  ],\n  \"name\": \"External Data Eval\",\n  \"created_at\": 1739314509,\n  \"metadata\": {\n    \"test\": \"synthetics\",\n  }\n}\nThe eval run object", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 173400, "end_char": 174000}, "348": {"text": "al\",\n  \"created_at\": 1739314509,\n  \"metadata\": {\n    \"test\": \"synthetics\",\n  }\n}\nThe eval run object\nA schema representing an evaluation run.\n\ncreated_at\ninteger\n\nUnix timestamp (in seconds) when the evaluation run was created.\n\ndata_source\nobject\n\nInformation about the run's data source.\n\nerror\nobject\n\nAn object representing an error response from the Eval API.\n\n\nShow properties\neval_id\nstring\n\nThe identifier of the associated evaluation.\n\nid\nstring\n\nUnique identifier for the evaluation run.\n\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for sto", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 173900, "end_char": 174500}, "349": {"text": "etadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nmodel\nstring\n\nThe model that is evaluated, if applicable.\n\nname\nstring\n\nThe name of the evaluation run.\n\nobject\nstring\n\nThe type of the object. Always \"eval.run\".\n\nper_model_usage\narray\n\nUsage statistics for each model during the evaluation run.\n\n\nShow properti", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 174400, "end_char": 175000}, "350": {"text": ".\n\nper_model_usage\narray\n\nUsage statistics for each model during the evaluation run.\n\n\nShow properties\nper_testing_criteria_results\narray\n\nResults per testing criteria applied during the evaluation run.\n\n\nShow properties\nreport_url\nstring\n\nThe URL to the rendered evaluation run report on the UI dashboard.\n\nresult_counts\nobject\n\nCounters summarizing the outcomes of the evaluation run.\n\n\nShow properties\nstatus\nstring\n\nThe status of the evaluation run.\n\nOBJECT The eval run object\n{\n  \"object\": \"eval.run\",\n  \"id\": \"evalrun_67e57965b480819094274e3a32235e4c\",\n  \"eval_id\": \"eval_67e579652b548190aaa83", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 174900, "end_char": 175500}, "351": {"text": "l.run\",\n  \"id\": \"evalrun_67e57965b480819094274e3a32235e4c\",\n  \"eval_id\": \"eval_67e579652b548190aaa83ada4b125f47\",\n  \"report_url\": \"https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47?run_id=evalrun_67e57965b480819094274e3a32235e4c\",\n  \"status\": \"queued\",\n  \"model\": \"gpt-4o-mini\",\n  \"name\": \"gpt-4o-mini\",\n  \"created_at\": 1743092069,\n  \"result_counts\": {\n    \"total\": 0,\n    \"errored\": 0,\n    \"failed\": 0,\n    \"passed\": 0\n  },\n  \"per_model_usage\": null,\n  \"per_testing_criteria_results\": null,\n  \"data_source\": {\n    \"type\": \"completions\",\n    \"source\": {\n      \"type\": \"fil", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 175400, "end_char": 176000}, "352": {"text": "ria_results\": null,\n  \"data_source\": {\n    \"type\": \"completions\",\n    \"source\": {\n      \"type\": \"file_content\",\n      \"content\": [\n        {\n          \"item\": {\n            \"input\": \"Tech Company Launches Advanced Artificial Intelligence Platform\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Central Bank Increases Interest Rates Amid Inflation Concerns\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"International Summit Addresses Climate Change Strategies\",", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 175900, "end_char": 176500}, "353": {"text": "          \"item\": {\n            \"input\": \"International Summit Addresses Climate Change Strategies\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Major Retailer Reports Record-Breaking Holiday Sales\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"National Team Qualifies for World Championship Finals\",\n            \"ground_truth\": \"Sports\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Stock Markets Rally After Positive Economic Data Re", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 176400, "end_char": 177000}, "354": {"text": "     {\n          \"item\": {\n            \"input\": \"Stock Markets Rally After Positive Economic Data Released\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Global Manufacturer Announces Merger with Competitor\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Breakthrough in Renewable Energy Technology Unveiled\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"World Leaders Sign Historic Climate Ag", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 176900, "end_char": 177500}, "355": {"text": "       },\n        {\n          \"item\": {\n            \"input\": \"World Leaders Sign Historic Climate Agreement\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Professional Athlete Sets New Record in Championship Event\",\n            \"ground_truth\": \"Sports\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Financial Institutions Adapt to New Regulatory Requirements\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Tech Conference Showcases Adva", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 177400, "end_char": 178000}, "356": {"text": "     }\n        },\n        {\n          \"item\": {\n            \"input\": \"Tech Conference Showcases Advances in Artificial Intelligence\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Global Markets Respond to Oil Price Fluctuations\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"International Cooperation Strengthened Through New Treaty\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Sports League A", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 177900, "end_char": 178500}, "357": {"text": ": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Sports League Announces Revised Schedule for Upcoming Season\",\n            \"ground_truth\": \"Sports\"\n          }\n        }\n      ]\n    },\n    \"input_messages\": {\n      \"type\": \"template\",\n      \"template\": [\n        {\n          \"type\": \"message\",\n          \"role\": \"developer\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 178400, "end_char": 179000}, "358": {"text": "opics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key indicators or keywords.\\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output Format\\n\\nRespond with the chosen category as a single word. For instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n*", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 178900, "end_char": 179500}, "359": {"text": "or instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Technology\\\"\\n\\n**Input**: \\\"Global Stocks Mixed as Investors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in Talks to Acquire Gaming Company for $2 Billion\\\"  \\n**Output**: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 179400, "end_char": 180000}, "360": {"text": "*: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category, choose the most dominant theme.\\n- Keywords or phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good indicators for classification.\\n\"\n          }\n        },\n        {\n          \"type\": \"message\",\n          \"role\": \"user\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"{{item.input}}\"\n          }\n        }\n      ]\n    },\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 179900, "end_char": 180500}, "361": {"text": "    \"type\": \"input_text\",\n            \"text\": \"{{item.input}}\"\n          }\n        }\n      ]\n    },\n    \"model\": \"gpt-4o-mini\",\n    \"sampling_params\": {\n      \"seed\": 42,\n      \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_completions_tokens\": 2048\n    }\n  },\n  \"error\": null,\n  \"metadata\": {}\n}\nThe eval run output item object\nA schema representing an evaluation run output item.\n\ncreated_at\ninteger\n\nUnix timestamp (in seconds) when the evaluation run was created.\n\ndatasource_item\nobject\n\nDetails of the input data source item.\n\ndatasource_item_id\ninteger\n\nThe identifier for the data source ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 180400, "end_char": 181000}, "362": {"text": "ails of the input data source item.\n\ndatasource_item_id\ninteger\n\nThe identifier for the data source item.\n\neval_id\nstring\n\nThe identifier of the evaluation group.\n\nid\nstring\n\nUnique identifier for the evaluation run output item.\n\nobject\nstring\n\nThe type of the object. Always \"eval.run.output_item\".\n\nresults\narray\n\nA list of results from the evaluation run.\n\n\nShow properties\nrun_id\nstring\n\nThe identifier of the evaluation run associated with this output item.\n\nsample\nobject\n\nA sample containing the input and output of the evaluation run.\n\n\nShow properties\nstatus\nstring\n\nThe status of the evalua", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 180900, "end_char": 181500}, "363": {"text": "he input and output of the evaluation run.\n\n\nShow properties\nstatus\nstring\n\nThe status of the evaluation run.\n\nOBJECT The eval run output item object\n{\n  \"object\": \"eval.run.output_item\",\n  \"id\": \"outputitem_67abd55eb6548190bb580745d5644a33\",\n  \"run_id\": \"evalrun_67abd54d60ec8190832b46859da808f7\",\n  \"eval_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"created_at\": 1739314509,\n  \"status\": \"pass\",\n  \"datasource_item_id\": 137,\n  \"datasource_item\": {\n      \"teacher\": \"To grade essays, I only check for style, content, and grammar.\",\n      \"student\": \"I am a student who is trying to write the best", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 181400, "end_char": 182000}, "364": {"text": " for style, content, and grammar.\",\n      \"student\": \"I am a student who is trying to write the best essay.\"\n  },\n  \"results\": [\n    {\n      \"name\": \"String Check Grader\",\n      \"type\": \"string-check-grader\",\n      \"score\": 1.0,\n      \"passed\": true,\n    }\n  ],\n  \"sample\": {\n    \"input\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are an evaluator bot...\"\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"You are assessing...\"\n      }\n    ],\n    \"output\": [\n      {\n        \"role\": \"assistant\",\n        \"content\": \"The rubric is not clear nor concise.\"\n      }\n    ],\n  ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 181900, "end_char": 182500}, "365": {"text": "    \"role\": \"assistant\",\n        \"content\": \"The rubric is not clear nor concise.\"\n      }\n    ],\n    \"finish_reason\": \"stop\",\n    \"model\": \"gpt-4o-2024-08-06\",\n    \"usage\": {\n      \"total_tokens\": 521,\n      \"completion_tokens\": 2,\n      \"prompt_tokens\": 519,\n      \"cached_tokens\": 0\n    },\n    \"error\": null,\n    \"temperature\": 1.0,\n    \"max_completion_tokens\": 2048,\n    \"top_p\": 1.0,\n    \"seed\": 42\n  }\n}\nFine-tuning\nManage fine-tuning jobs to tailor a model to your specific training data. Related guide: Fine-tune models\n\nCreate fine-tuning job\npost\n \nhttps://api.openai.com/v1/fine_tuning/job", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 182400, "end_char": 183000}, "366": {"text": "ted guide: Fine-tune models\n\nCreate fine-tuning job\npost\n \nhttps://api.openai.com/v1/fine_tuning/jobs\nCreates a fine-tuning job which begins the process of creating a new model from a given dataset.\n\nResponse includes details of the enqueued job including job status and the name of the fine-tuned models once complete.\n\nLearn more about fine-tuning\n\nRequest body\nmodel\nstring\n\nRequired\nThe name of the model to fine-tune. You can select one of the supported models.\n\ntraining_file\nstring\n\nRequired\nThe ID of an uploaded file that contains training data.\n\nSee upload file for how to upload a file.\n\nY", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 182900, "end_char": 183500}, "367": {"text": "he ID of an uploaded file that contains training data.\n\nSee upload file for how to upload a file.\n\nYour dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose fine-tune.\n\nThe contents of the file should differ depending on if the model uses the chat, completions format, or if the fine-tuning method uses the preference format.\n\nSee the fine-tuning guide for more details.\n\nhyperparameters\nDeprecated\nobject\n\nOptional\nThe hyperparameters used for the fine-tuning job. This value is now deprecated in favor of method, and should be passed in under the meth", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 183400, "end_char": 184000}, "368": {"text": "-tuning job. This value is now deprecated in favor of method, and should be passed in under the method parameter.\n\n\nShow properties\nintegrations\narray or null\n\nOptional\nA list of integrations to enable for your fine-tuning job.\n\n\nShow properties\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nmetho", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 183900, "end_char": 184500}, "369": {"text": " maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nmethod\nobject\n\nOptional\nThe method used for fine-tuning.\n\n\nShow properties\nseed\ninteger or null\n\nOptional\nThe seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases. If a seed is not specified, one will be generated for you.\n\nsuffix\nstring or null\n\nOptional\nDefaults to null\nA string of up to 64 characters that will be added to your fine-tuned model name.\n\nFor example, a suffix of \"custom-model-name\" would", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 184400, "end_char": 185000}, "370": {"text": "hat will be added to your fine-tuned model name.\n\nFor example, a suffix of \"custom-model-name\" would produce a model name like ft:gpt-4o-mini:openai:custom-model-name:7p4lURel.\n\nvalidation_file\nstring or null\n\nOptional\nThe ID of an uploaded file that contains validation data.\n\nIf you provide this file, the data is used to generate validation metrics periodically during fine-tuning. These metrics can be viewed in the fine-tuning results file. The same data should not be present in both train and validation files.\n\nYour dataset must be formatted as a JSONL file. You must upload your file with th", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 184900, "end_char": 185500}, "371": {"text": "validation files.\n\nYour dataset must be formatted as a JSONL file. You must upload your file with the purpose fine-tune.\n\nSee the fine-tuning guide for more details.\n\nReturns\nA fine-tuning.job object.\n\n\nDefault\n\nEpochs\n\nValidation file\n\nDPO\n\nW&B Integration\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.create(\n  training_file=\"file-abc123\",\n  model=\"gpt-4o-mini\"\n)\nResponse\n{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-4o-mini-2024-07-18\",\n  \"created_at\": 1721764800,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 185400, "end_char": 186000}, "372": {"text": "-07-18\",\n  \"created_at\": 1721764800,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"status\": \"queued\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n  \"method\": {\n    \"type\": \"supervised\",\n    \"supervised\": {\n      \"hyperparameters\": {\n        \"batch_size\": \"auto\",\n        \"learning_rate_multiplier\": \"auto\",\n        \"n_epochs\": \"auto\",\n      }\n    }\n  },\n  \"metadata\": null\n}\nList fine-tuning jobs\nget\n \nhttps://api.openai.com/v1/fine_tuning/jobs\nList your organization's fine-tuning jobs\n\nQuery parameters\nafter\nstring\n\nOptional\nIdentifier for ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 185900, "end_char": 186500}, "373": {"text": "s\nList your organization's fine-tuning jobs\n\nQuery parameters\nafter\nstring\n\nOptional\nIdentifier for the last job from the previous pagination request.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nNumber of fine-tuning jobs to retrieve.\n\nmetadata\nobject or null\n\nOptional\nOptional metadata filter. To filter, use the syntax metadata[k]=v. Alternatively, set metadata=null to indicate no metadata.\n\nReturns\nA list of paginated fine-tuning job objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.list()\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 186400, "end_char": 187000}, "374": {"text": "nAI()\n\nclient.fine_tuning.jobs.list()\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"fine_tuning.job\",\n      \"id\": \"ftjob-abc123\",\n      \"model\": \"gpt-4o-mini-2024-07-18\",\n      \"created_at\": 1721764800,\n      \"fine_tuned_model\": null,\n      \"organization_id\": \"org-123\",\n      \"result_files\": [],\n      \"status\": \"queued\",\n      \"validation_file\": null,\n      \"training_file\": \"file-abc123\",\n      \"metadata\": {\n        \"key\": \"value\"\n      }\n    },\n    { ... },\n    { ... }\n  ], \"has_more\": true\n}\nList fine-tuning events\nget\n \nhttps://api.openai.com/v1/fine_tuning/jobs/{fine_tu", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 186900, "end_char": 187500}, "375": {"text": "\"has_more\": true\n}\nList fine-tuning events\nget\n \nhttps://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/events\nGet status updates for a fine-tuning job.\n\nPath parameters\nfine_tuning_job_id\nstring\n\nRequired\nThe ID of the fine-tuning job to get events for.\n\nQuery parameters\nafter\nstring\n\nOptional\nIdentifier for the last event from the previous pagination request.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nNumber of events to retrieve.\n\nReturns\nA list of fine-tuning event objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.list_events(\n  fine_tunin", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 187400, "end_char": 188000}, "376": {"text": "quest\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.list_events(\n  fine_tuning_job_id=\"ftjob-abc123\",\n  limit=2\n)\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"fine_tuning.job.event\",\n      \"id\": \"ft-event-ddTJfwuMVpfLXseO0Am0Gqjm\",\n      \"created_at\": 1721764800,\n      \"level\": \"info\",\n      \"message\": \"Fine tuning job successfully completed\",\n      \"data\": null,\n      \"type\": \"message\"\n    },\n    {\n      \"object\": \"fine_tuning.job.event\",\n      \"id\": \"ft-event-tyiGuB72evQncpH87xe505Sv\",\n      \"created_at\": 1721764800,\n      \"level\": \"info\",\n      \"m", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 187900, "end_char": 188500}, "377": {"text": "\"ft-event-tyiGuB72evQncpH87xe505Sv\",\n      \"created_at\": 1721764800,\n      \"level\": \"info\",\n      \"message\": \"New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel\",\n      \"data\": null,\n      \"type\": \"message\"\n    }\n  ],\n  \"has_more\": true\n}\nList fine-tuning checkpoints\nget\n \nhttps://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/checkpoints\nList checkpoints for a fine-tuning job.\n\nPath parameters\nfine_tuning_job_id\nstring\n\nRequired\nThe ID of the fine-tuning job to get checkpoints for.\n\nQuery parameters\nafter\nstring\n\nOptional\nIdentifier for the last checkpoint ID from the prev", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 188400, "end_char": 189000}, "378": {"text": "ts for.\n\nQuery parameters\nafter\nstring\n\nOptional\nIdentifier for the last checkpoint ID from the previous pagination request.\n\nlimit\ninteger\n\nOptional\nDefaults to 10\nNumber of checkpoints to retrieve.\n\nReturns\nA list of fine-tuning checkpoint objects for a fine-tuning job.\n\nExample request\ncurl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\n{\n  \"object\": \"list\"\n  \"data\": [\n    {\n      \"object\": \"fine_tuning.job.checkpoint\",\n      \"id\": \"ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB\",\n      \"created_at\": 1721764867,\n      \"fine_tuned", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 188900, "end_char": 189500}, "379": {"text": "t\",\n      \"id\": \"ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB\",\n      \"created_at\": 1721764867,\n      \"fine_tuned_model_checkpoint\": \"ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000\",\n      \"metrics\": {\n        \"full_valid_loss\": 0.134,\n        \"full_valid_mean_token_accuracy\": 0.874\n      },\n      \"fine_tuning_job_id\": \"ftjob-abc123\",\n      \"step_number\": 2000,\n    },\n    {\n      \"object\": \"fine_tuning.job.checkpoint\",\n      \"id\": \"ftckpt_enQCFmOTGj3syEpYVhBRLTSy\",\n      \"created_at\": 1721764800,\n      \"fine_tuned_model_checkpoint\": \"ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 189400, "end_char": 190000}, "380": {"text": " 1721764800,\n      \"fine_tuned_model_checkpoint\": \"ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000\",\n      \"metrics\": {\n        \"full_valid_loss\": 0.167,\n        \"full_valid_mean_token_accuracy\": 0.781\n      },\n      \"fine_tuning_job_id\": \"ftjob-abc123\",\n      \"step_number\": 1000,\n    },\n  ],\n  \"first_id\": \"ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"last_id\": \"ftckpt_enQCFmOTGj3syEpYVhBRLTSy\",\n  \"has_more\": true\n}\nList checkpoint permissions\nget\n \nhttps://api.openai.com/v1/fine_tuning/checkpoints/{fine_tuned_model_checkpoint}/permissions\nNOTE: This endpoint requires an admin A", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 189900, "end_char": 190500}, "381": {"text": "tuning/checkpoints/{fine_tuned_model_checkpoint}/permissions\nNOTE: This endpoint requires an admin API key.\n\nOrganization owners can use this endpoint to view all permissions for a fine-tuned model checkpoint.\n\nPath parameters\nfine_tuned_model_checkpoint\nstring\n\nRequired\nThe ID of the fine-tuned model checkpoint to get permissions for.\n\nQuery parameters\nafter\nstring\n\nOptional\nIdentifier for the last permission ID from the previous pagination request.\n\nlimit\ninteger\n\nOptional\nDefaults to 10\nNumber of permissions to retrieve.\n\norder\nstring\n\nOptional\nDefaults to descending\nThe order in which to r", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 190400, "end_char": 191000}, "382": {"text": "r of permissions to retrieve.\n\norder\nstring\n\nOptional\nDefaults to descending\nThe order in which to retrieve permissions.\n\nproject_id\nstring\n\nOptional\nThe ID of the project to get permissions for.\n\nReturns\nA list of fine-tuned model checkpoint permission objects for a fine-tuned model checkpoint.\n\nExample request\ncurl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"checkpoint.permission\",\n      \"id\": \"cp_zc4Q7MP6XxulcVzj4MZ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 190900, "end_char": 191500}, "383": {"text": "ist\",\n  \"data\": [\n    {\n      \"object\": \"checkpoint.permission\",\n      \"id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n      \"created_at\": 1721764867,\n      \"project_id\": \"proj_abGMw1llN8IrBb6SvvY5A1iH\"\n    },\n    {\n      \"object\": \"checkpoint.permission\",\n      \"id\": \"cp_enQCFmOTGj3syEpYVhBRLTSy\",\n      \"created_at\": 1721764800,\n      \"project_id\": \"proj_iqGMw1llN8IrBb6SvvY5A1oF\"\n    },\n  ],\n  \"first_id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"last_id\": \"cp_enQCFmOTGj3syEpYVhBRLTSy\",\n  \"has_more\": false\n}\nCreate checkpoint permissions\npost\n \nhttps://api.openai.com/v1/fine_tuning/checkpoints/{fine_tuned_model", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 191400, "end_char": 192000}, "384": {"text": "te checkpoint permissions\npost\n \nhttps://api.openai.com/v1/fine_tuning/checkpoints/{fine_tuned_model_checkpoint}/permissions\nNOTE: Calling this endpoint requires an admin API key.\n\nThis enables organization owners to share fine-tuned models with other projects in their organization.\n\nPath parameters\nfine_tuned_model_checkpoint\nstring\n\nRequired\nThe ID of the fine-tuned model checkpoint to create a permission for.\n\nRequest body\nproject_ids\narray\n\nRequired\nThe project identifiers to grant access to.\n\nReturns\nA list of fine-tuned model checkpoint permission objects for a fine-tuned model checkpoin", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 191900, "end_char": 192500}, "385": {"text": ".\n\nReturns\nA list of fine-tuned model checkpoint permission objects for a fine-tuned model checkpoint.\n\nExample request\ncurl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n  -d '{\"project_ids\": [\"proj_abGMw1llN8IrBb6SvvY5A1iH\"]}'\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"checkpoint.permission\",\n      \"id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n      \"created_at\": 1721764867,\n      \"project_id\": \"proj_abGMw1llN8IrBb6SvvY5A1iH\"\n    }\n  ],\n  \"first_id\": \"cp_zc4Q7MP6XxulcVz", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 192400, "end_char": 193000}, "386": {"text": "67,\n      \"project_id\": \"proj_abGMw1llN8IrBb6SvvY5A1iH\"\n    }\n  ],\n  \"first_id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"last_id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"has_more\": false\n}\nDelete checkpoint permission\ndelete\n \nhttps://api.openai.com/v1/fine_tuning/checkpoints/{fine_tuned_model_checkpoint}/permissions\nNOTE: This endpoint requires an admin API key.\n\nOrganization owners can use this endpoint to delete a permission for a fine-tuned model checkpoint.\n\nPath parameters\nfine_tuned_model_checkpoint\nstring\n\nRequired\nThe ID of the fine-tuned model checkpoint to delete a permission for.\n\npermission_", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 192900, "end_char": 193500}, "387": {"text": "\nstring\n\nRequired\nThe ID of the fine-tuned model checkpoint to delete a permission for.\n\npermission_id\nstring\n\nRequired\nThe ID of the fine-tuned model checkpoint permission to delete.\n\nReturns\nThe deletion status of the fine-tuned model checkpoint permission object.\n\nExample request\ncurl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions/cp_zc4Q7MP6XxulcVzj4MZdwsAB \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\n{\n  \"object\": \"checkpoint.permission\",\n  \"id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"deleted\": true\n}\nRetrieve fine-tuning", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 193400, "end_char": 194000}, "388": {"text": "ckpoint.permission\",\n  \"id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"deleted\": true\n}\nRetrieve fine-tuning job\nget\n \nhttps://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}\nGet info about a fine-tuning job.\n\nLearn more about fine-tuning\n\nPath parameters\nfine_tuning_job_id\nstring\n\nRequired\nThe ID of the fine-tuning job.\n\nReturns\nThe fine-tuning object with the given ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.retrieve(\"ftjob-abc123\")\nResponse\n{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"davinci-002\",\n  \"created_at\": 1692661", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 193900, "end_char": 194500}, "389": {"text": "bject\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"davinci-002\",\n  \"created_at\": 1692661014,\n  \"finished_at\": 1692661190,\n  \"fine_tuned_model\": \"ft:davinci-002:my-org:custom_suffix:7q8mpxmy\",\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n      \"file-abc123\"\n  ],\n  \"status\": \"succeeded\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n  \"hyperparameters\": {\n      \"n_epochs\": 4,\n      \"batch_size\": 1,\n      \"learning_rate_multiplier\": 1.0\n  },\n  \"trained_tokens\": 5768,\n  \"integrations\": [],\n  \"seed\": 0,\n  \"estimated_finish\": 0,\n  \"method\": {\n    \"type\": \"supervised", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 194400, "end_char": 195000}, "390": {"text": "8,\n  \"integrations\": [],\n  \"seed\": 0,\n  \"estimated_finish\": 0,\n  \"method\": {\n    \"type\": \"supervised\",\n    \"supervised\": {\n      \"hyperparameters\": {\n        \"n_epochs\": 4,\n        \"batch_size\": 1,\n        \"learning_rate_multiplier\": 1.0\n      }\n    }\n  }\n}\nCancel fine-tuning\npost\n \nhttps://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancel\nImmediately cancel a fine-tune job.\n\nPath parameters\nfine_tuning_job_id\nstring\n\nRequired\nThe ID of the fine-tuning job to cancel.\n\nReturns\nThe cancelled fine-tuning object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.fin", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 194900, "end_char": 195500}, "391": {"text": "ncelled fine-tuning object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.cancel(\"ftjob-abc123\")\nResponse\n{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-4o-mini-2024-07-18\",\n  \"created_at\": 1721764800,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"status\": \"cancelled\",\n  \"validation_file\": \"file-abc123\",\n  \"training_file\": \"file-abc123\"\n}\nTraining format for chat models using the supervised method\nThe per-line training example of a fine-tuning input file for chat models using the supervised", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 195400, "end_char": 196000}, "392": {"text": "ethod\nThe per-line training example of a fine-tuning input file for chat models using the supervised method.\n\nfunctions\nDeprecated\narray\n\nA list of functions the model may generate JSON inputs for.\n\n\nShow properties\nmessages\narray\n\n\nShow possible types\nparallel_tool_calls\nboolean\n\nWhether to enable parallel function calling during tool use.\n\ntools\narray\n\nA list of tools the model may generate JSON inputs for.\n\n\nShow properties\nOBJECT Training format for chat models using the supervised method\n{\n  \"messages\": [\n    { \"role\": \"user\", \"content\": \"What is the weather in San Francisco?\" },\n    {\n  ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 195900, "end_char": 196500}, "393": {"text": "  \"messages\": [\n    { \"role\": \"user\", \"content\": \"What is the weather in San Francisco?\" },\n    {\n      \"role\": \"assistant\",\n      \"tool_calls\": [\n        {\n          \"id\": \"call_id\",\n          \"type\": \"function\",\n          \"function\": {\n            \"name\": \"get_current_weather\",\n            \"arguments\": \"{\\\"location\\\": \\\"San Francisco, USA\\\", \\\"format\\\": \\\"celsius\\\"}\"\n          }\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\": false,\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather\",\n ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 196400, "end_char": 197000}, "394": {"text": "ction\": {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The city and country, eg. San Francisco, USA\"\n            },\n            \"format\": { \"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"] }\n          },\n          \"required\": [\"location\", \"format\"]\n        }\n      }\n    }\n  ]\n}\nTraining format for chat models using the preference method\nThe per-line training example of a fine-tuni", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 196900, "end_char": 197500}, "395": {"text": "ning format for chat models using the preference method\nThe per-line training example of a fine-tuning input file for chat models using the dpo method.\n\ninput\nobject\n\n\nShow properties\nnon_preferred_completion\narray\n\nThe non-preferred completion message for the output.\n\n\nShow possible types\npreferred_completion\narray\n\nThe preferred completion message for the output.\n\n\nShow possible types\nOBJECT Training format for chat models using the preference method\n{\n  \"input\": {\n    \"messages\": [\n      { \"role\": \"user\", \"content\": \"What is the weather in San Francisco?\" }\n    ]\n  },\n  \"preferred_completio", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 197400, "end_char": 198000}, "396": {"text": "ole\": \"user\", \"content\": \"What is the weather in San Francisco?\" }\n    ]\n  },\n  \"preferred_completion\": [\n    {\n      \"role\": \"assistant\",\n      \"content\": \"The weather in San Francisco is 70 degrees Fahrenheit.\"\n    }\n  ],\n  \"non_preferred_completion\": [\n    {\n      \"role\": \"assistant\",\n      \"content\": \"The weather in San Francisco is 21 degrees Celsius.\"\n    }\n  ]\n}\nTraining format for completions models\nThe per-line training example of a fine-tuning input file for completions models\n\ncompletion\nstring\n\nThe desired completion for this training example.\n\nprompt\nstring\n\nThe input prompt for t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 197900, "end_char": 198500}, "397": {"text": "ion\nstring\n\nThe desired completion for this training example.\n\nprompt\nstring\n\nThe input prompt for this training example.\n\nOBJECT Training format for completions models\n{\n  \"prompt\": \"What is the answer to 2+2\",\n  \"completion\": \"4\"\n}\nThe fine-tuning job object\nThe fine_tuning.job object represents a fine-tuning job that has been created through the API.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the fine-tuning job was created.\n\nerror\nobject or null\n\nFor fine-tuning jobs that have failed, this will contain more information on the cause of the failure.\n\n\nShow properties\nestim", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 198400, "end_char": 199000}, "398": {"text": "have failed, this will contain more information on the cause of the failure.\n\n\nShow properties\nestimated_finish\ninteger or null\n\nThe Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.\n\nfine_tuned_model\nstring or null\n\nThe name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.\n\nfinished_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.\n\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 198900, "end_char": 199500}, "399": {"text": " the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.\n\nhyperparameters\nobject\n\nThe hyperparameters used for the fine-tuning job. This value will only be returned when running supervised jobs.\n\n\nShow properties\nid\nstring\n\nThe object identifier, which can be referenced in the API endpoints.\n\nintegrations\narray or null\n\nA list of integrations to enable for this fine-tuning job.\n\n\nShow possible types\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a stru", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 199400, "end_char": 200000}, "400": {"text": "ached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nmethod\nobject\n\nThe method used for fine-tuning.\n\n\nShow properties\nmodel\nstring\n\nThe base model that is being fine-tuned.\n\nobject\nstring\n\nThe object type, which is always \"fine_tuning.job\".\n\norganization_id\nstring\n\nThe organization that owns the fine-tuning job.\n\nresult_files\narray\n\nThe compiled results file ID(s) ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 199900, "end_char": 200500}, "401": {"text": "he organization that owns the fine-tuning job.\n\nresult_files\narray\n\nThe compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the Files API.\n\nseed\ninteger\n\nThe seed used for the fine-tuning job.\n\nstatus\nstring\n\nThe current status of the fine-tuning job, which can be either validating_files, queued, running, succeeded, failed, or cancelled.\n\ntrained_tokens\ninteger or null\n\nThe total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.\n\ntraining_file\nstring\n\nThe file ID used for training. You", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 200400, "end_char": 201000}, "402": {"text": "l if the fine-tuning job is still running.\n\ntraining_file\nstring\n\nThe file ID used for training. You can retrieve the training data with the Files API.\n\nvalidation_file\nstring or null\n\nThe file ID used for validation. You can retrieve the validation results with the Files API.\n\nOBJECT The fine-tuning job object\n{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"davinci-002\",\n  \"created_at\": 1692661014,\n  \"finished_at\": 1692661190,\n  \"fine_tuned_model\": \"ft:davinci-002:my-org:custom_suffix:7q8mpxmy\",\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n      \"file-abc123\"\n  ],\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 200900, "end_char": 201500}, "403": {"text": "stom_suffix:7q8mpxmy\",\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n      \"file-abc123\"\n  ],\n  \"status\": \"succeeded\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n  \"hyperparameters\": {\n      \"n_epochs\": 4,\n      \"batch_size\": 1,\n      \"learning_rate_multiplier\": 1.0\n  },\n  \"trained_tokens\": 5768,\n  \"integrations\": [],\n  \"seed\": 0,\n  \"estimated_finish\": 0,\n  \"method\": {\n    \"type\": \"supervised\",\n    \"supervised\": {\n      \"hyperparameters\": {\n        \"n_epochs\": 4,\n        \"batch_size\": 1,\n        \"learning_rate_multiplier\": 1.0\n      }\n    }\n  },\n  \"metadata\": {\n    \"key", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 201400, "end_char": 202000}, "404": {"text": "\"batch_size\": 1,\n        \"learning_rate_multiplier\": 1.0\n      }\n    }\n  },\n  \"metadata\": {\n    \"key\": \"value\"\n  }\n}\nThe fine-tuning job event object\nFine-tuning job event object\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the fine-tuning job was created.\n\ndata\nobject\n\nThe data associated with the event.\n\nid\nstring\n\nThe object identifier.\n\nlevel\nstring\n\nThe log level of the event.\n\nmessage\nstring\n\nThe message of the event.\n\nobject\nstring\n\nThe object type, which is always \"fine_tuning.job.event\".\n\ntype\nstring\n\nThe type of event.\n\nOBJECT The fine-tuning job event object\n{\n  \"ob", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 201900, "end_char": 202500}, "405": {"text": "tuning.job.event\".\n\ntype\nstring\n\nThe type of event.\n\nOBJECT The fine-tuning job event object\n{\n  \"object\": \"fine_tuning.job.event\",\n  \"id\": \"ftevent-abc123\"\n  \"created_at\": 1677610602,\n  \"level\": \"info\",\n  \"message\": \"Created fine-tuning job\",\n  \"data\": {},\n  \"type\": \"message\"\n}\nThe fine-tuning job checkpoint object\nThe fine_tuning.job.checkpoint object represents a model checkpoint for a fine-tuning job that is ready to use.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the checkpoint was created.\n\nfine_tuned_model_checkpoint\nstring\n\nThe name of the fine-tuned checkpoint model", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 202400, "end_char": 203000}, "406": {"text": "kpoint was created.\n\nfine_tuned_model_checkpoint\nstring\n\nThe name of the fine-tuned checkpoint model that is created.\n\nfine_tuning_job_id\nstring\n\nThe name of the fine-tuning job that this checkpoint was created from.\n\nid\nstring\n\nThe checkpoint identifier, which can be referenced in the API endpoints.\n\nmetrics\nobject\n\nMetrics at the step number during the fine-tuning job.\n\n\nShow properties\nobject\nstring\n\nThe object type, which is always \"fine_tuning.job.checkpoint\".\n\nstep_number\ninteger\n\nThe step number that the checkpoint was created at.\n\nOBJECT The fine-tuning job checkpoint object\n{\n  \"objec", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 202900, "end_char": 203500}, "407": {"text": " number that the checkpoint was created at.\n\nOBJECT The fine-tuning job checkpoint object\n{\n  \"object\": \"fine_tuning.job.checkpoint\",\n  \"id\": \"ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P\",\n  \"created_at\": 1712211699,\n  \"fine_tuned_model_checkpoint\": \"ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88\",\n  \"fine_tuning_job_id\": \"ftjob-fpbNQ3H1GrMehXRf8cO97xTN\",\n  \"metrics\": {\n    \"step\": 88,\n    \"train_loss\": 0.478,\n    \"train_mean_token_accuracy\": 0.924,\n    \"valid_loss\": 10.112,\n    \"valid_mean_token_accuracy\": 0.145,\n    \"full_valid_loss\": 0.567,\n    \"full_valid_mean_token_accuracy\": 0.", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 203400, "end_char": 204000}, "408": {"text": "_mean_token_accuracy\": 0.145,\n    \"full_valid_loss\": 0.567,\n    \"full_valid_mean_token_accuracy\": 0.944\n  },\n  \"step_number\": 88\n}\nThe fine-tuned model checkpoint permission object\nThe checkpoint.permission object represents a permission for a fine-tuned model checkpoint.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the permission was created.\n\nid\nstring\n\nThe permission identifier, which can be referenced in the API endpoints.\n\nobject\nstring\n\nThe object type, which is always \"checkpoint.permission\".\n\nproject_id\nstring\n\nThe project identifier that the permission is for.\n\nOBJECT", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 203900, "end_char": 204500}, "409": {"text": "eckpoint.permission\".\n\nproject_id\nstring\n\nThe project identifier that the permission is for.\n\nOBJECT The fine-tuned model checkpoint permission object\n{\n  \"object\": \"checkpoint.permission\",\n  \"id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"created_at\": 1712211699,\n  \"project_id\": \"proj_abGMw1llN8IrBb6SvvY5A1iH\"\n}\nBatch\nCreate large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount. Related guide: Batch\n\nCreate batch\npost\n \nhttps://api.openai.com/v1/batches\nCreates and executes a batch from an uploaded file of requests\n\nRequest bod", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 204400, "end_char": 205000}, "410": {"text": "pi.openai.com/v1/batches\nCreates and executes a batch from an uploaded file of requests\n\nRequest body\ncompletion_window\nstring\n\nRequired\nThe time frame within which the batch should be processed. Currently only 24h is supported.\n\nendpoint\nstring\n\nRequired\nThe endpoint to be used for all requests in the batch. Currently /v1/responses, /v1/chat/completions, /v1/embeddings, and /v1/completions are supported. Note that /v1/embeddings batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.\n\ninput_file_id\nstring\n\nRequired\nThe ID of an uploaded file that ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 204900, "end_char": 205500}, "411": {"text": "s across all requests in the batch.\n\ninput_file_id\nstring\n\nRequired\nThe ID of an uploaded file that contains requests for the new batch.\n\nSee upload file for how to upload a file.\n\nYour input file must be formatted as a JSONL file, and must be uploaded with the purpose batch. The file can contain up to 50,000 requests, and can be up to 200 MB in size.\n\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strin", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 205400, "end_char": 206000}, "412": {"text": "he object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nReturns\nThe created Batch object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.batches.create(\n  input_file_id=\"file-abc123\",\n  endpoint=\"/v1/chat/completions\",\n  completion_window=\"24h\"\n)\nResponse\n{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"endpoint\": \"/v1/chat/completions\",\n  \"errors\": null,\n  \"input_file_id\": \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"stat", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 205900, "end_char": 206500}, "413": {"text": "pletions\",\n  \"errors\": null,\n  \"input_file_id\": \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"validating\",\n  \"output_file_id\": null,\n  \"error_file_id\": null,\n  \"created_at\": 1711471533,\n  \"in_progress_at\": null,\n  \"expires_at\": null,\n  \"finalizing_at\": null,\n  \"completed_at\": null,\n  \"failed_at\": null,\n  \"expired_at\": null,\n  \"cancelling_at\": null,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n    \"total\": 0,\n    \"completed\": 0,\n    \"failed\": 0\n  },\n  \"metadata\": {\n    \"customer_id\": \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\",\n  }\n}\nRetrieve batch\nget\n \nhttps://a", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 206400, "end_char": 207000}, "414": {"text": " \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\",\n  }\n}\nRetrieve batch\nget\n \nhttps://api.openai.com/v1/batches/{batch_id}\nRetrieves a batch.\n\nPath parameters\nbatch_id\nstring\n\nRequired\nThe ID of the batch to retrieve.\n\nReturns\nThe Batch object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.batches.retrieve(\"batch_abc123\")\nResponse\n{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"endpoint\": \"/v1/completions\",\n  \"errors\": null,\n  \"input_file_id\": \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"completed\",\n  \"output_file_id\"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 206900, "end_char": 207500}, "415": {"text": "t_file_id\": \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"completed\",\n  \"output_file_id\": \"file-cvaTdG\",\n  \"error_file_id\": \"file-HOWS94\",\n  \"created_at\": 1711471533,\n  \"in_progress_at\": 1711471538,\n  \"expires_at\": 1711557933,\n  \"finalizing_at\": 1711493133,\n  \"completed_at\": 1711493163,\n  \"failed_at\": null,\n  \"expired_at\": null,\n  \"cancelling_at\": null,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n    \"total\": 100,\n    \"completed\": 95,\n    \"failed\": 5\n  },\n  \"metadata\": {\n    \"customer_id\": \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\",\n  }\n}\nCancel batch\npost\n \nht", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 207400, "end_char": 208000}, "416": {"text": "mer_id\": \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\",\n  }\n}\nCancel batch\npost\n \nhttps://api.openai.com/v1/batches/{batch_id}/cancel\nCancels an in-progress batch. The batch will be in status cancelling for up to 10 minutes, before changing to cancelled, where it will have partial results (if any) available in the output file.\n\nPath parameters\nbatch_id\nstring\n\nRequired\nThe ID of the batch to cancel.\n\nReturns\nThe Batch object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.batches.cancel(\"batch_abc123\")\nResponse\n{\n  \"id\": \"batch_ab", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 207900, "end_char": 208500}, "417": {"text": " import OpenAI\nclient = OpenAI()\n\nclient.batches.cancel(\"batch_abc123\")\nResponse\n{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"endpoint\": \"/v1/chat/completions\",\n  \"errors\": null,\n  \"input_file_id\": \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"cancelling\",\n  \"output_file_id\": null,\n  \"error_file_id\": null,\n  \"created_at\": 1711471533,\n  \"in_progress_at\": 1711471538,\n  \"expires_at\": 1711557933,\n  \"finalizing_at\": null,\n  \"completed_at\": null,\n  \"failed_at\": null,\n  \"expired_at\": null,\n  \"cancelling_at\": 1711475133,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n    \"total\": 100,\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 208400, "end_char": 209000}, "418": {"text": "ull,\n  \"cancelling_at\": 1711475133,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n    \"total\": 100,\n    \"completed\": 23,\n    \"failed\": 1\n  },\n  \"metadata\": {\n    \"customer_id\": \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\",\n  }\n}\nList batch\nget\n \nhttps://api.openai.com/v1/batches\nList your organization's batches.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 208900, "end_char": 209500}, "419": {"text": "est and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\nReturns\nA list of paginated Batch objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.batches.list()\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"batch_abc123\",\n      \"object\": \"batch\",\n      \"endpoint\": \"/v1/chat/completions\",\n      \"errors\": null,\n      \"input_file", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 209400, "end_char": 210000}, "420": {"text": "\"object\": \"batch\",\n      \"endpoint\": \"/v1/chat/completions\",\n      \"errors\": null,\n      \"input_file_id\": \"file-abc123\",\n      \"completion_window\": \"24h\",\n      \"status\": \"completed\",\n      \"output_file_id\": \"file-cvaTdG\",\n      \"error_file_id\": \"file-HOWS94\",\n      \"created_at\": 1711471533,\n      \"in_progress_at\": 1711471538,\n      \"expires_at\": 1711557933,\n      \"finalizing_at\": 1711493133,\n      \"completed_at\": 1711493163,\n      \"failed_at\": null,\n      \"expired_at\": null,\n      \"cancelling_at\": null,\n      \"cancelled_at\": null,\n      \"request_counts\": {\n        \"total\": 100,\n        \"compl", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 209900, "end_char": 210500}, "421": {"text": "t\": null,\n      \"cancelled_at\": null,\n      \"request_counts\": {\n        \"total\": 100,\n        \"completed\": 95,\n        \"failed\": 5\n      },\n      \"metadata\": {\n        \"customer_id\": \"user_123456789\",\n        \"batch_description\": \"Nightly job\",\n      }\n    },\n    { ... },\n  ],\n  \"first_id\": \"batch_abc123\",\n  \"last_id\": \"batch_abc456\",\n  \"has_more\": true\n}\nThe batch object\ncancelled_at\ninteger\n\nThe Unix timestamp (in seconds) for when the batch was cancelled.\n\ncancelling_at\ninteger\n\nThe Unix timestamp (in seconds) for when the batch started cancelling.\n\ncompleted_at\ninteger\n\nThe Unix timestamp ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 210400, "end_char": 211000}, "422": {"text": "stamp (in seconds) for when the batch started cancelling.\n\ncompleted_at\ninteger\n\nThe Unix timestamp (in seconds) for when the batch was completed.\n\ncompletion_window\nstring\n\nThe time frame within which the batch should be processed.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the batch was created.\n\nendpoint\nstring\n\nThe OpenAI API endpoint used by the batch.\n\nerror_file_id\nstring\n\nThe ID of the file containing the outputs of requests with errors.\n\nerrors\nobject\n\n\nShow properties\nexpired_at\ninteger\n\nThe Unix timestamp (in seconds) for when the batch expired.\n\nexpires_at\nintege", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 210900, "end_char": 211500}, "423": {"text": "s\nexpired_at\ninteger\n\nThe Unix timestamp (in seconds) for when the batch expired.\n\nexpires_at\ninteger\n\nThe Unix timestamp (in seconds) for when the batch will expire.\n\nfailed_at\ninteger\n\nThe Unix timestamp (in seconds) for when the batch failed.\n\nfinalizing_at\ninteger\n\nThe Unix timestamp (in seconds) for when the batch started finalizing.\n\nid\nstring\n\nin_progress_at\ninteger\n\nThe Unix timestamp (in seconds) for when the batch started processing.\n\ninput_file_id\nstring\n\nThe ID of the input file for the batch.\n\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be u", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 211400, "end_char": 212000}, "424": {"text": "the batch.\n\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nobject\nstring\n\nThe object type, which is always batch.\n\noutput_file_id\nstring\n\nThe ID of the file containing the outputs of successfully executed requests.\n\nrequest_counts\nobject\n\nThe request counts for different statuses within the batch.\n\n\nShow p", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 211900, "end_char": 212500}, "425": {"text": "quests.\n\nrequest_counts\nobject\n\nThe request counts for different statuses within the batch.\n\n\nShow properties\nstatus\nstring\n\nThe current status of the batch.\n\nOBJECT The batch object\n{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"endpoint\": \"/v1/completions\",\n  \"errors\": null,\n  \"input_file_id\": \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"completed\",\n  \"output_file_id\": \"file-cvaTdG\",\n  \"error_file_id\": \"file-HOWS94\",\n  \"created_at\": 1711471533,\n  \"in_progress_at\": 1711471538,\n  \"expires_at\": 1711557933,\n  \"finalizing_at\": 1711493133,\n  \"completed_at\": 1711493163,\n  \"failed_at", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 212400, "end_char": 213000}, "426": {"text": " \"expires_at\": 1711557933,\n  \"finalizing_at\": 1711493133,\n  \"completed_at\": 1711493163,\n  \"failed_at\": null,\n  \"expired_at\": null,\n  \"cancelling_at\": null,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n    \"total\": 100,\n    \"completed\": 95,\n    \"failed\": 5\n  },\n  \"metadata\": {\n    \"customer_id\": \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\",\n  }\n}\nThe request input object\nThe per-line object of the batch input file\n\ncustom_id\nstring\n\nA developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch.\n\nmethod\nstring\n\nThe ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 212900, "end_char": 213500}, "427": {"text": "be used to match outputs to inputs. Must be unique for each request in a batch.\n\nmethod\nstring\n\nThe HTTP method to be used for the request. Currently only POST is supported.\n\nurl\nstring\n\nThe OpenAI API relative URL to be used for the request. Currently /v1/chat/completions, /v1/embeddings, and /v1/completions are supported.\n\nOBJECT The request input object\n{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o-mini\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"What is 2+2?\"}]}}\nThe reque", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 213400, "end_char": 214000}, "428": {"text": "\"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"What is 2+2?\"}]}}\nThe request output object\nThe per-line object of the batch output and error files\n\ncustom_id\nstring\n\nA developer-provided per-request id that will be used to match outputs to inputs.\n\nerror\nobject or null\n\nFor requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.\n\n\nShow properties\nid\nstring\n\nresponse\nobject or null\n\n\nShow properties\nOBJECT The request output object\n{\"id\": \"batch_req_wnaDys\", \"custom_id\": \"request-2\", \"response\": {\"status_code\": 200, \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 213900, "end_char": 214500}, "429": {"text": "utput object\n{\"id\": \"batch_req_wnaDys\", \"custom_id\": \"request-2\", \"response\": {\"status_code\": 200, \"request_id\": \"req_c187b3\", \"body\": {\"id\": \"chatcmpl-9758Iw\", \"object\": \"chat.completion\", \"created\": 1711475054, \"model\": \"gpt-4o-mini\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"2 + 2 equals 4.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 24, \"completion_tokens\": 15, \"total_tokens\": 39}, \"system_fingerprint\": null}}, \"error\": null}\nFiles\nFiles are used to upload documents that can be used with features like Assistants, Fine-tuning, and Batch API.\n\nUpload ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 214400, "end_char": 215000}, "430": {"text": "pload documents that can be used with features like Assistants, Fine-tuning, and Batch API.\n\nUpload file\npost\n \nhttps://api.openai.com/v1/files\nUpload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.\n\nThe Assistants API supports files up to 2 million tokens and of specific file types. See the Assistants Tools guide for details.\n\nThe Fine-tuning API only supports .jsonl files. The input also has certain required formats for fine-tuning chat or completions models.\n\nThe Batch API onl", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 214900, "end_char": 215500}, "431": {"text": "put also has certain required formats for fine-tuning chat or completions models.\n\nThe Batch API only supports .jsonl files up to 200 MB in size. The input also has a specific required format.\n\nPlease contact us if you need to increase these storage limits.\n\nRequest body\nfile\nfile\n\nRequired\nThe File object (not file name) to be uploaded.\n\npurpose\nstring\n\nRequired\nThe intended purpose of the uploaded file. One of: - assistants: Used in the Assistants API - batch: Used in the Batch API - fine-tune: Used for fine-tuning - vision: Images used for vision fine-tuning - user_data: Flexible file type ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 215400, "end_char": 216000}, "432": {"text": ": Used for fine-tuning - vision: Images used for vision fine-tuning - user_data: Flexible file type for any purpose - evals: Used for eval data sets\n\nReturns\nThe uploaded File object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.files.create(\n  file=open(\"mydata.jsonl\", \"rb\"),\n  purpose=\"fine-tune\"\n)\nResponse\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"filename\": \"mydata.jsonl\",\n  \"purpose\": \"fine-tune\",\n}\nList files\nget\n \nhttps://api.openai.com/v1/files\nReturns a list of files.\n\nQuery parameters\nafter\nstring\n\nOptional\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 215900, "end_char": 216500}, "433": {"text": " \nhttps://api.openai.com/v1/files\nReturns a list of files.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nlimit\ninteger\n\nOptional\nDefaults to 10000\nA limit on the number of objects to be returned. Limit can range between 1 and 10,000, and the default is 10,000.\n\norder\nstring\n\nOptional\nDefaults to desc\nSort order by the created_at tim", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 216400, "end_char": 217000}, "434": {"text": "and the default is 10,000.\n\norder\nstring\n\nOptional\nDefaults to desc\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\npurpose\nstring\n\nOptional\nOnly return files with the given purpose.\n\nReturns\nA list of File objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.files.list()\nResponse\n{\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 175,\n      \"created_at\": 1613677385,\n      \"filename\": \"salesOverview.pdf\",\n      \"purpose\": \"assistants\",\n    },\n    {\n      \"id\": \"file-abc123", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 216900, "end_char": 217500}, "435": {"text": "filename\": \"salesOverview.pdf\",\n      \"purpose\": \"assistants\",\n    },\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 140,\n      \"created_at\": 1613779121,\n      \"filename\": \"puppy.jsonl\",\n      \"purpose\": \"fine-tune\",\n    }\n  ],\n  \"object\": \"list\"\n}\nRetrieve file\nget\n \nhttps://api.openai.com/v1/files/{file_id}\nReturns information about a specific file.\n\nPath parameters\nfile_id\nstring\n\nRequired\nThe ID of the file to use for this request.\n\nReturns\nThe File object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.files.retrieve", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 217400, "end_char": 218000}, "436": {"text": "he specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.files.retrieve(\"file-abc123\")\nResponse\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"filename\": \"mydata.jsonl\",\n  \"purpose\": \"fine-tune\",\n}\nDelete file\ndelete\n \nhttps://api.openai.com/v1/files/{file_id}\nDelete a file.\n\nPath parameters\nfile_id\nstring\n\nRequired\nThe ID of the file to use for this request.\n\nReturns\nDeletion status.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.files.delete(\"file-abc123\")\nResponse\n{\n  \"id\": \"file-abc123\",\n  \"o", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 217900, "end_char": 218500}, "437": {"text": " OpenAI\nclient = OpenAI()\n\nclient.files.delete(\"file-abc123\")\nResponse\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"deleted\": true\n}\nRetrieve file content\nget\n \nhttps://api.openai.com/v1/files/{file_id}/content\nReturns the contents of the specified file.\n\nPath parameters\nfile_id\nstring\n\nRequired\nThe ID of the file to use for this request.\n\nReturns\nThe file content.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\ncontent = client.files.content(\"file-abc123\")\nThe file object\nThe File object represents a document that has been uploaded to OpenAI.\n\nbytes\ninteger\n\nThe size of the f", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 218400, "end_char": 219000}, "438": {"text": "ile object represents a document that has been uploaded to OpenAI.\n\nbytes\ninteger\n\nThe size of the file, in bytes.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the file was created.\n\nexpires_at\ninteger\n\nThe Unix timestamp (in seconds) for when the file will expire.\n\nfilename\nstring\n\nThe name of the file.\n\nid\nstring\n\nThe file identifier, which can be referenced in the API endpoints.\n\nobject\nstring\n\nThe object type, which is always file.\n\npurpose\nstring\n\nThe intended purpose of the file. Supported values are assistants, assistants_output, batch, batch_output, fine-tune, fine-tun", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 218900, "end_char": 219500}, "439": {"text": "e file. Supported values are assistants, assistants_output, batch, batch_output, fine-tune, fine-tune-results and vision.\n\nstatus\nDeprecated\nstring\n\nDeprecated. The current status of the file, which can be either uploaded, processed, or error.\n\nstatus_details\nDeprecated\nstring\n\nDeprecated. For details on why a fine-tuning training file failed validation, see the error field on fine_tuning.job.\n\nOBJECT The file object\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"expires_at\": 1680202602,\n  \"filename\": \"salesOverview.pdf\",\n  \"purpose\": \"assistants", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 219400, "end_char": 220000}, "440": {"text": " 1677610602,\n  \"expires_at\": 1680202602,\n  \"filename\": \"salesOverview.pdf\",\n  \"purpose\": \"assistants\",\n}\nUploads\nAllows you to upload large files in multiple parts.\n\nCreate upload\npost\n \nhttps://api.openai.com/v1/uploads\nCreates an intermediate Upload object that you can add Parts to. Currently, an Upload can accept at most 8 GB in total and expires after an hour after you create it.\n\nOnce you complete the Upload, we will create a File object that contains all the parts you uploaded. This File is usable in the rest of our platform as a regular File object.\n\nFor certain purpose values, the corr", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 219900, "end_char": 220500}, "441": {"text": "s usable in the rest of our platform as a regular File object.\n\nFor certain purpose values, the correct mime_type must be specified. Please refer to documentation for the supported MIME types for your use case.\n\nFor guidance on the proper filename extensions for each purpose, please follow the documentation on creating a File.\n\nRequest body\nbytes\ninteger\n\nRequired\nThe number of bytes in the file you are uploading.\n\nfilename\nstring\n\nRequired\nThe name of the file to upload.\n\nmime_type\nstring\n\nRequired\nThe MIME type of the file.\n\nThis must fall within the supported MIME types for your file purpos", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 220400, "end_char": 221000}, "442": {"text": "ired\nThe MIME type of the file.\n\nThis must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision.\n\npurpose\nstring\n\nRequired\nThe intended purpose of the uploaded file.\n\nSee the documentation on File purposes.\n\nReturns\nThe Upload object with status pending.\n\nExample request\ncurl https://api.openai.com/v1/uploads \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"purpose\": \"fine-tune\",\n    \"filename\": \"training_examples.jsonl\",\n    \"bytes\": 2147483648,\n    \"mime_type\": \"text/jsonl\"\n  }'\nResponse\n{\n  \"id\": \"upload_abc123\",\n  \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 220900, "end_char": 221500}, "443": {"text": "\n    \"bytes\": 2147483648,\n    \"mime_type\": \"text/jsonl\"\n  }'\nResponse\n{\n  \"id\": \"upload_abc123\",\n  \"object\": \"upload\",\n  \"bytes\": 2147483648,\n  \"created_at\": 1719184911,\n  \"filename\": \"training_examples.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"pending\",\n  \"expires_at\": 1719127296\n}\nAdd upload part\npost\n \nhttps://api.openai.com/v1/uploads/{upload_id}/parts\nAdds a Part to an Upload object. A Part represents a chunk of bytes from the file you are trying to upload.\n\nEach Part can be at most 64 MB, and you can add Parts until you hit the Upload maximum of 8 GB.\n\nIt is possible to add multiple", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 221400, "end_char": 222000}, "444": {"text": " MB, and you can add Parts until you hit the Upload maximum of 8 GB.\n\nIt is possible to add multiple Parts in parallel. You can decide the intended order of the Parts when you complete the Upload.\n\nPath parameters\nupload_id\nstring\n\nRequired\nThe ID of the Upload.\n\nRequest body\ndata\nfile\n\nRequired\nThe chunk of bytes for this Part.\n\nReturns\nThe upload Part object.\n\nExample request\ncurl https://api.openai.com/v1/uploads/upload_abc123/parts\n  -F data=\"aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz...\"\nResponse\n{\n  \"id\": \"part_def456\",\n  \"object\": \"upload.part\",\n  \"created_at\": 1719185911,\n  \"upload_i", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 221900, "end_char": 222500}, "445": {"text": "Response\n{\n  \"id\": \"part_def456\",\n  \"object\": \"upload.part\",\n  \"created_at\": 1719185911,\n  \"upload_id\": \"upload_abc123\"\n}\nComplete upload\npost\n \nhttps://api.openai.com/v1/uploads/{upload_id}/complete\nCompletes the Upload.\n\nWithin the returned Upload object, there is a nested File object that is ready to use in the rest of the platform.\n\nYou can specify the order of the Parts by passing in an ordered list of the Part IDs.\n\nThe number of bytes uploaded upon completion must match the number of bytes initially specified when creating the Upload object. No Parts may be added after an Upload is comp", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 222400, "end_char": 223000}, "446": {"text": "s initially specified when creating the Upload object. No Parts may be added after an Upload is completed.\n\nPath parameters\nupload_id\nstring\n\nRequired\nThe ID of the Upload.\n\nRequest body\npart_ids\narray\n\nRequired\nThe ordered list of Part IDs.\n\nmd5\nstring\n\nOptional\nThe optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect.\n\nReturns\nThe Upload object with status completed with an additional file property containing the created usable File object.\n\nExample request\ncurl https://api.openai.com/v1/uploads/upload_abc123/complete\n  -d '{\n    \"part_ids\": [\"p", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 222900, "end_char": 223500}, "447": {"text": "le request\ncurl https://api.openai.com/v1/uploads/upload_abc123/complete\n  -d '{\n    \"part_ids\": [\"part_def456\", \"part_ghi789\"]\n  }'\nResponse\n{\n  \"id\": \"upload_abc123\",\n  \"object\": \"upload\",\n  \"bytes\": 2147483648,\n  \"created_at\": 1719184911,\n  \"filename\": \"training_examples.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"completed\",\n  \"expires_at\": 1719127296,\n  \"file\": {\n    \"id\": \"file-xyz321\",\n    \"object\": \"file\",\n    \"bytes\": 2147483648,\n    \"created_at\": 1719186911,\n    \"filename\": \"training_examples.jsonl\",\n    \"purpose\": \"fine-tune\",\n  }\n}\nCancel upload\npost\n \nhttps://api.openai.com/v1/", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 223400, "end_char": 224000}, "448": {"text": "g_examples.jsonl\",\n    \"purpose\": \"fine-tune\",\n  }\n}\nCancel upload\npost\n \nhttps://api.openai.com/v1/uploads/{upload_id}/cancel\nCancels the Upload. No Parts may be added after an Upload is cancelled.\n\nPath parameters\nupload_id\nstring\n\nRequired\nThe ID of the Upload.\n\nReturns\nThe Upload object with status cancelled.\n\nExample request\ncurl https://api.openai.com/v1/uploads/upload_abc123/cancel\nResponse\n{\n  \"id\": \"upload_abc123\",\n  \"object\": \"upload\",\n  \"bytes\": 2147483648,\n  \"created_at\": 1719184911,\n  \"filename\": \"training_examples.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"cancelled\",\n  \"expi", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 223900, "end_char": 224500}, "449": {"text": "\n  \"filename\": \"training_examples.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"cancelled\",\n  \"expires_at\": 1719127296\n}\nThe upload object\nThe Upload object can accept byte chunks in the form of Parts.\n\nbytes\ninteger\n\nThe intended number of bytes to be uploaded.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the Upload was created.\n\nexpires_at\ninteger\n\nThe Unix timestamp (in seconds) for when the Upload will expire.\n\nfile\nundefined or null\n\nThe ready File object after the Upload is completed.\n\nfilename\nstring\n\nThe name of the file to be uploaded.\n\nid\nstring\n\nThe Upload unique i", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 224400, "end_char": 225000}, "450": {"text": "is completed.\n\nfilename\nstring\n\nThe name of the file to be uploaded.\n\nid\nstring\n\nThe Upload unique identifier, which can be referenced in API endpoints.\n\nobject\nstring\n\nThe object type, which is always \"upload\".\n\npurpose\nstring\n\nThe intended purpose of the file. Please refer here for acceptable values.\n\nstatus\nstring\n\nThe status of the Upload.\n\nOBJECT The upload object\n{\n  \"id\": \"upload_abc123\",\n  \"object\": \"upload\",\n  \"bytes\": 2147483648,\n  \"created_at\": 1719184911,\n  \"filename\": \"training_examples.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"completed\",\n  \"expires_at\": 1719127296,\n  \"file\"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 224900, "end_char": 225500}, "451": {"text": "ples.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"completed\",\n  \"expires_at\": 1719127296,\n  \"file\": {\n    \"id\": \"file-xyz321\",\n    \"object\": \"file\",\n    \"bytes\": 2147483648,\n    \"created_at\": 1719186911,\n    \"filename\": \"training_examples.jsonl\",\n    \"purpose\": \"fine-tune\",\n  }\n}\nThe upload part object\nThe upload Part represents a chunk of bytes we can add to an Upload object.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the Part was created.\n\nid\nstring\n\nThe upload Part unique identifier, which can be referenced in API endpoints.\n\nobject\nstring\n\nThe object type, which is alw", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 225400, "end_char": 226000}, "452": {"text": " identifier, which can be referenced in API endpoints.\n\nobject\nstring\n\nThe object type, which is always upload.part.\n\nupload_id\nstring\n\nThe ID of the Upload object that this Part was added to.\n\nOBJECT The upload part object\n{\n    \"id\": \"part_def456\",\n    \"object\": \"upload.part\",\n    \"created_at\": 1719186911,\n    \"upload_id\": \"upload_abc123\"\n}\nImages\nGiven a prompt and/or an input image, the model will generate a new image. Related guide: Image generation\n\nCreate image\npost\n \nhttps://api.openai.com/v1/images/generations\nCreates an image given a prompt.\n\nRequest body\nprompt\nstring\n\nRequired\nA te", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 225900, "end_char": 226500}, "453": {"text": "om/v1/images/generations\nCreates an image given a prompt.\n\nRequest body\nprompt\nstring\n\nRequired\nA text description of the desired image(s). The maximum length is 1000 characters for dall-e-2 and 4000 characters for dall-e-3.\n\nmodel\nstring\n\nOptional\nDefaults to dall-e-2\nThe model to use for image generation.\n\nn\ninteger or null\n\nOptional\nDefaults to 1\nThe number of images to generate. Must be between 1 and 10. For dall-e-3, only n=1 is supported.\n\nquality\nstring\n\nOptional\nDefaults to standard\nThe quality of the image that will be generated. hd creates images with finer details and greater consis", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 226400, "end_char": 227000}, "454": {"text": "quality of the image that will be generated. hd creates images with finer details and greater consistency across the image. This param is only supported for dall-e-3.\n\nresponse_format\nstring or null\n\nOptional\nDefaults to url\nThe format in which the generated images are returned. Must be one of url or b64_json. URLs are only valid for 60 minutes after the image has been generated.\n\nsize\nstring or null\n\nOptional\nDefaults to 1024x1024\nThe size of the generated images. Must be one of 256x256, 512x512, or 1024x1024 for dall-e-2. Must be one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3 models.", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 226900, "end_char": 227500}, "455": {"text": "2, or 1024x1024 for dall-e-2. Must be one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3 models.\n\nstyle\nstring or null\n\nOptional\nDefaults to vivid\nThe style of the generated images. Must be one of vivid or natural. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for dall-e-3.\n\nuser\nstring\n\nOptional\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.\n\nReturns\nReturns a list of image objects", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 227400, "end_char": 228000}, "456": {"text": "ch can help OpenAI to monitor and detect abuse. Learn more.\n\nReturns\nReturns a list of image objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.images.generate(\n  model=\"dall-e-3\",\n  prompt=\"A cute baby sea otter\",\n  n=1,\n  size=\"1024x1024\"\n)\nResponse\n{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n    }\n  ]\n}\nCreate image edit\npost\n \nhttps://api.openai.com/v1/images/edits\nCreates an edited or extended image given an original image and a prompt.\n\nRequest body\nimage\nfile\n\nRequired\nThe image to edit. Must ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 227900, "end_char": 228500}, "457": {"text": "ge given an original image and a prompt.\n\nRequest body\nimage\nfile\n\nRequired\nThe image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.\n\nprompt\nstring\n\nRequired\nA text description of the desired image(s). The maximum length is 1000 characters.\n\nmask\nfile\n\nOptional\nAn additional image whose fully transparent areas (e.g. where alpha is zero) indicate where image should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as image.\n\nmodel\nstring or \"dall-e-2\"\n\nOptional\nDe", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 228400, "end_char": 229000}, "458": {"text": "file, less than 4MB, and have the same dimensions as image.\n\nmodel\nstring or \"dall-e-2\"\n\nOptional\nDefaults to dall-e-2\nThe model to use for image generation. Only dall-e-2 is supported at this time.\n\nn\ninteger or null\n\nOptional\nDefaults to 1\nThe number of images to generate. Must be between 1 and 10.\n\nresponse_format\nstring or null\n\nOptional\nDefaults to url\nThe format in which the generated images are returned. Must be one of url or b64_json. URLs are only valid for 60 minutes after the image has been generated.\n\nsize\nstring or null\n\nOptional\nDefaults to 1024x1024\nThe size of the generated ima", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 228900, "end_char": 229500}, "459": {"text": "s been generated.\n\nsize\nstring or null\n\nOptional\nDefaults to 1024x1024\nThe size of the generated images. Must be one of 256x256, 512x512, or 1024x1024.\n\nuser\nstring\n\nOptional\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.\n\nReturns\nReturns a list of image objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.images.edit(\n  image=open(\"otter.png\", \"rb\"),\n  mask=open(\"mask.png\", \"rb\"),\n  prompt=\"A cute baby sea otter wearing a beret\",\n  n=2,\n  size=\"1024x1024\"\n)\nResponse\n{\n  \"created\": 1589478378,\n  \"data\": [\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 229400, "end_char": 230000}, "460": {"text": "otter wearing a beret\",\n  n=2,\n  size=\"1024x1024\"\n)\nResponse\n{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n    }\n  ]\n}\nCreate image variation\npost\n \nhttps://api.openai.com/v1/images/variations\nCreates a variation of a given image.\n\nRequest body\nimage\nfile\n\nRequired\nThe image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.\n\nmodel\nstring or \"dall-e-2\"\n\nOptional\nDefaults to dall-e-2\nThe model to use for image generation. Only dall-e-2 is supported at this time.\n\nn\ninteger or null\n\nOpti", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 229900, "end_char": 230500}, "461": {"text": "model to use for image generation. Only dall-e-2 is supported at this time.\n\nn\ninteger or null\n\nOptional\nDefaults to 1\nThe number of images to generate. Must be between 1 and 10. For dall-e-3, only n=1 is supported.\n\nresponse_format\nstring or null\n\nOptional\nDefaults to url\nThe format in which the generated images are returned. Must be one of url or b64_json. URLs are only valid for 60 minutes after the image has been generated.\n\nsize\nstring or null\n\nOptional\nDefaults to 1024x1024\nThe size of the generated images. Must be one of 256x256, 512x512, or 1024x1024.\n\nuser\nstring\n\nOptional\nA unique id", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 230400, "end_char": 231000}, "462": {"text": " generated images. Must be one of 256x256, 512x512, or 1024x1024.\n\nuser\nstring\n\nOptional\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.\n\nReturns\nReturns a list of image objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.images.create_variation(\n  image=open(\"image_edit_original.png\", \"rb\"),\n  n=2,\n  size=\"1024x1024\"\n)\nResponse\n{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n    }\n  ]\n}\nThe image object\nRepresents the url or the co", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 230900, "end_char": 231500}, "463": {"text": ".\"\n    },\n    {\n      \"url\": \"https://...\"\n    }\n  ]\n}\nThe image object\nRepresents the url or the content of an image generated by the OpenAI API.\n\nb64_json\nstring\n\nThe base64-encoded JSON of the generated image, if response_format is b64_json.\n\nrevised_prompt\nstring\n\nThe prompt that was used to generate the image, if there was any revision to the prompt.\n\nurl\nstring\n\nThe URL of the generated image, if response_format is url (default).\n\nOBJECT The image object\n{\n  \"url\": \"...\",\n  \"revised_prompt\": \"...\"\n}\nModels\nList and describe the various models available in the API. You can refer to the Mo", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 231400, "end_char": 232000}, "464": {"text": "\": \"...\"\n}\nModels\nList and describe the various models available in the API. You can refer to the Models documentation to understand what models are available and the differences between them.\n\nList models\nget\n \nhttps://api.openai.com/v1/models\nLists the currently available models, and provides basic information about each one such as the owner and availability.\n\nReturns\nA list of model objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.models.list()\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"model-id-0\",\n      \"object\": \"model\",\n      \"created\": 1", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 231900, "end_char": 232500}, "465": {"text": "ct\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"model-id-0\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"organization-owner\"\n    },\n    {\n      \"id\": \"model-id-1\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"organization-owner\",\n    },\n    {\n      \"id\": \"model-id-2\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"openai\"\n    },\n  ],\n  \"object\": \"list\"\n}\nRetrieve model\nget\n \nhttps://api.openai.com/v1/models/{model}\nRetrieves a model instance, providing basic information about the model such as the owner and permissi", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 232400, "end_char": 233000}, "466": {"text": "trieves a model instance, providing basic information about the model such as the owner and permissioning.\n\nPath parameters\nmodel\nstring\n\nRequired\nThe ID of the model to use for this request\n\nReturns\nThe model object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.models.retrieve(\"gpt-4.1\")\nResponse\n{\n  \"id\": \"gpt-4.1\",\n  \"object\": \"model\",\n  \"created\": 1686935002,\n  \"owned_by\": \"openai\"\n}\nDelete a fine-tuned model\ndelete\n \nhttps://api.openai.com/v1/models/{model}\nDelete a fine-tuned model. You must have the Owner role in your organization to del", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 232900, "end_char": 233500}, "467": {"text": "1/models/{model}\nDelete a fine-tuned model. You must have the Owner role in your organization to delete a model.\n\nPath parameters\nmodel\nstring\n\nRequired\nThe model to delete\n\nReturns\nDeletion status.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.models.delete(\"ft:gpt-4o-mini:acemeco:suffix:abc123\")\nResponse\n{\n  \"id\": \"ft:gpt-4o-mini:acemeco:suffix:abc123\",\n  \"object\": \"model\",\n  \"deleted\": true\n}\nThe model object\nDescribes an OpenAI model offering that can be used with the API.\n\ncreated\ninteger\n\nThe Unix timestamp (in seconds) when the model was created.\n\nid\nstring\n\nThe m", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 233400, "end_char": 234000}, "468": {"text": "API.\n\ncreated\ninteger\n\nThe Unix timestamp (in seconds) when the model was created.\n\nid\nstring\n\nThe model identifier, which can be referenced in the API endpoints.\n\nobject\nstring\n\nThe object type, which is always \"model\".\n\nowned_by\nstring\n\nThe organization that owns the model.\n\nOBJECT The model object\n{\n  \"id\": \"gpt-4.1\",\n  \"object\": \"model\",\n  \"created\": 1686935002,\n  \"owned_by\": \"openai\"\n}\nModerations\nGiven text and/or image inputs, classifies if those inputs are potentially harmful across several categories. Related guide: Moderations\n\nCreate moderation\npost\n \nhttps://api.openai.com/v1/moder", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 233900, "end_char": 234500}, "469": {"text": "ral categories. Related guide: Moderations\n\nCreate moderation\npost\n \nhttps://api.openai.com/v1/moderations\nClassifies if text and/or image inputs are potentially harmful. Learn more in the moderation guide.\n\nRequest body\ninput\nstring or array\n\nRequired\nInput (or inputs) to classify. Can be a single string, an array of strings, or an array of multi-modal input objects similar to other models.\n\n\nShow possible types\nmodel\nstring\n\nOptional\nDefaults to omni-moderation-latest\nThe content moderation model you would like to use. Learn more in the moderation guide, and learn about available models here", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 234400, "end_char": 235000}, "470": {"text": "del you would like to use. Learn more in the moderation guide, and learn about available models here.\n\nReturns\nA moderation object.\n\n\nSingle string\n\nImage and text\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nmoderation = client.moderations.create(input=\"I want to kill them.\")\nprint(moderation)\nResponse\n{\n  \"id\": \"modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR\",\n  \"model\": \"text-moderation-007\",\n  \"results\": [\n    {\n      \"flagged\": true,\n      \"categories\": {\n        \"sexual\": false,\n        \"hate\": false,\n        \"harassment\": true,\n        \"self-harm\": false,\n        \"sexual/minors\": fa", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 234900, "end_char": 235500}, "471": {"text": "  \"hate\": false,\n        \"harassment\": true,\n        \"self-harm\": false,\n        \"sexual/minors\": false,\n        \"hate/threatening\": false,\n        \"violence/graphic\": false,\n        \"self-harm/intent\": false,\n        \"self-harm/instructions\": false,\n        \"harassment/threatening\": true,\n        \"violence\": true\n      },\n      \"category_scores\": {\n        \"sexual\": 0.000011726012417057063,\n        \"hate\": 0.22706663608551025,\n        \"harassment\": 0.5215635299682617,\n        \"self-harm\": 2.227119921371923e-6,\n        \"sexual/minors\": 7.107352217872176e-8,\n        \"hate/threatening\": 0.023547", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 235400, "end_char": 236000}, "472": {"text": "119921371923e-6,\n        \"sexual/minors\": 7.107352217872176e-8,\n        \"hate/threatening\": 0.023547329008579254,\n        \"violence/graphic\": 0.00003391829886822961,\n        \"self-harm/intent\": 1.646940972932498e-6,\n        \"self-harm/instructions\": 1.1198755256458526e-9,\n        \"harassment/threatening\": 0.5694745779037476,\n        \"violence\": 0.9971134662628174\n      }\n    }\n  ]\n}\nThe moderation object\nRepresents if a given text input is potentially harmful.\n\nid\nstring\n\nThe unique identifier for the moderation request.\n\nmodel\nstring\n\nThe model used to generate the moderation results.\n\nresult", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 235900, "end_char": 236500}, "473": {"text": "or the moderation request.\n\nmodel\nstring\n\nThe model used to generate the moderation results.\n\nresults\narray\n\nA list of moderation objects.\n\n\nShow properties\nOBJECT The moderation object\n{\n  \"id\": \"modr-0d9740456c391e43c445bf0f010940c7\",\n  \"model\": \"omni-moderation-latest\",\n  \"results\": [\n    {\n      \"flagged\": true,\n      \"categories\": {\n        \"harassment\": true,\n        \"harassment/threatening\": true,\n        \"sexual\": false,\n        \"hate\": false,\n        \"hate/threatening\": false,\n        \"illicit\": false,\n        \"illicit/violent\": false,\n        \"self-harm/intent\": false,\n        \"self-", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 236400, "end_char": 237000}, "474": {"text": "illicit\": false,\n        \"illicit/violent\": false,\n        \"self-harm/intent\": false,\n        \"self-harm/instructions\": false,\n        \"self-harm\": false,\n        \"sexual/minors\": false,\n        \"violence\": true,\n        \"violence/graphic\": true\n      },\n      \"category_scores\": {\n        \"harassment\": 0.8189693396524255,\n        \"harassment/threatening\": 0.804985420696006,\n        \"sexual\": 1.573112165348997e-6,\n        \"hate\": 0.007562942636942845,\n        \"hate/threatening\": 0.004208854591835476,\n        \"illicit\": 0.030535955153511665,\n        \"illicit/violent\": 0.008925306722380033,\n     ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 236900, "end_char": 237500}, "475": {"text": "476,\n        \"illicit\": 0.030535955153511665,\n        \"illicit/violent\": 0.008925306722380033,\n        \"self-harm/intent\": 0.00023023930975076432,\n        \"self-harm/instructions\": 0.0002293869201073356,\n        \"self-harm\": 0.012598046106750154,\n        \"sexual/minors\": 2.212566909570261e-8,\n        \"violence\": 0.9999992735124786,\n        \"violence/graphic\": 0.843064871157054\n      },\n      \"category_applied_input_types\": {\n        \"harassment\": [\n          \"text\"\n        ],\n        \"harassment/threatening\": [\n          \"text\"\n        ],\n        \"sexual\": [\n          \"text\",\n          \"image\"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 237400, "end_char": 238000}, "476": {"text": "/threatening\": [\n          \"text\"\n        ],\n        \"sexual\": [\n          \"text\",\n          \"image\"\n        ],\n        \"hate\": [\n          \"text\"\n        ],\n        \"hate/threatening\": [\n          \"text\"\n        ],\n        \"illicit\": [\n          \"text\"\n        ],\n        \"illicit/violent\": [\n          \"text\"\n        ],\n        \"self-harm/intent\": [\n          \"text\",\n          \"image\"\n        ],\n        \"self-harm/instructions\": [\n          \"text\",\n          \"image\"\n        ],\n        \"self-harm\": [\n          \"text\",\n          \"image\"\n        ],\n        \"sexual/minors\": [\n          \"text\"\n    ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 237900, "end_char": 238500}, "477": {"text": "\": [\n          \"text\",\n          \"image\"\n        ],\n        \"sexual/minors\": [\n          \"text\"\n        ],\n        \"violence\": [\n          \"text\",\n          \"image\"\n        ],\n        \"violence/graphic\": [\n          \"text\",\n          \"image\"\n        ]\n      }\n    }\n  ]\n}\nVector stores\nVector stores power semantic search for the Retrieval API and the file_search tool in the Responses and Assistants APIs.\n\nRelated guide: File Search\n\nCreate vector store\npost\n \nhttps://api.openai.com/v1/vector_stores\nCreate a vector store.\n\nRequest body\nchunking_strategy\nobject\n\nOptional\nThe chunking strategy use", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 238400, "end_char": 239000}, "478": {"text": "es\nCreate a vector store.\n\nRequest body\nchunking_strategy\nobject\n\nOptional\nThe chunking strategy used to chunk the file(s). If not set, will use the auto strategy. Only applicable if file_ids is non-empty.\n\n\nShow possible types\nexpires_after\nobject\n\nOptional\nThe expiration policy for a vector store.\n\n\nShow properties\nfile_ids\narray\n\nOptional\nA list of File IDs that the vector store should use. Useful for tools like file_search that can access files.\n\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 238900, "end_char": 239500}, "479": {"text": "irs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nname\nstring\n\nOptional\nThe name of the vector store.\n\nReturns\nA vector store object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nvector_store = client.vector_stores.create(\n  name=\"Support FAQ\"\n)\nprint(vector_store)\nResponse\n{\n  \"id\": \"vs_abc123\",\n  \"object\": \"vector_store\",\n  \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 239400, "end_char": 240000}, "480": {"text": "=\"Support FAQ\"\n)\nprint(vector_store)\nResponse\n{\n  \"id\": \"vs_abc123\",\n  \"object\": \"vector_store\",\n  \"created_at\": 1699061776,\n  \"name\": \"Support FAQ\",\n  \"bytes\": 139920,\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\": 3,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 3\n  }\n}\nList vector stores\nget\n \nhttps://api.openai.com/v1/vector_stores\nReturns a list of vector stores.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 239900, "end_char": 240500}, "481": {"text": "lace in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\n\nOptional\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can r", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 240400, "end_char": 241000}, "482": {"text": "\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\n\nOptional\nDefaults to desc\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nReturns\nA list of vector store objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nvector_stores = client.vector_stores.list()\nprint(vector_stores)\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"vs_abc123\",\n      \"object\": \"vector_store\",\n      \"created_at\": 16990617", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 240900, "end_char": 241500}, "483": {"text": "data\": [\n    {\n      \"id\": \"vs_abc123\",\n      \"object\": \"vector_store\",\n      \"created_at\": 1699061776,\n      \"name\": \"Support FAQ\",\n      \"bytes\": 139920,\n      \"file_counts\": {\n        \"in_progress\": 0,\n        \"completed\": 3,\n        \"failed\": 0,\n        \"cancelled\": 0,\n        \"total\": 3\n      }\n    },\n    {\n      \"id\": \"vs_abc456\",\n      \"object\": \"vector_store\",\n      \"created_at\": 1699061776,\n      \"name\": \"Support FAQ v2\",\n      \"bytes\": 139920,\n      \"file_counts\": {\n        \"in_progress\": 0,\n        \"completed\": 3,\n        \"failed\": 0,\n        \"cancelled\": 0,\n        \"total\": 3\n     ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 241400, "end_char": 242000}, "484": {"text": "s\": 0,\n        \"completed\": 3,\n        \"failed\": 0,\n        \"cancelled\": 0,\n        \"total\": 3\n      }\n    }\n  ],\n  \"first_id\": \"vs_abc123\",\n  \"last_id\": \"vs_abc456\",\n  \"has_more\": false\n}\nRetrieve vector store\nget\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}\nRetrieves a vector store.\n\nPath parameters\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store to retrieve.\n\nReturns\nThe vector store object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nvector_store = client.vector_stores.retrieve(\n  vector_store_id=\"vs_abc123\"\n)\nprint(vec", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 241900, "end_char": 242500}, "485": {"text": " = OpenAI()\n\nvector_store = client.vector_stores.retrieve(\n  vector_store_id=\"vs_abc123\"\n)\nprint(vector_store)\nResponse\n{\n  \"id\": \"vs_abc123\",\n  \"object\": \"vector_store\",\n  \"created_at\": 1699061776\n}\nModify vector store\npost\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}\nModifies a vector store.\n\nPath parameters\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store to modify.\n\nRequest body\nexpires_after\nobject or null\n\nOptional\nThe expiration policy for a vector store.\n\n\nShow properties\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 242400, "end_char": 243000}, "486": {"text": "properties\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nname\nstring or null\n\nOptional\nThe name of the vector store.\n\nReturns\nThe modified vector store object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nvector_store = client.vector_stores.update(\n  vector_store_id=\"vs_abc123\",\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 242900, "end_char": 243500}, "487": {"text": "penAI\nclient = OpenAI()\n\nvector_store = client.vector_stores.update(\n  vector_store_id=\"vs_abc123\",\n  name=\"Support FAQ\"\n)\nprint(vector_store)\nResponse\n{\n  \"id\": \"vs_abc123\",\n  \"object\": \"vector_store\",\n  \"created_at\": 1699061776,\n  \"name\": \"Support FAQ\",\n  \"bytes\": 139920,\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\": 3,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 3\n  }\n}\nDelete vector store\ndelete\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}\nDelete a vector store.\n\nPath parameters\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store to delete.\n\nReturns", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 243400, "end_char": 244000}, "488": {"text": "re.\n\nPath parameters\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store to delete.\n\nReturns\nDeletion status\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\ndeleted_vector_store = client.vector_stores.delete(\n  vector_store_id=\"vs_abc123\"\n)\nprint(deleted_vector_store)\nResponse\n{\n  id: \"vs_abc123\",\n  object: \"vector_store.deleted\",\n  deleted: true\n}\nSearch vector store\npost\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}/search\nSearch a vector store for relevant chunks based on a query and file attributes filter.\n\nPath parameters\nvector_store_id\nstring\n\nRequire", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 243900, "end_char": 244500}, "489": {"text": "chunks based on a query and file attributes filter.\n\nPath parameters\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store to search.\n\nRequest body\nquery\nstring or array\n\nRequired\nA query string for a search\n\nfilters\nobject\n\nOptional\nA filter to apply based on file attributes.\n\n\nShow possible types\nmax_num_results\ninteger\n\nOptional\nDefaults to 10\nThe maximum number of results to return. This number should be between 1 and 50 inclusive.\n\nranking_options\nobject\n\nOptional\nRanking options for search.\n\n\nShow properties\nrewrite_query\nboolean\n\nOptional\nDefaults to false\nWhether to rewrite the n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 244400, "end_char": 245000}, "490": {"text": "search.\n\n\nShow properties\nrewrite_query\nboolean\n\nOptional\nDefaults to false\nWhether to rewrite the natural language query for vector search.\n\nReturns\nA page of search results from the vector store.\n\nExample request\ncurl -X POST \\\nhttps://api.openai.com/v1/vector_stores/vs_abc123/search \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\"query\": \"What is the return policy?\", \"filters\": {...}}'\nResponse\n{\n  \"object\": \"vector_store.search_results.page\",\n  \"search_query\": \"What is the return policy?\",\n  \"data\": [\n    {\n      \"file_id\": \"file_123\",\n      \"file", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 244900, "end_char": 245500}, "491": {"text": "rch_query\": \"What is the return policy?\",\n  \"data\": [\n    {\n      \"file_id\": \"file_123\",\n      \"filename\": \"document.pdf\",\n      \"score\": 0.95,\n      \"attributes\": {\n        \"author\": \"John Doe\",\n        \"date\": \"2023-01-01\"\n      },\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"Relevant chunk\"\n        }\n      ]\n    },\n    {\n      \"file_id\": \"file_456\",\n      \"filename\": \"notes.txt\",\n      \"score\": 0.89,\n      \"attributes\": {\n        \"author\": \"Jane Smith\",\n        \"date\": \"2023-01-02\"\n      },\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\":", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 245400, "end_char": 246000}, "492": {"text": "ate\": \"2023-01-02\"\n      },\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"Sample text content from the vector store.\"\n        }\n      ]\n    }\n  ],\n  \"has_more\": false,\n  \"next_page\": null\n}\nThe vector store object\nA vector store is a collection of processed files can be used by the file_search tool.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the vector store was created.\n\nexpires_after\nobject\n\nThe expiration policy for a vector store.\n\n\nShow properties\nexpires_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the vector store will expir", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 245900, "end_char": 246500}, "493": {"text": "ies\nexpires_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the vector store will expire.\n\nfile_counts\nobject\n\n\nShow properties\nid\nstring\n\nThe identifier, which can be referenced in API endpoints.\n\nlast_active_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the vector store was last active.\n\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Va", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 246400, "end_char": 247000}, "494": {"text": "g for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nname\nstring\n\nThe name of the vector store.\n\nobject\nstring\n\nThe object type, which is always vector_store.\n\nstatus\nstring\n\nThe status of the vector store, which can be either expired, in_progress, or completed. A status of completed indicates that the vector store is ready for use.\n\nusage_bytes\ninteger\n\nThe total number of bytes used by the files in the vector store.\n\nOBJECT The vector store object\n{\n  \"id\": \"vs_123\",\n  \"object\": \"vector_", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 246900, "end_char": 247500}, "495": {"text": " files in the vector store.\n\nOBJECT The vector store object\n{\n  \"id\": \"vs_123\",\n  \"object\": \"vector_store\",\n  \"created_at\": 1698107661,\n  \"usage_bytes\": 123456,\n  \"last_active_at\": 1698107661,\n  \"name\": \"my_vector_store\",\n  \"status\": \"completed\",\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\": 100,\n    \"cancelled\": 0,\n    \"failed\": 0,\n    \"total\": 100\n  },\n  \"last_used_at\": 1698107661\n}\nVector store files\nVector store files represent files inside a vector store.\n\nRelated guide: File Search\n\nCreate vector store file\npost\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}/file", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 247400, "end_char": 248000}, "496": {"text": "arch\n\nCreate vector store file\npost\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}/files\nCreate a vector store file by attaching a File to a vector store.\n\nPath parameters\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store for which to create a File.\n\nRequest body\nfile_id\nstring\n\nRequired\nA File ID that the vector store should use. Useful for tools like file_search that can access files.\n\nattributes\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and q", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 247900, "end_char": 248500}, "497": {"text": "This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters, booleans, or numbers.\n\nchunking_strategy\nobject\n\nOptional\nThe chunking strategy used to chunk the file(s). If not set, will use the auto strategy.\n\n\nShow possible types\nReturns\nA vector store file object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nvector_store_file = client.vector_stores.files.create(\n  vector_store_", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 248400, "end_char": 249000}, "498": {"text": "ort OpenAI\nclient = OpenAI()\n\nvector_store_file = client.vector_stores.files.create(\n  vector_store_id=\"vs_abc123\",\n  file_id=\"file-abc123\"\n)\nprint(vector_store_file)\nResponse\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\",\n  \"created_at\": 1699061776,\n  \"usage_bytes\": 1234,\n  \"vector_store_id\": \"vs_abcd\",\n  \"status\": \"completed\",\n  \"last_error\": null\n}\nList vector store files\nget\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}/files\nReturns a list of vector store files.\n\nPath parameters\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store that the files belong to.\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 248900, "end_char": 249500}, "499": {"text": "th parameters\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store that the files belong to.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\n\nOptional\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starti", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 249400, "end_char": 250000}, "500": {"text": "nes your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\nfilter\nstring\n\nOptional\nFilter by file status. One of in_progress, completed, failed, cancelled.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\n\nOptional\nDefaults to desc\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descendi", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 249900, "end_char": 250500}, "501": {"text": "Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nReturns\nA list of vector store file objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nvector_store_files = client.vector_stores.files.list(\n  vector_store_id=\"vs_abc123\"\n)\nprint(vector_store_files)\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"vector_store.file\",\n      \"created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\n    },\n    {\n      \"id\": \"file-abc456\",\n      \"object\": \"vector_store.file\",\n      \"crea", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 250400, "end_char": 251000}, "502": {"text": "\"vs_abc123\"\n    },\n    {\n      \"id\": \"file-abc456\",\n      \"object\": \"vector_store.file\",\n      \"created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\n    }\n  ],\n  \"first_id\": \"file-abc123\",\n  \"last_id\": \"file-abc456\",\n  \"has_more\": false\n}\nRetrieve vector store file\nget\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id}\nRetrieves a vector store file.\n\nPath parameters\nfile_id\nstring\n\nRequired\nThe ID of the file being retrieved.\n\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store that the file belongs to.\n\nReturns\nThe vector store file object.\n\nExample r", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 250900, "end_char": 251500}, "503": {"text": "e ID of the vector store that the file belongs to.\n\nReturns\nThe vector store file object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nvector_store_file = client.vector_stores.files.retrieve(\n  vector_store_id=\"vs_abc123\",\n  file_id=\"file-abc123\"\n)\nprint(vector_store_file)\nResponse\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\",\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abcd\",\n  \"status\": \"completed\",\n  \"last_error\": null\n}\nRetrieve vector store file content\nget\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id}/content\nRetrieve th", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 251400, "end_char": 252000}, "504": {"text": "\nget\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id}/content\nRetrieve the parsed contents of a vector store file.\n\nPath parameters\nfile_id\nstring\n\nRequired\nThe ID of the file within the vector store.\n\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store.\n\nReturns\nThe parsed contents of the specified vector store file.\n\nExample request\ncurl \\\nhttps://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123/content \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\n{\n  \"file_id\": \"file-abc123\",\n  \"filename\": \"example.txt\",\n  \"attributes\": {\"key\": \"value\"}", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 251900, "end_char": 252500}, "505": {"text": "Response\n{\n  \"file_id\": \"file-abc123\",\n  \"filename\": \"example.txt\",\n  \"attributes\": {\"key\": \"value\"},\n  \"content\": [\n    {\"type\": \"text\", \"text\": \"...\"},\n    ...\n  ]\n}\nUpdate vector store file attributes\npost\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id}\nUpdate attributes on a vector store file.\n\nPath parameters\nfile_id\nstring\n\nRequired\nThe ID of the file to update attributes.\n\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store the file belongs to.\n\nRequest body\nattributes\nmap\n\nRequired\nSet of 16 key-value pairs that can be attached to an object. This can", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 252400, "end_char": 253000}, "506": {"text": " body\nattributes\nmap\n\nRequired\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters, booleans, or numbers.\n\nReturns\nThe updated vector store file object.\n\nExample request\ncurl https://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id} \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 252900, "end_char": 253500}, "507": {"text": "id}/files/{file_id} \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"attributes\": {\"key1\": \"value1\", \"key2\": 2}}'\nResponse\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\",\n  \"usage_bytes\": 1234,\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abcd\",\n  \"status\": \"completed\",\n  \"last_error\": null,\n  \"chunking_strategy\": {...},\n  \"attributes\": {\"key1\": \"value1\", \"key2\": 2}\n}\nDelete vector store file\ndelete\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id}\nDelete a vector store file. This will remove the file f", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 253400, "end_char": 254000}, "508": {"text": "tor_stores/{vector_store_id}/files/{file_id}\nDelete a vector store file. This will remove the file from the vector store but the file itself will not be deleted. To delete the file, use the delete file endpoint.\n\nPath parameters\nfile_id\nstring\n\nRequired\nThe ID of the file to delete.\n\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store that the file belongs to.\n\nReturns\nDeletion status\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\ndeleted_vector_store_file = client.vector_stores.files.delete(\n    vector_store_id=\"vs_abc123\",\n    file_id=\"file-abc123\"\n)\nprint(deleted_vect", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 253900, "end_char": 254500}, "509": {"text": "stores.files.delete(\n    vector_store_id=\"vs_abc123\",\n    file_id=\"file-abc123\"\n)\nprint(deleted_vector_store_file)\nResponse\n{\n  id: \"file-abc123\",\n  object: \"vector_store.file.deleted\",\n  deleted: true\n}\nThe vector store file object\nBeta\nA list of files attached to a vector store.\n\nattributes\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum len", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 254400, "end_char": 255000}, "510": {"text": "oard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters, booleans, or numbers.\n\nchunking_strategy\nobject\n\nThe strategy used to chunk the file.\n\n\nShow possible types\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the vector store file was created.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints.\n\nlast_error\nobject or null\n\nThe last error associated with this vector store file. Will be null if there are no errors.\n\n\nShow properties\nobject\nstring\n\nThe object type, which is always vector_store.file", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 254900, "end_char": 255500}, "511": {"text": "e are no errors.\n\n\nShow properties\nobject\nstring\n\nThe object type, which is always vector_store.file.\n\nstatus\nstring\n\nThe status of the vector store file, which can be either in_progress, completed, cancelled, or failed. The status completed indicates that the vector store file is ready for use.\n\nusage_bytes\ninteger\n\nThe total vector store usage in bytes. Note that this may be different from the original file size.\n\nvector_store_id\nstring\n\nThe ID of the vector store that the File is attached to.\n\nOBJECT The vector store file object\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\",\n  \"u", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 255400, "end_char": 256000}, "512": {"text": "\n\nOBJECT The vector store file object\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\",\n  \"usage_bytes\": 1234,\n  \"created_at\": 1698107661,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"completed\",\n  \"last_error\": null,\n  \"chunking_strategy\": {\n    \"type\": \"static\",\n    \"static\": {\n      \"max_chunk_size_tokens\": 800,\n      \"chunk_overlap_tokens\": 400\n    }\n  }\n}\nVector store file batches\nVector store file batches represent operations to add multiple files to a vector store. Related guide: File Search\n\nCreate vector store file batch\npost\n \nhttps://api.openai.com/v1/vector_stores/{vector", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 255900, "end_char": 256500}, "513": {"text": ": File Search\n\nCreate vector store file batch\npost\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}/file_batches\nCreate a vector store file batch.\n\nPath parameters\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store for which to create a File Batch.\n\nRequest body\nfile_ids\narray\n\nRequired\nA list of File IDs that the vector store should use. Useful for tools like file_search that can access files.\n\nattributes\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 256400, "end_char": 257000}, "514": {"text": "ect. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters, booleans, or numbers.\n\nchunking_strategy\nobject\n\nOptional\nThe chunking strategy used to chunk the file(s). If not set, will use the auto strategy.\n\n\nShow possible types\nReturns\nA vector store file batch object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nvector_store_file_batch = client.vector_stores.file_batches", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 256900, "end_char": 257500}, "515": {"text": " openai import OpenAI\nclient = OpenAI()\n\nvector_store_file_batch = client.vector_stores.file_batches.create(\n  vector_store_id=\"vs_abc123\",\n  file_ids=[\"file-abc123\", \"file-abc456\"]\n)\nprint(vector_store_file_batch)\nResponse\n{\n  \"id\": \"vsfb_abc123\",\n  \"object\": \"vector_store.file_batch\",\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"in_progress\",\n  \"file_counts\": {\n    \"in_progress\": 1,\n    \"completed\": 1,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 0,\n  }\n}\nRetrieve vector store file batch\nget\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}/file_b", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 257400, "end_char": 258000}, "516": {"text": "rieve vector store file batch\nget\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}/file_batches/{batch_id}\nRetrieves a vector store file batch.\n\nPath parameters\nbatch_id\nstring\n\nRequired\nThe ID of the file batch being retrieved.\n\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store that the file batch belongs to.\n\nReturns\nThe vector store file batch object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nvector_store_file_batch = client.vector_stores.file_batches.retrieve(\n  vector_store_id=\"vs_abc123\",\n  batch_id=\"vsfb_abc123\"\n)\nprint(vector_store_file_batch)\nR", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 257900, "end_char": 258500}, "517": {"text": "retrieve(\n  vector_store_id=\"vs_abc123\",\n  batch_id=\"vsfb_abc123\"\n)\nprint(vector_store_file_batch)\nResponse\n{\n  \"id\": \"vsfb_abc123\",\n  \"object\": \"vector_store.file_batch\",\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"in_progress\",\n  \"file_counts\": {\n    \"in_progress\": 1,\n    \"completed\": 1,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 0,\n  }\n}\nCancel vector store file batch\npost\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}/file_batches/{batch_id}/cancel\nCancel a vector store file batch. This attempts to cancel the processing of files in this ba", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 258400, "end_char": 259000}, "518": {"text": "/cancel\nCancel a vector store file batch. This attempts to cancel the processing of files in this batch as soon as possible.\n\nPath parameters\nbatch_id\nstring\n\nRequired\nThe ID of the file batch to cancel.\n\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store that the file batch belongs to.\n\nReturns\nThe modified vector store file batch object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\ndeleted_vector_store_file_batch = client.vector_stores.file_batches.cancel(\n    vector_store_id=\"vs_abc123\",\n    file_batch_id=\"vsfb_abc123\"\n)\nprint(deleted_vector_store_file_batch)\nRespo", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 258900, "end_char": 259500}, "519": {"text": "store_id=\"vs_abc123\",\n    file_batch_id=\"vsfb_abc123\"\n)\nprint(deleted_vector_store_file_batch)\nResponse\n{\n  \"id\": \"vsfb_abc123\",\n  \"object\": \"vector_store.file_batch\",\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"in_progress\",\n  \"file_counts\": {\n    \"in_progress\": 12,\n    \"completed\": 3,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 15,\n  }\n}\nList vector store files in a batch\nget\n \nhttps://api.openai.com/v1/vector_stores/{vector_store_id}/file_batches/{batch_id}/files\nReturns a list of vector store files in a batch.\n\nPath parameters\nbatch_id\nstring\n\nRequired\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 259400, "end_char": 260000}, "520": {"text": "}/files\nReturns a list of vector store files in a batch.\n\nPath parameters\nbatch_id\nstring\n\nRequired\nThe ID of the file batch that the files belong to.\n\nvector_store_id\nstring\n\nRequired\nThe ID of the vector store that the files belong to.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\n\nOptional\nA cursor for use in pagina", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 259900, "end_char": 260500}, "521": {"text": "foo in order to fetch the next page of the list.\n\nbefore\nstring\n\nOptional\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\nfilter\nstring\n\nOptional\nFilter by file status. One of in_progress, completed, failed, cancelled.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\nor", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 260400, "end_char": 261000}, "522": {"text": " the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\n\nOptional\nDefaults to desc\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nReturns\nA list of vector store file objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nvector_store_files = client.vector_stores.file_batches.list_files(\n  vector_store_id=\"vs_abc123\",\n  batch_id=\"vsfb_abc123\"\n)\nprint(vector_store_files)\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 260900, "end_char": 261500}, "523": {"text": "files)\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"vector_store.file\",\n      \"created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\n    },\n    {\n      \"id\": \"file-abc456\",\n      \"object\": \"vector_store.file\",\n      \"created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\n    }\n  ],\n  \"first_id\": \"file-abc123\",\n  \"last_id\": \"file-abc456\",\n  \"has_more\": false\n}\nThe vector store files batch object\nBeta\nA batch of files attached to a vector store.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the vector store files batc", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 261400, "end_char": 262000}, "524": {"text": "tor store.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the vector store files batch was created.\n\nfile_counts\nobject\n\n\nShow properties\nid\nstring\n\nThe identifier, which can be referenced in API endpoints.\n\nobject\nstring\n\nThe object type, which is always vector_store.file_batch.\n\nstatus\nstring\n\nThe status of the vector store files batch, which can be either in_progress, completed, cancelled or failed.\n\nvector_store_id\nstring\n\nThe ID of the vector store that the File is attached to.\n\nOBJECT The vector store files batch object\n{\n  \"id\": \"vsfb_123\",\n  \"object\": \"vector_store.files", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 261900, "end_char": 262500}, "525": {"text": "o.\n\nOBJECT The vector store files batch object\n{\n  \"id\": \"vsfb_123\",\n  \"object\": \"vector_store.files_batch\",\n  \"created_at\": 1698107661,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"completed\",\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\": 100,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 100\n  }\n}\nAssistants\nBeta\nBuild assistants that can call models and use tools to perform tasks.\n\nGet started with the Assistants API\n\nCreate assistant\nBeta\npost\n \nhttps://api.openai.com/v1/assistants\nCreate an assistant with a model and instructions.\n\nRequest body\nmodel\nstring\n\nRequired\nID ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 262400, "end_char": 263000}, "526": {"text": "sistants\nCreate an assistant with a model and instructions.\n\nRequest body\nmodel\nstring\n\nRequired\nID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.\n\ndescription\nstring or null\n\nOptional\nThe description of the assistant. The maximum length is 512 characters.\n\ninstructions\nstring or null\n\nOptional\nThe system instructions that the assistant uses. The maximum length is 256,000 characters.\n\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing ad", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 262900, "end_char": 263500}, "527": {"text": "ional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nname\nstring or null\n\nOptional\nThe name of the assistant. The maximum length is 256 characters.\n\nreasoning_effort\nstring or null\n\nOptional\nDefaults to medium\no-series models only\n\nConstrains effort on reasoning for reasoning models. Currently supported values are low, ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 263400, "end_char": 264000}, "528": {"text": "dels only\n\nConstrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.\n\nresponse_format\n\"auto\" or object\n\nOptional\nSpecifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.\n\nSetting to { \"type\": \"json_schema\", \"json_schema\": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guid", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 263900, "end_char": 264500}, "529": {"text": "ch ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.\n\nSetting to { \"type\": \"json_object\" } enables JSON mode, which ensures the message the model generates is valid JSON.\n\nImportant: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"leng", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 264400, "end_char": 265000}, "530": {"text": " \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.\n\n\nShow possible types\ntemperature\nnumber or null\n\nOptional\nDefaults to 1\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\ntool_resources\nobject or null\n\nOptional\nA set of resources that are used by the assistant's tools. The resources are specific to the typ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 264900, "end_char": 265500}, "531": {"text": "nal\nA set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs.\n\n\nShow properties\ntools\narray\n\nOptional\nDefaults to []\nA list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types code_interpreter, file_search, or function.\n\n\nShow possible types\ntop_p\nnumber or null\n\nOptional\nDefaults to 1\nAn alternative to sampling with temperature, called nucleus sampling, where t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 265400, "end_char": 266000}, "532": {"text": "Optional\nDefaults to 1\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n\nReturns\nAn assistant object.\n\n\nCode Interpreter\n\nFiles\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nmy_assistant = client.beta.assistants.create(\n    instructions=\"You are a personal math tutor. When asked a question, write and run Python code to answer the", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 265900, "end_char": 266500}, "533": {"text": "tions=\"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n    name=\"Math Tutor\",\n    tools=[{\"type\": \"code_interpreter\"}],\n    model=\"gpt-4o\",\n)\nprint(my_assistant)\nResponse\n{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1698984975,\n  \"name\": \"Math Tutor\",\n  \"description\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"top_p\": 1.0,\n  \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 266400, "end_char": 267000}, "534": {"text": "  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\nList assistants\nBeta\nget\n \nhttps://api.openai.com/v1/assistants\nReturns a list of assistants.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\n\nOptional\nA cursor for use in p", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 266900, "end_char": 267500}, "535": {"text": "=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\n\nOptional\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\n\nOptional\nDefaults to desc\nSort order by the created_at timestamp of the objects. ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 267400, "end_char": 268000}, "536": {"text": "20.\n\norder\nstring\n\nOptional\nDefaults to desc\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nReturns\nA list of assistant objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nmy_assistants = client.beta.assistants.list(\n    order=\"desc\",\n    limit=\"20\",\n)\nprint(my_assistants.data)\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"asst_abc123\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982736,\n      \"name\": \"Coding Tutor\",\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 267900, "end_char": 268500}, "537": {"text": "     \"name\": \"Coding Tutor\",\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": \"You are a helpful assistant designed to make me better at coding!\",\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    },\n    {\n      \"id\": \"asst_abc456\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982718,\n      \"name\": \"My Assistant\",\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": \"You are a helpful assistant designed to make me better at coding!\",\n      \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 268400, "end_char": 269000}, "538": {"text": ",\n      \"instructions\": \"You are a helpful assistant designed to make me better at coding!\",\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    },\n    {\n      \"id\": \"asst_abc789\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982643,\n      \"name\": null,\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": null,\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    }\n  ],\n ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 268900, "end_char": 269500}, "539": {"text": "ata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    }\n  ],\n  \"first_id\": \"asst_abc123\",\n  \"last_id\": \"asst_abc789\",\n  \"has_more\": false\n}\nRetrieve assistant\nBeta\nget\n \nhttps://api.openai.com/v1/assistants/{assistant_id}\nRetrieves an assistant.\n\nPath parameters\nassistant_id\nstring\n\nRequired\nThe ID of the assistant to retrieve.\n\nReturns\nThe assistant object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nmy_assistant = client.beta.assistants.retrieve(\"asst_abc123\")\nprint(my_assistant)\nResponse\n{\n  \"id\": \"asst_abc123", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 269400, "end_char": 270000}, "540": {"text": "= client.beta.assistants.retrieve(\"asst_abc123\")\nprint(my_assistant)\nResponse\n{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1699009709,\n  \"name\": \"HR Helper\",\n  \"description\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are an HR bot, and you have access to files to answer employee questions about company policies.\",\n  \"tools\": [\n    {\n      \"type\": \"file_search\"\n    }\n  ],\n  \"metadata\": {},\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\nModify assistant\nBeta\npost\n \nhttps://api.openai.com/v1/assistants/{assistant_id}\nModifies an assistant.\n\nPath p", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 269900, "end_char": 270500}, "541": {"text": "stant\nBeta\npost\n \nhttps://api.openai.com/v1/assistants/{assistant_id}\nModifies an assistant.\n\nPath parameters\nassistant_id\nstring\n\nRequired\nThe ID of the assistant to modify.\n\nRequest body\ndescription\nstring or null\n\nOptional\nThe description of the assistant. The maximum length is 512 characters.\n\ninstructions\nstring or null\n\nOptional\nThe system instructions that the assistant uses. The maximum length is 256,000 characters.\n\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 270400, "end_char": 271000}, "542": {"text": "o an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nmodel\nstring\n\nOptional\nID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.\n\nname\nstring or null\n\nOptional\nThe name of the assistant. The maximum length is 256 characters.\n\nreasoning_effort\nstring or null\n\nOptional\nDefaults to med", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 270900, "end_char": 271500}, "543": {"text": "nt. The maximum length is 256 characters.\n\nreasoning_effort\nstring or null\n\nOptional\nDefaults to medium\no-series models only\n\nConstrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.\n\nresponse_format\n\"auto\" or object\n\nOptional\nSpecifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.\n\nSetting to { \"type\": \"json_schema\", \"json_schema\": {...} } enables Structu", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 271400, "end_char": 272000}, "544": {"text": "ince gpt-3.5-turbo-1106.\n\nSetting to { \"type\": \"json_schema\", \"json_schema\": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.\n\nSetting to { \"type\": \"json_object\" } enables JSON mode, which ensures the message the model generates is valid JSON.\n\nImportant: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-runnin", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 271900, "end_char": 272500}, "545": {"text": "ending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.\n\n\nShow possible types\ntemperature\nnumber or null\n\nOptional\nDefaults to 1\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\ntool_resources\nobject", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 272400, "end_char": 273000}, "546": {"text": "dom, while lower values like 0.2 will make it more focused and deterministic.\n\ntool_resources\nobject or null\n\nOptional\nA set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs.\n\n\nShow properties\ntools\narray\n\nOptional\nDefaults to []\nA list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types code_interpreter, file_search, or function.\n\n\nShow possible types\ntop_p\nn", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 272900, "end_char": 273500}, "547": {"text": "ant. Tools can be of types code_interpreter, file_search, or function.\n\n\nShow possible types\ntop_p\nnumber or null\n\nOptional\nDefaults to 1\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n\nReturns\nThe modified assistant object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nmy_updated_assistant = client.beta.assistants.update(\n  \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 273400, "end_char": 274000}, "548": {"text": "om openai import OpenAI\nclient = OpenAI()\n\nmy_updated_assistant = client.beta.assistants.update(\n  \"asst_abc123\",\n  instructions=\"You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.\",\n  name=\"HR Helper\",\n  tools=[{\"type\": \"file_search\"}],\n  model=\"gpt-4o\"\n)\n\nprint(my_updated_assistant)\nResponse\n{\n  \"id\": \"asst_123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1699009709,\n  \"name\": \"HR Helper\",\n  \"description\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are an HR bot, and you have access to ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 273900, "end_char": 274500}, "549": {"text": "scription\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.\",\n  \"tools\": [\n    {\n      \"type\": \"file_search\"\n    }\n  ],\n  \"tool_resources\": {\n    \"file_search\": {\n      \"vector_store_ids\": []\n    }\n  },\n  \"metadata\": {},\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\nDelete assistant\nBeta\ndelete\n \nhttps://api.openai.com/v1/assistants/{assistant_id}\nDelete an assistant.\n\nPath parameters\nassistant_id\nstring\n\nRequired\nThe ID of", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 274400, "end_char": 275000}, "550": {"text": "istants/{assistant_id}\nDelete an assistant.\n\nPath parameters\nassistant_id\nstring\n\nRequired\nThe ID of the assistant to delete.\n\nReturns\nDeletion status\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.beta.assistants.delete(\"asst_abc123\")\nprint(response)\nResponse\n{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant.deleted\",\n  \"deleted\": true\n}\nThe assistant object\nBeta\nRepresents an assistant that can call the model and use tools.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the assistant was created.\n\ndescription\nstring or null\n\nThe description of th", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 274900, "end_char": 275500}, "551": {"text": " (in seconds) for when the assistant was created.\n\ndescription\nstring or null\n\nThe description of the assistant. The maximum length is 512 characters.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints.\n\ninstructions\nstring or null\n\nThe system instructions that the assistant uses. The maximum length is 256,000 characters.\n\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum len", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 275400, "end_char": 276000}, "552": {"text": "ured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nmodel\nstring\n\nID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.\n\nname\nstring or null\n\nThe name of the assistant. The maximum length is 256 characters.\n\nobject\nstring\n\nThe object type, which is always assistant.\n\nresponse_format\n\"auto\" or object\n\nSpecifies the format that the model must output. Compatible with GPT-4o, GPT", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 275900, "end_char": 276500}, "553": {"text": "ormat\n\"auto\" or object\n\nSpecifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.\n\nSetting to { \"type\": \"json_schema\", \"json_schema\": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.\n\nSetting to { \"type\": \"json_object\" } enables JSON mode, which ensures the message the model generates is valid JSON.\n\nImportant: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Wi", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 276400, "end_char": 277000}, "554": {"text": "SON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.\n\n\nShow possible types\ntemperature\nnumber or null\n\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make th", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 276900, "end_char": 277500}, "555": {"text": "mber or null\n\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\ntool_resources\nobject or null\n\nA set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs.\n\n\nShow properties\ntools\narray\n\nA list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can b", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 277400, "end_char": 278000}, "556": {"text": "ist of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types code_interpreter, file_search, or function.\n\n\nShow possible types\ntop_p\nnumber or null\n\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n\nOBJECT The assistant object\n{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 169", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 277900, "end_char": 278500}, "557": {"text": ".\n\nOBJECT The assistant object\n{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1698984975,\n  \"name\": \"Math Tutor\",\n  \"description\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\nThreads\nBeta\nCreate threads that assistants can interact with.\n\nRelated guide: Assistants\n\nCreate thread\nBeta\npost\n \nhttps://api.openai.com/v1/thread", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 278400, "end_char": 279000}, "558": {"text": "nteract with.\n\nRelated guide: Assistants\n\nCreate thread\nBeta\npost\n \nhttps://api.openai.com/v1/threads\nCreate a thread.\n\nRequest body\nmessages\narray\n\nOptional\nA list of messages to start the thread with.\n\n\nShow properties\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\ntool_resources\nobject or null\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 278900, "end_char": 279500}, "559": {"text": "racters. Values are strings with a maximum length of 512 characters.\n\ntool_resources\nobject or null\n\nOptional\nA set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs.\n\n\nShow properties\nReturns\nA thread object.\n\n\nEmpty\n\nMessages\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nempty_thread = client.beta.threads.create()\nprint(empty_thread)\nResponse\n{\n  \"id\": \"thread_abc123\",\n  \"o", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 279400, "end_char": 280000}, "560": {"text": "y_thread = client.beta.threads.create()\nprint(empty_thread)\nResponse\n{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1699012949,\n  \"metadata\": {},\n  \"tool_resources\": {}\n}\nRetrieve thread\nBeta\nget\n \nhttps://api.openai.com/v1/threads/{thread_id}\nRetrieves a thread.\n\nPath parameters\nthread_id\nstring\n\nRequired\nThe ID of the thread to retrieve.\n\nReturns\nThe thread object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nmy_thread = client.beta.threads.retrieve(\"thread_abc123\")\nprint(my_thread)\nResponse\n{\n  \"id\": \"thread_abc123\",\n  \"object\": \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 279900, "end_char": 280500}, "561": {"text": "threads.retrieve(\"thread_abc123\")\nprint(my_thread)\nResponse\n{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1699014083,\n  \"metadata\": {},\n  \"tool_resources\": {\n    \"code_interpreter\": {\n      \"file_ids\": []\n    }\n  }\n}\nModify thread\nBeta\npost\n \nhttps://api.openai.com/v1/threads/{thread_id}\nModifies a thread.\n\nPath parameters\nthread_id\nstring\n\nRequired\nThe ID of the thread to modify. Only the metadata can be modified.\n\nRequest body\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 280400, "end_char": 281000}, "562": {"text": " that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\ntool_resources\nobject or null\n\nOptional\nA set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 280900, "end_char": 281500}, "563": {"text": "preter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs.\n\n\nShow properties\nReturns\nThe modified thread object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nmy_updated_thread = client.beta.threads.update(\n  \"thread_abc123\",\n  metadata={\n    \"modified\": \"true\",\n    \"user\": \"abc123\"\n  }\n)\nprint(my_updated_thread)\nResponse\n{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1699014083,\n  \"metadata\": {\n    \"modified\": \"true\",\n    \"user\": \"abc123\"\n  },\n  \"tool_resources\": {}\n}\nDelete thread\nBeta\nd", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 281400, "end_char": 282000}, "564": {"text": "\": {\n    \"modified\": \"true\",\n    \"user\": \"abc123\"\n  },\n  \"tool_resources\": {}\n}\nDelete thread\nBeta\ndelete\n \nhttps://api.openai.com/v1/threads/{thread_id}\nDelete a thread.\n\nPath parameters\nthread_id\nstring\n\nRequired\nThe ID of the thread to delete.\n\nReturns\nDeletion status\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.beta.threads.delete(\"thread_abc123\")\nprint(response)\nResponse\n{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread.deleted\",\n  \"deleted\": true\n}\nThe thread object\nBeta\nRepresents a thread that contains messages.\n\ncreated_at\ninteger\n\nThe Unix timestamp (i", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 281900, "end_char": 282500}, "565": {"text": "d object\nBeta\nRepresents a thread that contains messages.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the thread was created.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints.\n\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nobject\nstring\n\nThe object type, which is alwa", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 282400, "end_char": 283000}, "566": {"text": " are strings with a maximum length of 512 characters.\n\nobject\nstring\n\nThe object type, which is always thread.\n\ntool_resources\nobject or null\n\nA set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs.\n\n\nShow properties\nOBJECT The thread object\n{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1698107661,\n  \"metadata\": {}\n}\nMessages\nBeta\nCreate messages within threads\n\nRelated ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 282900, "end_char": 283500}, "567": {"text": " \"created_at\": 1698107661,\n  \"metadata\": {}\n}\nMessages\nBeta\nCreate messages within threads\n\nRelated guide: Assistants\n\nCreate message\nBeta\npost\n \nhttps://api.openai.com/v1/threads/{thread_id}/messages\nCreate a message.\n\nPath parameters\nthread_id\nstring\n\nRequired\nThe ID of the thread to create a message for.\n\nRequest body\ncontent\nstring or array\n\nRequired\n\nShow possible types\nrole\nstring\n\nRequired\nThe role of the entity that is creating the message. Allowed values include:\n\nuser: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated message", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 283400, "end_char": 284000}, "568": {"text": "ssage is sent by an actual user and should be used in most cases to represent user-generated messages.\nassistant: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.\nattachments\narray or null\n\nOptional\nA list of files attached to the message, and the tools they should be added to.\n\n\nShow properties\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dash", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 283900, "end_char": 284500}, "569": {"text": "al information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nReturns\nA message object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nthread_message = client.beta.threads.messages.create(\n  \"thread_abc123\",\n  role=\"user\",\n  content=\"How does AI work? Explain it in simple terms.\",\n)\nprint(thread_message)\nResponse\n{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1713226573,\n  \"assistant_id\": null,\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 284400, "end_char": 285000}, "570": {"text": "d\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1713226573,\n  \"assistant_id\": null,\n  \"thread_id\": \"thread_abc123\",\n  \"run_id\": null,\n  \"role\": \"user\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"How does AI work? Explain it in simple terms.\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"attachments\": [],\n  \"metadata\": {}\n}\nList messages\nBeta\nget\n \nhttps://api.openai.com/v1/threads/{thread_id}/messages\nReturns a list of messages for a given thread.\n\nPath parameters\nthread_id\nstring\n\nRequired\nThe ID of the thread the messages belong to.\n\nQuery", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 284900, "end_char": 285500}, "571": {"text": "ead.\n\nPath parameters\nthread_id\nstring\n\nRequired\nThe ID of the thread the messages belong to.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\n\nOptional\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting wit", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 285400, "end_char": 286000}, "572": {"text": "ur place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\n\nOptional\nDefaults to desc\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nrun_id\nstring\n\nOptional\nFilter messages by the run ID that generated them.\n\nReturns\nA list of", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 285900, "end_char": 286500}, "573": {"text": "rder.\n\nrun_id\nstring\n\nOptional\nFilter messages by the run ID that generated them.\n\nReturns\nA list of message objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nthread_messages = client.beta.threads.messages.list(\"thread_abc123\")\nprint(thread_messages.data)\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"msg_abc123\",\n      \"object\": \"thread.message\",\n      \"created_at\": 1699016383,\n      \"assistant_id\": null,\n      \"thread_id\": \"thread_abc123\",\n      \"run_id\": null,\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": {", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 286400, "end_char": 287000}, "574": {"text": "ll,\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": {\n            \"value\": \"How does AI work? Explain it in simple terms.\",\n            \"annotations\": []\n          }\n        }\n      ],\n      \"attachments\": [],\n      \"metadata\": {}\n    },\n    {\n      \"id\": \"msg_abc456\",\n      \"object\": \"thread.message\",\n      \"created_at\": 1699016383,\n      \"assistant_id\": null,\n      \"thread_id\": \"thread_abc123\",\n      \"run_id\": null,\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": {\n            \"value\": \"Hello, what ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 286900, "end_char": 287500}, "575": {"text": "ntent\": [\n        {\n          \"type\": \"text\",\n          \"text\": {\n            \"value\": \"Hello, what is AI?\",\n            \"annotations\": []\n          }\n        }\n      ],\n      \"attachments\": [],\n      \"metadata\": {}\n    }\n  ],\n  \"first_id\": \"msg_abc123\",\n  \"last_id\": \"msg_abc456\",\n  \"has_more\": false\n}\nRetrieve message\nBeta\nget\n \nhttps://api.openai.com/v1/threads/{thread_id}/messages/{message_id}\nRetrieve a message.\n\nPath parameters\nmessage_id\nstring\n\nRequired\nThe ID of the message to retrieve.\n\nthread_id\nstring\n\nRequired\nThe ID of the thread to which this message belongs.\n\nReturns\nThe message", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 287400, "end_char": 288000}, "576": {"text": "\nthread_id\nstring\n\nRequired\nThe ID of the thread to which this message belongs.\n\nReturns\nThe message object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nmessage = client.beta.threads.messages.retrieve(\n  message_id=\"msg_abc123\",\n  thread_id=\"thread_abc123\",\n)\nprint(message)\nResponse\n{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1699017614,\n  \"assistant_id\": null,\n  \"thread_id\": \"thread_abc123\",\n  \"run_id\": null,\n  \"role\": \"user\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"How does AI work? Exp", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 287900, "end_char": 288500}, "577": {"text": ",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"How does AI work? Explain it in simple terms.\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"attachments\": [],\n  \"metadata\": {}\n}\nModify message\nBeta\npost\n \nhttps://api.openai.com/v1/threads/{thread_id}/messages/{message_id}\nModifies a message.\n\nPath parameters\nmessage_id\nstring\n\nRequired\nThe ID of the message to modify.\n\nthread_id\nstring\n\nRequired\nThe ID of the thread to which this message belongs.\n\nRequest body\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be usefu", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 288400, "end_char": 289000}, "578": {"text": "etadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nReturns\nThe modified message object.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nmessage = client.beta.threads.messages.update(\n  message_id=\"msg_abc12\",\n  thread_id=\"thread_abc123\",\n  metadata={\n    \"modified\": \"true\",\n    \"user\": \"a", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 288900, "end_char": 289500}, "579": {"text": "age_id=\"msg_abc12\",\n  thread_id=\"thread_abc123\",\n  metadata={\n    \"modified\": \"true\",\n    \"user\": \"abc123\",\n  },\n)\nprint(message)\nResponse\n{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1699017614,\n  \"assistant_id\": null,\n  \"thread_id\": \"thread_abc123\",\n  \"run_id\": null,\n  \"role\": \"user\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"How does AI work? Explain it in simple terms.\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"file_ids\": [],\n  \"metadata\": {\n    \"modified\": \"true\",\n    \"user\": \"abc123\"\n  }\n}\nDelete message\nBeta\ndelete\n \nhtt", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 289400, "end_char": 290000}, "580": {"text": "\n  \"metadata\": {\n    \"modified\": \"true\",\n    \"user\": \"abc123\"\n  }\n}\nDelete message\nBeta\ndelete\n \nhttps://api.openai.com/v1/threads/{thread_id}/messages/{message_id}\nDeletes a message.\n\nPath parameters\nmessage_id\nstring\n\nRequired\nThe ID of the message to delete.\n\nthread_id\nstring\n\nRequired\nThe ID of the thread to which this message belongs.\n\nReturns\nDeletion status\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\ndeleted_message = client.beta.threads.messages.delete(\n  message_id=\"msg_abc12\",\n  thread_id=\"thread_abc123\",\n)\nprint(deleted_message)\nResponse\n{\n  \"id\": \"msg_abc123\",\n  \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 289900, "end_char": 290500}, "581": {"text": "g_abc12\",\n  thread_id=\"thread_abc123\",\n)\nprint(deleted_message)\nResponse\n{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message.deleted\",\n  \"deleted\": true\n}\nThe message object\nBeta\nRepresents a message within a thread.\n\nassistant_id\nstring or null\n\nIf applicable, the ID of the assistant that authored this message.\n\nattachments\narray or null\n\nA list of files attached to the message, and the tools they were added to.\n\n\nShow properties\ncompleted_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the message was completed.\n\ncontent\narray\n\nThe content of the message in array of text and/or ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 290400, "end_char": 291000}, "582": {"text": " when the message was completed.\n\ncontent\narray\n\nThe content of the message in array of text and/or images.\n\n\nShow possible types\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the message was created.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints.\n\nincomplete_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the message was marked as incomplete.\n\nincomplete_details\nobject or null\n\nOn an incomplete message, details about why the message is incomplete.\n\n\nShow properties\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. Thi", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 290900, "end_char": 291500}, "583": {"text": "te.\n\n\nShow properties\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nobject\nstring\n\nThe object type, which is always thread.message.\n\nrole\nstring\n\nThe entity that produced the message. One of user or assistant.\n\nrun_id\nstring or null\n\nThe ID of the run associated with the creation of this message. Value is", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 291400, "end_char": 292000}, "584": {"text": "nt.\n\nrun_id\nstring or null\n\nThe ID of the run associated with the creation of this message. Value is null when messages are created manually using the create message or create thread endpoints.\n\nstatus\nstring\n\nThe status of the message, which can be either in_progress, incomplete, or completed.\n\nthread_id\nstring\n\nThe thread ID that this message belongs to.\n\nOBJECT The message object\n{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1698983503,\n  \"thread_id\": \"thread_abc123\",\n  \"role\": \"assistant\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 291900, "end_char": 292500}, "585": {"text": "  \"role\": \"assistant\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"Hi! How can I help you today?\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"assistant_id\": \"asst_abc123\",\n  \"run_id\": \"run_abc123\",\n  \"attachments\": [],\n  \"metadata\": {}\n}\nRuns\nBeta\nRepresents an execution run on a thread.\n\nRelated guide: Assistants\n\nCreate run\nBeta\npost\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs\nCreate a run.\n\nPath parameters\nthread_id\nstring\n\nRequired\nThe ID of the thread to run.\n\nQuery parameters\ninclude[]\narray\n\nOptional\nA list of additional fields to include i", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 292400, "end_char": 293000}, "586": {"text": " thread to run.\n\nQuery parameters\ninclude[]\narray\n\nOptional\nA list of additional fields to include in the response. Currently the only supported value is step_details.tool_calls[*].file_search.results[*].content to fetch the file search result content.\n\nSee the file search tool documentation for more information.\n\nRequest body\nassistant_id\nstring\n\nRequired\nThe ID of the assistant to use to execute this run.\n\nadditional_instructions\nstring or null\n\nOptional\nAppends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis wi", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 292900, "end_char": 293500}, "587": {"text": "end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.\n\nadditional_messages\narray or null\n\nOptional\nAdds additional messages to the thread before creating the run.\n\n\nShow properties\ninstructions\nstring or null\n\nOptional\nOverrides the instructions of the assistant. This is useful for modifying the behavior on a per-run basis.\n\nmax_completion_tokens\ninteger or null\n\nOptional\nThe maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 293400, "end_char": 294000}, "588": {"text": "at may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status incomplete. See incomplete_details for more info.\n\nmax_prompt_tokens\ninteger or null\n\nOptional\nThe maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens speci", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 293900, "end_char": 294500}, "589": {"text": "ns specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status incomplete. See incomplete_details for more info.\n\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nmodel\nstring\n\nOptional\nThe ID of the Model to be used to execute ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 294400, "end_char": 295000}, "590": {"text": "maximum length of 512 characters.\n\nmodel\nstring\n\nOptional\nThe ID of the Model to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.\n\nparallel_tool_calls\nboolean\n\nOptional\nDefaults to true\nWhether to enable parallel function calling during tool use.\n\nreasoning_effort\nstring or null\n\nOptional\nDefaults to medium\no-series models only\n\nConstrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can res", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 294900, "end_char": 295500}, "591": {"text": "ning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.\n\nresponse_format\n\"auto\" or object\n\nOptional\nSpecifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.\n\nSetting to { \"type\": \"json_schema\", \"json_schema\": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.\n\nSetting to { \"type\": \"json_object\" } enables JS", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 295400, "end_char": 296000}, "592": {"text": "schema. Learn more in the Structured Outputs guide.\n\nSetting to { \"type\": \"json_object\" } enables JSON mode, which ensures the message the model generates is valid JSON.\n\nImportant: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_to", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 295900, "end_char": 296500}, "593": {"text": "t may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.\n\n\nShow possible types\nstream\nboolean or null\n\nOptional\nIf true, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a data: [DONE] message.\n\ntemperature\nnumber or null\n\nOptional\nDefaults to 1\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deter", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 296400, "end_char": 297000}, "594": {"text": ".8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\ntool_choice\nstring or object\n\nOptional\nControls which (if any) tool is called by the model. none means the model will not call any tools and instead generates a message. auto is the default value and means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools before responding to the user. Specifying a particular tool like {\"type\": \"file_search\"} or {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} fo", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 296900, "end_char": 297500}, "595": {"text": "ar tool like {\"type\": \"file_search\"} or {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that tool.\n\n\nShow possible types\ntools\narray or null\n\nOptional\nOverride the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.\n\n\nShow possible types\ntop_p\nnumber or null\n\nOptional\nDefaults to 1\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are consid", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 297400, "end_char": 298000}, "596": {"text": "_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n\ntruncation_strategy\nobject or null\n\nOptional\nControls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.\n\n\nShow properties\nReturns\nA run object.\n\n\nDefault\n\nStreaming\n\nStreaming with Functions\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.create(\n  thread_id=\"thread_abc123\",\n  assistant_id=\"asst_abc123\"\n)\n\nprint(run)\nRe", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 297900, "end_char": 298500}, "597": {"text": "beta.threads.runs.create(\n  thread_id=\"thread_abc123\",\n  assistant_id=\"asst_abc123\"\n)\n\nprint(run)\nResponse\n{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699063290,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"queued\",\n  \"started_at\": 1699063290,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699063291,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"incomplete_details\": null,\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"usage\": null,\n  \"tempe", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 298400, "end_char": 299000}, "598": {"text": "ls\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"usage\": null,\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\nCreate thread and run\nBeta\npost\n \nhttps://api.openai.com/v1/threads/runs\nCreate a thread and run it in one request.\n\nRequest body\nassistant_id\nstring\n\nRequired\nThe ID of the assistant to use to execute this run.\n\ninstructions\nstring or null\n\nOp", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 298900, "end_char": 299500}, "599": {"text": "tring\n\nRequired\nThe ID of the assistant to use to execute this run.\n\ninstructions\nstring or null\n\nOptional\nOverride the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.\n\nmax_completion_tokens\ninteger or null\n\nOptional\nThe maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status incomplete. See incomplete_deta", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 299400, "end_char": 300000}, "600": {"text": " number of completion tokens specified, the run will end with status incomplete. See incomplete_details for more info.\n\nmax_prompt_tokens\ninteger or null\n\nOptional\nThe maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status incomplete. See incomplete_details for more info.\n\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be usef", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 299900, "end_char": 300500}, "601": {"text": "metadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nmodel\nstring\n\nOptional\nThe ID of the Model to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.\n\nparallel_tool_calls\nboolea", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 300400, "end_char": 301000}, "602": {"text": "assistant. If not, the model associated with the assistant will be used.\n\nparallel_tool_calls\nboolean\n\nOptional\nDefaults to true\nWhether to enable parallel function calling during tool use.\n\nresponse_format\n\"auto\" or object\n\nOptional\nSpecifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.\n\nSetting to { \"type\": \"json_schema\", \"json_schema\": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.\n\nSetting to { \"type\": \"json_obje", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 300900, "end_char": 301500}, "603": {"text": "r supplied JSON schema. Learn more in the Structured Outputs guide.\n\nSetting to { \"type\": \"json_object\" } enables JSON mode, which ensures the message the model generates is valid JSON.\n\nImportant: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 301400, "end_char": 302000}, "604": {"text": "e message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.\n\n\nShow possible types\nstream\nboolean or null\n\nOptional\nIf true, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a data: [DONE] message.\n\ntemperature\nnumber or null\n\nOptional\nDefaults to 1\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more f", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 301900, "end_char": 302500}, "605": {"text": "er values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nthread\nobject\n\nOptional\nOptions to create a new thread. If no thread is provided when running a request, an empty thread will be created.\n\n\nShow properties\ntool_choice\nstring or object\n\nOptional\nControls which (if any) tool is called by the model. none means the model will not call any tools and instead generates a message. auto is the default value and means the model can pick between generating a message or calling one or more tools. required means the model must cal", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 302400, "end_char": 303000}, "606": {"text": "an pick between generating a message or calling one or more tools. required means the model must call one or more tools before responding to the user. Specifying a particular tool like {\"type\": \"file_search\"} or {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that tool.\n\n\nShow possible types\ntool_resources\nobject or null\n\nOptional\nA set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector stor", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 302900, "end_char": 303500}, "607": {"text": "erpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs.\n\n\nShow properties\ntools\narray or null\n\nOptional\nOverride the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.\n\ntop_p\nnumber or null\n\nOptional\nDefaults to 1\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or tempe", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 303400, "end_char": 304000}, "608": {"text": "mprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n\ntruncation_strategy\nobject or null\n\nOptional\nControls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.\n\n\nShow properties\nReturns\nA run object.\n\n\nDefault\n\nStreaming\n\nStreaming with Functions\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.create_and_run(\n  assistant_id=\"asst_abc123\",\n  thread={\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"Explain deep learning to a 5 ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 303900, "end_char": 304500}, "609": {"text": "c123\",\n  thread={\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"Explain deep learning to a 5 year old.\"}\n    ]\n  }\n)\n\nprint(run)\nResponse\n{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699076792,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"queued\",\n  \"started_at\": null,\n  \"expires_at\": 1699077392,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"required_action\": null,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are a helpful assistant.\",\n  \"tools\": [],\n  \"tool_resources\": {},\n  \"metadata\"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 304400, "end_char": 305000}, "610": {"text": " \"instructions\": \"You are a helpful assistant.\",\n  \"tools\": [],\n  \"tool_resources\": {},\n  \"metadata\": {},\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_completion_tokens\": null,\n  \"max_prompt_tokens\": null,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"incomplete_details\": null,\n  \"usage\": null,\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\nList runs\nBeta\nget\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs\nReturns a list of runs belonging to a thread.\n\nPath parameters\nthread_id\nstring\n\nRequired\nThe ID of the thread ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 304900, "end_char": 305500}, "611": {"text": "ist of runs belonging to a thread.\n\nPath parameters\nthread_id\nstring\n\nRequired\nThe ID of the thread the run belongs to.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\n\nOptional\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 305400, "end_char": 306000}, "612": {"text": " object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\n\nOptional\nDefaults to desc\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nReturns\nA list of run objects.\n\nExample request\nfrom openai import ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 305900, "end_char": 306500}, "613": {"text": " and desc for descending order.\n\nReturns\nA list of run objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nruns = client.beta.threads.runs.list(\n  \"thread_abc123\"\n)\n\nprint(runs)\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"run_abc123\",\n      \"object\": \"thread.run\",\n      \"created_at\": 1699075072,\n      \"assistant_id\": \"asst_abc123\",\n      \"thread_id\": \"thread_abc123\",\n      \"status\": \"completed\",\n      \"started_at\": 1699075072,\n      \"expires_at\": null,\n      \"cancelled_at\": null,\n      \"failed_at\": null,\n      \"completed_at\": 1699075073,\n      \"last_error\":", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 306400, "end_char": 307000}, "614": {"text": "\"cancelled_at\": null,\n      \"failed_at\": null,\n      \"completed_at\": 1699075073,\n      \"last_error\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": null,\n      \"incomplete_details\": null,\n      \"tools\": [\n        {\n          \"type\": \"code_interpreter\"\n        }\n      ],\n      \"tool_resources\": {\n        \"code_interpreter\": {\n          \"file_ids\": [\n            \"file-abc123\",\n            \"file-abc456\"\n          ]\n        }\n      },\n      \"metadata\": {},\n      \"usage\": {\n        \"prompt_tokens\": 123,\n        \"completion_tokens\": 456,\n        \"total_tokens\": 579\n      },\n      \"temperature\"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 306900, "end_char": 307500}, "615": {"text": "ns\": 123,\n        \"completion_tokens\": 456,\n        \"total_tokens\": 579\n      },\n      \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_prompt_tokens\": 1000,\n      \"max_completion_tokens\": 1000,\n      \"truncation_strategy\": {\n        \"type\": \"auto\",\n        \"last_messages\": null\n      },\n      \"response_format\": \"auto\",\n      \"tool_choice\": \"auto\",\n      \"parallel_tool_calls\": true\n    },\n    {\n      \"id\": \"run_abc456\",\n      \"object\": \"thread.run\",\n      \"created_at\": 1699063290,\n      \"assistant_id\": \"asst_abc123\",\n      \"thread_id\": \"thread_abc123\",\n      \"status\": \"completed\",\n      \"sta", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 307400, "end_char": 308000}, "616": {"text": "tant_id\": \"asst_abc123\",\n      \"thread_id\": \"thread_abc123\",\n      \"status\": \"completed\",\n      \"started_at\": 1699063290,\n      \"expires_at\": null,\n      \"cancelled_at\": null,\n      \"failed_at\": null,\n      \"completed_at\": 1699063291,\n      \"last_error\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": null,\n      \"incomplete_details\": null,\n      \"tools\": [\n        {\n          \"type\": \"code_interpreter\"\n        }\n      ],\n      \"tool_resources\": {\n        \"code_interpreter\": {\n          \"file_ids\": [\n            \"file-abc123\",\n            \"file-abc456\"\n          ]\n        }\n      },\n     ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 307900, "end_char": 308500}, "617": {"text": "le_ids\": [\n            \"file-abc123\",\n            \"file-abc456\"\n          ]\n        }\n      },\n      \"metadata\": {},\n      \"usage\": {\n        \"prompt_tokens\": 123,\n        \"completion_tokens\": 456,\n        \"total_tokens\": 579\n      },\n      \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_prompt_tokens\": 1000,\n      \"max_completion_tokens\": 1000,\n      \"truncation_strategy\": {\n        \"type\": \"auto\",\n        \"last_messages\": null\n      },\n      \"response_format\": \"auto\",\n      \"tool_choice\": \"auto\",\n      \"parallel_tool_calls\": true\n    }\n  ],\n  \"first_id\": \"run_abc123\",\n  \"last_id\": \"run_ab", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 308400, "end_char": 309000}, "618": {"text": "auto\",\n      \"parallel_tool_calls\": true\n    }\n  ],\n  \"first_id\": \"run_abc123\",\n  \"last_id\": \"run_abc456\",\n  \"has_more\": false\n}\nRetrieve run\nBeta\nget\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs/{run_id}\nRetrieves a run.\n\nPath parameters\nrun_id\nstring\n\nRequired\nThe ID of the run to retrieve.\n\nthread_id\nstring\n\nRequired\nThe ID of the thread that was run.\n\nReturns\nThe run object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.retrieve(\n  thread_id=\"thread_abc123\",\n  run_id=\"run_abc123\"\n)\n\nprint(run)\nResponse\n{\n  \"id", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 308900, "end_char": 309500}, "619": {"text": "ads.runs.retrieve(\n  thread_id=\"thread_abc123\",\n  run_id=\"run_abc123\"\n)\n\nprint(run)\nResponse\n{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699075072,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n  \"started_at\": 1699075072,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699075073,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"incomplete_details\": null,\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"usage\": {\n    \"prompt_tokens\": 12", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 309400, "end_char": 310000}, "620": {"text": "{\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  },\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\nModify run\nBeta\npost\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs/{run_id}\nModifies a run.\n\nPath parameters\nrun_id\nstring\n\nRequired\nThe ID of the run to modify.\n\nthre", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 309900, "end_char": 310500}, "621": {"text": "{run_id}\nModifies a run.\n\nPath parameters\nrun_id\nstring\n\nRequired\nThe ID of the run to modify.\n\nthread_id\nstring\n\nRequired\nThe ID of the thread that was run.\n\nRequest body\nmetadata\nmap\n\nOptional\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nReturns\nThe modified run object matching the specified ID.\n\nExample request\nfro", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 310400, "end_char": 311000}, "622": {"text": " of 512 characters.\n\nReturns\nThe modified run object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.update(\n  thread_id=\"thread_abc123\",\n  run_id=\"run_abc123\",\n  metadata={\"user_id\": \"user_abc123\"},\n)\n\nprint(run)\nResponse\n{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699075072,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n  \"started_at\": 1699075072,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699075073,\n  \"last_erro", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 310900, "end_char": 311500}, "623": {"text": "s_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699075073,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"incomplete_details\": null,\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"tool_resources\": {\n    \"code_interpreter\": {\n      \"file_ids\": [\n        \"file-abc123\",\n        \"file-abc456\"\n      ]\n    }\n  },\n  \"metadata\": {\n    \"user_id\": \"user_abc123\"\n  },\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  },\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"ma", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 311400, "end_char": 312000}, "624": {"text": "   \"total_tokens\": 579\n  },\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\nSubmit tool outputs to run\nBeta\npost\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/submit_tool_outputs\nWhen a run has the status: \"requires_action\" and required_action.type is submit_tool_outputs, this endpoint can be used to submit the outputs from the tool calls once they're all completed.", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 311900, "end_char": 312500}, "625": {"text": "uts, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.\n\nPath parameters\nrun_id\nstring\n\nRequired\nThe ID of the run that requires the tool output submission.\n\nthread_id\nstring\n\nRequired\nThe ID of the thread to which this run belongs.\n\nRequest body\ntool_outputs\narray\n\nRequired\nA list of tools for which the outputs are being submitted.\n\n\nShow properties\nstream\nboolean or null\n\nOptional\nIf true, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 312400, "end_char": 313000}, "626": {"text": " stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a data: [DONE] message.\n\nReturns\nThe modified run object matching the specified ID.\n\n\nDefault\n\nStreaming\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.submit_tool_outputs(\n  thread_id=\"thread_123\",\n  run_id=\"run_123\",\n  tool_outputs=[\n    {\n      \"tool_call_id\": \"call_001\",\n      \"output\": \"70 degrees and sunny.\"\n    }\n  ]\n)\n\nprint(run)\nResponse\n{\n  \"id\": \"run_123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699075592,\n  \"assist", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 312900, "end_char": 313500}, "627": {"text": "t(run)\nResponse\n{\n  \"id\": \"run_123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699075592,\n  \"assistant_id\": \"asst_123\",\n  \"thread_id\": \"thread_123\",\n  \"status\": \"queued\",\n  \"started_at\": 1699075592,\n  \"expires_at\": 1699076192,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"parameters\": {\n          \"type\": \"object\",\n          ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 313400, "end_char": 314000}, "628": {"text": "current weather in a given location\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"location\": {\n              \"type\": \"string\",\n              \"description\": \"The city and state, e.g. San Francisco, CA\"\n            },\n            \"unit\": {\n              \"type\": \"string\",\n              \"enum\": [\"celsius\", \"fahrenheit\"]\n            }\n          },\n          \"required\": [\"location\"]\n        }\n      }\n    }\n  ],\n  \"metadata\": {},\n  \"usage\": null,\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"trunca", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 313900, "end_char": 314500}, "629": {"text": "ature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\nCancel a run\nBeta\npost\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/cancel\nCancels a run that is in_progress.\n\nPath parameters\nrun_id\nstring\n\nRequired\nThe ID of the run to cancel.\n\nthread_id\nstring\n\nRequired\nThe ID of the thread to which this run belongs.\n\nReturns\nThe modified run object matching the specified ID.\n\nExample req", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 314400, "end_char": 315000}, "630": {"text": " to which this run belongs.\n\nReturns\nThe modified run object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.cancel(\n  thread_id=\"thread_abc123\",\n  run_id=\"run_abc123\"\n)\n\nprint(run)\nResponse\n{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699076126,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"cancelling\",\n  \"started_at\": 1699076126,\n  \"expires_at\": 1699076726,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 314900, "end_char": 315500}, "631": {"text": "_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You summarize books.\",\n  \"tools\": [\n    {\n      \"type\": \"file_search\"\n    }\n  ],\n  \"tool_resources\": {\n    \"file_search\": {\n      \"vector_store_ids\": [\"vs_123\"]\n    }\n  },\n  \"metadata\": {},\n  \"usage\": null,\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\nThe run object\nBeta\nRepresents an execution run on a thread.\n\nassistant_id\nstring\n\nThe ID of the assistant used for execution of this run.\n\ncancelled_", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 315400, "end_char": 316000}, "632": {"text": " a thread.\n\nassistant_id\nstring\n\nThe ID of the assistant used for execution of this run.\n\ncancelled_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run was cancelled.\n\ncompleted_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run was completed.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the run was created.\n\nexpires_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run will expire.\n\nfailed_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run failed.\n\nid\nstring\n\nThe identifier, which can be referenced in API end", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 315900, "end_char": 316500}, "633": {"text": "(in seconds) for when the run failed.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints.\n\nincomplete_details\nobject or null\n\nDetails on why the run is incomplete. Will be null if the run is not incomplete.\n\n\nShow properties\ninstructions\nstring\n\nThe instructions that the assistant used for this run.\n\nlast_error\nobject or null\n\nThe last error associated with this run. Will be null if there are no errors.\n\n\nShow properties\nmax_completion_tokens\ninteger or null\n\nThe maximum number of completion tokens specified to have been used over the course of the run.\n\nmax_prompt_tokens\nint", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 316400, "end_char": 317000}, "634": {"text": " of completion tokens specified to have been used over the course of the run.\n\nmax_prompt_tokens\ninteger or null\n\nThe maximum number of prompt tokens specified to have been used over the course of the run.\n\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nmodel\nstring\n\nThe model that the assistant used for t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 316900, "end_char": 317500}, "635": {"text": "ings with a maximum length of 512 characters.\n\nmodel\nstring\n\nThe model that the assistant used for this run.\n\nobject\nstring\n\nThe object type, which is always thread.run.\n\nparallel_tool_calls\nboolean\n\nWhether to enable parallel function calling during tool use.\n\nrequired_action\nobject or null\n\nDetails on the action required to continue the run. Will be null if no action is required.\n\n\nShow properties\nresponse_format\n\"auto\" or object\n\nSpecifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.\n\nSetting to { \"type\": ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 317400, "end_char": 318000}, "636": {"text": "h GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.\n\nSetting to { \"type\": \"json_schema\", \"json_schema\": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.\n\nSetting to { \"type\": \"json_object\" } enables JSON mode, which ensures the message the model generates is valid JSON.\n\nImportant: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generatio", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 317900, "end_char": 318500}, "637": {"text": "r message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.\n\n\nShow possible types\nstarted_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run was started.\n\nstatus\nstring\n\nThe status of the run, which can be either queued, in_progress, requires_action, cancelling, ca", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 318400, "end_char": 319000}, "638": {"text": "ing\n\nThe status of the run, which can be either queued, in_progress, requires_action, cancelling, cancelled, failed, completed, incomplete, or expired.\n\ntemperature\nnumber or null\n\nThe sampling temperature used for this run. If not set, defaults to 1.\n\nthread_id\nstring\n\nThe ID of the thread that was executed on as a part of this run.\n\ntool_choice\nstring or object\n\nControls which (if any) tool is called by the model. none means the model will not call any tools and instead generates a message. auto is the default value and means the model can pick between generating a message or calling one or ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 318900, "end_char": 319500}, "639": {"text": "to is the default value and means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools before responding to the user. Specifying a particular tool like {\"type\": \"file_search\"} or {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that tool.\n\n\nShow possible types\ntools\narray\n\nThe list of tools that the assistant used for this run.\n\n\nShow possible types\ntop_p\nnumber or null\n\nThe nucleus sampling value used for this run. If not set, defaults to 1.\n\ntruncation_strategy\nobject or null\n\nCont", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 319400, "end_char": 320000}, "640": {"text": "mpling value used for this run. If not set, defaults to 1.\n\ntruncation_strategy\nobject or null\n\nControls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.\n\n\nShow properties\nusage\nobject or null\n\nUsage statistics related to the run. This value will be null if the run is not in a terminal state (i.e. in_progress, queued, etc.).\n\n\nShow properties\nOBJECT The run object\n{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1698107661,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n  \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 319900, "end_char": 320500}, "641": {"text": "07661,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n  \"started_at\": 1699073476,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699073498,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"tools\": [{\"type\": \"file_search\"}, {\"type\": \"code_interpreter\"}],\n  \"metadata\": {},\n  \"incomplete_details\": null,\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  },\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 100", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 320400, "end_char": 321000}, "642": {"text": "},\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\nRun steps\nBeta\nRepresents the steps (model and tool calls) taken during the run.\n\nRelated guide: Assistants\n\nList run steps\nBeta\nget\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/steps\nReturns a list of run steps belonging to a run.\n\nPath parameters\nrun_id\nstring\n\nRequired\nThe ID of the run the run steps belong to.\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 320900, "end_char": 321500}, "643": {"text": "nging to a run.\n\nPath parameters\nrun_id\nstring\n\nRequired\nThe ID of the run the run steps belong to.\n\nthread_id\nstring\n\nRequired\nThe ID of the thread the run and run steps belong to.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\n\nOptional\nA cursor for use in pagination. before is an object ID that defines your place in ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 321400, "end_char": 322000}, "644": {"text": "\nstring\n\nOptional\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\ninclude[]\narray\n\nOptional\nA list of additional fields to include in the response. Currently the only supported value is step_details.tool_calls[*].file_search.results[*].content to fetch the file search result content.\n\nSee the file search tool documentation for more information.\n\nlimit\ninteger\n\nOption", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 321900, "end_char": 322500}, "645": {"text": "result content.\n\nSee the file search tool documentation for more information.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\n\nOptional\nDefaults to desc\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nReturns\nA list of run step objects.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nrun_steps = client.beta.threads.runs.steps.list(\n    thread_id=\"thread_abc123\",\n    run_id=\"run_abc123\"\n)\n\nprint(run_steps)\nR", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 322400, "end_char": 323000}, "646": {"text": "hreads.runs.steps.list(\n    thread_id=\"thread_abc123\",\n    run_id=\"run_abc123\"\n)\n\nprint(run_steps)\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"step_abc123\",\n      \"object\": \"thread.run.step\",\n      \"created_at\": 1699063291,\n      \"run_id\": \"run_abc123\",\n      \"assistant_id\": \"asst_abc123\",\n      \"thread_id\": \"thread_abc123\",\n      \"type\": \"message_creation\",\n      \"status\": \"completed\",\n      \"cancelled_at\": null,\n      \"completed_at\": 1699063291,\n      \"expired_at\": null,\n      \"failed_at\": null,\n      \"last_error\": null,\n      \"step_details\": {\n        \"type\": \"message_crea", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 322900, "end_char": 323500}, "647": {"text": "  \"failed_at\": null,\n      \"last_error\": null,\n      \"step_details\": {\n        \"type\": \"message_creation\",\n        \"message_creation\": {\n          \"message_id\": \"msg_abc123\"\n        }\n      },\n      \"usage\": {\n        \"prompt_tokens\": 123,\n        \"completion_tokens\": 456,\n        \"total_tokens\": 579\n      }\n    }\n  ],\n  \"first_id\": \"step_abc123\",\n  \"last_id\": \"step_abc456\",\n  \"has_more\": false\n}\nRetrieve run step\nBeta\nget\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/steps/{step_id}\nRetrieves a run step.\n\nPath parameters\nrun_id\nstring\n\nRequired\nThe ID of the run to which the r", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 323400, "end_char": 324000}, "648": {"text": "_id}\nRetrieves a run step.\n\nPath parameters\nrun_id\nstring\n\nRequired\nThe ID of the run to which the run step belongs.\n\nstep_id\nstring\n\nRequired\nThe ID of the run step to retrieve.\n\nthread_id\nstring\n\nRequired\nThe ID of the thread to which the run and run step belongs.\n\nQuery parameters\ninclude[]\narray\n\nOptional\nA list of additional fields to include in the response. Currently the only supported value is step_details.tool_calls[*].file_search.results[*].content to fetch the file search result content.\n\nSee the file search tool documentation for more information.\n\nReturns\nThe run step object match", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 323900, "end_char": 324500}, "649": {"text": "nt.\n\nSee the file search tool documentation for more information.\n\nReturns\nThe run step object matching the specified ID.\n\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nrun_step = client.beta.threads.runs.steps.retrieve(\n    thread_id=\"thread_abc123\",\n    run_id=\"run_abc123\",\n    step_id=\"step_abc123\"\n)\n\nprint(run_step)\nResponse\n{\n  \"id\": \"step_abc123\",\n  \"object\": \"thread.run.step\",\n  \"created_at\": 1699063291,\n  \"run_id\": \"run_abc123\",\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"type\": \"message_creation\",\n  \"status\": \"completed\",\n  \"cancelled_at\": null,\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 324400, "end_char": 325000}, "650": {"text": "d\": \"thread_abc123\",\n  \"type\": \"message_creation\",\n  \"status\": \"completed\",\n  \"cancelled_at\": null,\n  \"completed_at\": 1699063291,\n  \"expired_at\": null,\n  \"failed_at\": null,\n  \"last_error\": null,\n  \"step_details\": {\n    \"type\": \"message_creation\",\n    \"message_creation\": {\n      \"message_id\": \"msg_abc123\"\n    }\n  },\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  }\n}\nThe run step object\nBeta\nRepresents a step in execution of a run.\n\nassistant_id\nstring\n\nThe ID of the assistant associated with the run step.\n\ncancelled_at\ninteger or null\n\nThe Unix ti", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 324900, "end_char": 325500}, "651": {"text": "ng\n\nThe ID of the assistant associated with the run step.\n\ncancelled_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run step was cancelled.\n\ncompleted_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run step completed.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the run step was created.\n\nexpired_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.\n\nfailed_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run step failed.\n\nid\nstring\n\nThe i", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 325400, "end_char": 326000}, "652": {"text": "_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run step failed.\n\nid\nstring\n\nThe identifier of the run step, which can be referenced in API endpoints.\n\nlast_error\nobject or null\n\nThe last error associated with this run step. Will be null if there are no errors.\n\n\nShow properties\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 325900, "end_char": 326500}, "653": {"text": " or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.\n\nobject\nstring\n\nThe object type, which is always thread.run.step.\n\nrun_id\nstring\n\nThe ID of the run that this run step is a part of.\n\nstatus\nstring\n\nThe status of the run step, which can be either in_progress, cancelled, failed, completed, or expired.\n\nstep_details\nobject\n\nThe details of the run step.\n\n\nShow possible types\nthread_id\nstring\n\nThe ID of the thread that was run.\n\ntype\nstring\n\nThe type of run step, which can be either message_creation or tool_call", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 326400, "end_char": 327000}, "654": {"text": " that was run.\n\ntype\nstring\n\nThe type of run step, which can be either message_creation or tool_calls.\n\nusage\nobject or null\n\nUsage statistics related to the run step. This value will be null while the run step's status is in_progress.\n\n\nShow properties\nOBJECT The run step object\n{\n  \"id\": \"step_abc123\",\n  \"object\": \"thread.run.step\",\n  \"created_at\": 1699063291,\n  \"run_id\": \"run_abc123\",\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"type\": \"message_creation\",\n  \"status\": \"completed\",\n  \"cancelled_at\": null,\n  \"completed_at\": 1699063291,\n  \"expired_at\": null,\n  \"failed_at\"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 326900, "end_char": 327500}, "655": {"text": "ompleted\",\n  \"cancelled_at\": null,\n  \"completed_at\": 1699063291,\n  \"expired_at\": null,\n  \"failed_at\": null,\n  \"last_error\": null,\n  \"step_details\": {\n    \"type\": \"message_creation\",\n    \"message_creation\": {\n      \"message_id\": \"msg_abc123\"\n    }\n  },\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  }\n}\nStreaming\nBeta\nStream the result of executing a Run or resuming a Run after submitting tool outputs. You can stream events from the Create Thread and Run, Create Run, and Submit Tool Outputs endpoints by passing \"stream\": true. The response will be ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 327400, "end_char": 328000}, "656": {"text": " Run, Create Run, and Submit Tool Outputs endpoints by passing \"stream\": true. The response will be a Server-Sent events stream. Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the Assistants API quickstart to learn more.\n\nThe message delta object\nBeta\nRepresents a message delta i.e. any changed fields on a message during streaming.\n\ndelta\nobject\n\nThe delta containing the fields that have changed on the Message.\n\n\nShow properties\nid\nstring\n\nThe identifier of the message, which can be referenced in API endpoints.\n\nobject\nstring\n\nThe object type, which is alw", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 327900, "end_char": 328500}, "657": {"text": "the message, which can be referenced in API endpoints.\n\nobject\nstring\n\nThe object type, which is always thread.message.delta.\n\nOBJECT The message delta object\n{\n  \"id\": \"msg_123\",\n  \"object\": \"thread.message.delta\",\n  \"delta\": {\n    \"content\": [\n      {\n        \"index\": 0,\n        \"type\": \"text\",\n        \"text\": { \"value\": \"Hello\", \"annotations\": [] }\n      }\n    ]\n  }\n}\nThe run step delta object\nBeta\nRepresents a run step delta i.e. any changed fields on a run step during streaming.\n\ndelta\nobject\n\nThe delta containing the fields that have changed on the run step.\n\n\nShow properties\nid\nstring\n\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 328400, "end_char": 329000}, "658": {"text": "ct\n\nThe delta containing the fields that have changed on the run step.\n\n\nShow properties\nid\nstring\n\nThe identifier of the run step, which can be referenced in API endpoints.\n\nobject\nstring\n\nThe object type, which is always thread.run.step.delta.\n\nOBJECT The run step delta object\n{\n  \"id\": \"step_123\",\n  \"object\": \"thread.run.step.delta\",\n  \"delta\": {\n    \"step_details\": {\n      \"type\": \"tool_calls\",\n      \"tool_calls\": [\n        {\n          \"index\": 0,\n          \"id\": \"call_123\",\n          \"type\": \"code_interpreter\",\n          \"code_interpreter\": { \"input\": \"\", \"outputs\": [] }\n        }\n      ]", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 328900, "end_char": 329500}, "659": {"text": ": \"code_interpreter\",\n          \"code_interpreter\": { \"input\": \"\", \"outputs\": [] }\n        }\n      ]\n    }\n  }\n}\nAssistant stream events\nBeta\nRepresents an event emitted when streaming a Run.\n\nEach event in a server-sent events stream has an event and data property:\n\nevent: thread.created\ndata: {\"id\": \"thread_123\", \"object\": \"thread\", ...}\nWe emit events whenever a new object is created, transitions to a new state, or is being streamed in parts (deltas). For example, we emit thread.run.created when a new run is created, thread.run.completed when a run completes, and so on. When an Assistant ch", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 329400, "end_char": 330000}, "660": {"text": "hen a new run is created, thread.run.completed when a run completes, and so on. When an Assistant chooses to create a message during a run, we emit a thread.message.created event, a thread.message.in_progress event, many thread.message.delta events, and finally a thread.message.completed event.\n\nWe may add additional events over time, so we recommend handling unknown events gracefully in your code. See the Assistants API quickstart to learn how to integrate the Assistants API with streaming.\n\ndone\ndata is [DONE]\n\nOccurs when a stream ends.\n\nerror\ndata is an error\n\nOccurs when an error occurs. ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 329900, "end_char": 330500}, "661": {"text": "ne\ndata is [DONE]\n\nOccurs when a stream ends.\n\nerror\ndata is an error\n\nOccurs when an error occurs. This can happen due to an internal server error or a timeout.\n\nthread.created\ndata is a thread\n\nOccurs when a new thread is created.\n\nthread.message.completed\ndata is a message\n\nOccurs when a message is completed.\n\nthread.message.created\ndata is a message\n\nOccurs when a message is created.\n\nthread.message.delta\ndata is a message delta\n\nOccurs when parts of a Message are being streamed.\n\nthread.message.in_progress\ndata is a message\n\nOccurs when a message moves to an in_progress state.\n\nthread.mes", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 330400, "end_char": 331000}, "662": {"text": "sage.in_progress\ndata is a message\n\nOccurs when a message moves to an in_progress state.\n\nthread.message.incomplete\ndata is a message\n\nOccurs when a message ends before it is completed.\n\nthread.run.cancelled\ndata is a run\n\nOccurs when a run is cancelled.\n\nthread.run.cancelling\ndata is a run\n\nOccurs when a run moves to a cancelling status.\n\nthread.run.completed\ndata is a run\n\nOccurs when a run is completed.\n\nthread.run.created\ndata is a run\n\nOccurs when a new run is created.\n\nthread.run.expired\ndata is a run\n\nOccurs when a run expires.\n\nthread.run.failed\ndata is a run\n\nOccurs when a run fails.\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 330900, "end_char": 331500}, "663": {"text": "ata is a run\n\nOccurs when a run expires.\n\nthread.run.failed\ndata is a run\n\nOccurs when a run fails.\n\nthread.run.in_progress\ndata is a run\n\nOccurs when a run moves to an in_progress status.\n\nthread.run.incomplete\ndata is a run\n\nOccurs when a run ends with status incomplete.\n\nthread.run.queued\ndata is a run\n\nOccurs when a run moves to a queued status.\n\nthread.run.requires_action\ndata is a run\n\nOccurs when a run moves to a requires_action status.\n\nthread.run.step.cancelled\ndata is a run step\n\nOccurs when a run step is cancelled.\n\nthread.run.step.completed\ndata is a run step\n\nOccurs when a run ste", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 331400, "end_char": 332000}, "664": {"text": "s when a run step is cancelled.\n\nthread.run.step.completed\ndata is a run step\n\nOccurs when a run step is completed.\n\nthread.run.step.created\ndata is a run step\n\nOccurs when a run step is created.\n\nthread.run.step.delta\ndata is a run step delta\n\nOccurs when parts of a run step are being streamed.\n\nthread.run.step.expired\ndata is a run step\n\nOccurs when a run step expires.\n\nthread.run.step.failed\ndata is a run step\n\nOccurs when a run step fails.\n\nthread.run.step.in_progress\ndata is a run step\n\nOccurs when a run step moves to an in_progress state.\n\nAdministration\nProgrammatically manage your orga", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 331900, "end_char": 332500}, "665": {"text": "urs when a run step moves to an in_progress state.\n\nAdministration\nProgrammatically manage your organization. The Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes. To access these endpoints please generate an Admin API Key through the API Platform Organization overview. Admin API keys cannot be used for non-administration endpoints. For best practices on setting up your organization, please refer to this guide\n\nAdmin API Keys\nAdmin API keys enable Organization Owners to programmatically manage various aspects of their organization", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 332400, "end_char": 333000}, "666": {"text": "API keys enable Organization Owners to programmatically manage various aspects of their organization, including users, projects, and API keys. These keys provide administrative capabilities, such as creating, updating, and deleting users; managing projects; and overseeing API key lifecycles.\n\nKey Features of Admin API Keys:\n\nUser Management: Invite new users, update roles, and remove users from the organization.\n\nProject Management: Create, update, archive projects, and manage user assignments within projects.\n\nAPI Key Oversight: List, retrieve, and delete API keys associated with projects.\n\nO", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 332900, "end_char": 333500}, "667": {"text": "ithin projects.\n\nAPI Key Oversight: List, retrieve, and delete API keys associated with projects.\n\nOnly Organization Owners have the authority to create and utilize Admin API keys. To manage these keys, Organization Owners can navigate to the Admin Keys section of their API Platform dashboard.\n\nFor direct access to the Admin Keys management page, Organization Owners can use the following link:\n\nhttps://platform.openai.com/settings/organization/admin-keys\n\nIt's crucial to handle Admin API keys with care due to their elevated permissions. Adhering to best practices, such as regular key rotation ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 333400, "end_char": 334000}, "668": {"text": "th care due to their elevated permissions. Adhering to best practices, such as regular key rotation and assigning appropriate permissions, enhances security and ensures proper governance within the organization.\n\nList all organization and project API keys.\nget\n \nhttps://api.openai.com/v1/organization/admin_api_keys\nList organization API keys\n\nQuery parameters\nafter\nstring or null\n\nOptional\nlimit\ninteger\n\nOptional\nDefaults to 20\norder\nstring\n\nOptional\nDefaults to asc\nReturns\nA list of admin and project API key objects.\n\nExample request\ncurl https://api.openai.com/v1/organization/admin_api_keys?", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 333900, "end_char": 334500}, "669": {"text": "roject API key objects.\n\nExample request\ncurl https://api.openai.com/v1/organization/admin_api_keys?after=key_abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"organization.admin_api_key\",\n      \"id\": \"key_abc\",\n      \"name\": \"Main Admin Key\",\n      \"redacted_value\": \"sk-admin...def\",\n      \"created_at\": 1711471533,\n      \"owner\": {\n        \"type\": \"service_account\",\n        \"object\": \"organization.service_account\",\n        \"id\": \"sa_456\",\n        \"name\": \"My Service Account\",\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 334400, "end_char": 335000}, "670": {"text": "ect\": \"organization.service_account\",\n        \"id\": \"sa_456\",\n        \"name\": \"My Service Account\",\n        \"created_at\": 1711471533,\n        \"role\": \"member\"\n      }\n    }\n  ],\n  \"first_id\": \"key_abc\",\n  \"last_id\": \"key_abc\",\n  \"has_more\": false\n}\nCreate admin API key\npost\n \nhttps://api.openai.com/v1/organization/admin_api_keys\nCreate an organization admin API key\n\nRequest body\nname\nstring\n\nRequired\nReturns\nThe created admin API key object.\n\nExample request\ncurl -X POST https://api.openai.com/v1/organization/admin_api_keys \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type:", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 334900, "end_char": 335500}, "671": {"text": "1/organization/admin_api_keys \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"name\": \"New Admin Key\"\n  }'\nResponse\n{\n  \"object\": \"organization.admin_api_key\",\n  \"id\": \"key_xyz\",\n  \"name\": \"New Admin Key\",\n  \"redacted_value\": \"sk-admin...xyz\",\n  \"created_at\": 1711471533,\n  \"owner\": {\n    \"type\": \"user\",\n    \"object\": \"organization.user\",\n    \"id\": \"user_123\",\n    \"name\": \"John Doe\",\n    \"created_at\": 1711471533,\n    \"role\": \"owner\"\n  },\n  \"value\": \"sk-admin-1234abcd\"\n}\nRetrieve admin API key\nget\n \nhttps://api.openai.com/v1/organization/a", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 335400, "end_char": 336000}, "672": {"text": "\"value\": \"sk-admin-1234abcd\"\n}\nRetrieve admin API key\nget\n \nhttps://api.openai.com/v1/organization/admin_api_keys/{key_id}\nRetrieve a single organization API key\n\nPath parameters\nkey_id\nstring\n\nRequired\nReturns\nThe requested admin API key object.\n\nExample request\ncurl https://api.openai.com/v1/organization/admin_api_keys/key_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n  \"object\": \"organization.admin_api_key\",\n  \"id\": \"key_abc\",\n  \"name\": \"Main Admin Key\",\n  \"redacted_value\": \"sk-admin...xyz\",\n  \"created_at\": 1711471533,\n  \"owner\": {\n ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 335900, "end_char": 336500}, "673": {"text": ": \"Main Admin Key\",\n  \"redacted_value\": \"sk-admin...xyz\",\n  \"created_at\": 1711471533,\n  \"owner\": {\n    \"type\": \"user\",\n    \"object\": \"organization.user\",\n    \"id\": \"user_123\",\n    \"name\": \"John Doe\",\n    \"created_at\": 1711471533,\n    \"role\": \"owner\"\n  }\n}\nDelete admin API key\ndelete\n \nhttps://api.openai.com/v1/organization/admin_api_keys/{key_id}\nDelete an organization admin API key\n\nPath parameters\nkey_id\nstring\n\nRequired\nReturns\nA confirmation object indicating the key was deleted.\n\nExample request\ncurl -X DELETE https://api.openai.com/v1/organization/admin_api_keys/key_abc \\\n  -H \"Authoriza", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 336400, "end_char": 337000}, "674": {"text": "quest\ncurl -X DELETE https://api.openai.com/v1/organization/admin_api_keys/key_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n  \"id\": \"key_abc\",\n  \"object\": \"organization.admin_api_key.deleted\",\n  \"deleted\": true\n}\nInvites\nInvite and manage invitations for an organization.\n\nList invites\nget\n \nhttps://api.openai.com/v1/organization/invites\nReturns a list of invites in the organization.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you ma", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 336900, "end_char": 337500}, "675": {"text": "se in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\nReturns\nA list of Invite objects.\n\nExample request\ncurl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Ty", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 337400, "end_char": 338000}, "676": {"text": "nvites?after=invite-abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"organization.invite\",\n      \"id\": \"invite-abc\",\n      \"email\": \"user@example.com\",\n      \"role\": \"owner\",\n      \"status\": \"accepted\",\n      \"invited_at\": 1711471533,\n      \"expires_at\": 1711471533,\n      \"accepted_at\": 1711471533\n    }\n  ],\n  \"first_id\": \"invite-abc\",\n  \"last_id\": \"invite-abc\",\n  \"has_more\": false\n}\nCreate invite\npost\n \nhttps://api.openai.com/v1/organization/invites\nCreate an invite for a use", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 337900, "end_char": 338500}, "677": {"text": "lse\n}\nCreate invite\npost\n \nhttps://api.openai.com/v1/organization/invites\nCreate an invite for a user to the organization. The invite must be accepted by the user before they have access to the organization.\n\nRequest body\nemail\nstring\n\nRequired\nSend an email to this address\n\nrole\nstring\n\nRequired\nowner or reader\n\nprojects\narray\n\nOptional\nAn array of projects to which membership is granted at the same time the org invite is accepted. If omitted, the user will be invited to the default project for compatibility with legacy behavior.\n\n\nShow properties\nReturns\nThe created Invite object.\n\nExample r", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 338400, "end_char": 339000}, "678": {"text": " compatibility with legacy behavior.\n\n\nShow properties\nReturns\nThe created Invite object.\n\nExample request\ncurl -X POST https://api.openai.com/v1/organization/invites \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"email\": \"anotheruser@example.com\",\n      \"role\": \"reader\",\n      \"projects\": [\n        {\n          \"id\": \"project-xyz\",\n          \"role\": \"member\"\n        },\n        {\n          \"id\": \"project-abc\",\n          \"role\": \"owner\"\n        }\n      ]\n  }'\nResponse\n{\n  \"object\": \"organization.invite\",\n  \"id\": \"invite-def\",\n  \"email\": ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 338900, "end_char": 339500}, "679": {"text": "      }\n      ]\n  }'\nResponse\n{\n  \"object\": \"organization.invite\",\n  \"id\": \"invite-def\",\n  \"email\": \"anotheruser@example.com\",\n  \"role\": \"reader\",\n  \"status\": \"pending\",\n  \"invited_at\": 1711471533,\n  \"expires_at\": 1711471533,\n  \"accepted_at\": null,\n  \"projects\": [\n    {\n      \"id\": \"project-xyz\",\n      \"role\": \"member\"\n    },\n    {\n      \"id\": \"project-abc\",\n      \"role\": \"owner\"\n    }\n  ]\n}\nRetrieve invite\nget\n \nhttps://api.openai.com/v1/organization/invites/{invite_id}\nRetrieves an invite.\n\nPath parameters\ninvite_id\nstring\n\nRequired\nThe ID of the invite to retrieve.\n\nReturns\nThe Invite objec", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 339400, "end_char": 340000}, "680": {"text": "th parameters\ninvite_id\nstring\n\nRequired\nThe ID of the invite to retrieve.\n\nReturns\nThe Invite object matching the specified ID.\n\nExample request\ncurl https://api.openai.com/v1/organization/invites/invite-abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"organization.invite\",\n    \"id\": \"invite-abc\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"status\": \"accepted\",\n    \"invited_at\": 1711471533,\n    \"expires_at\": 1711471533,\n    \"accepted_at\": 1711471533\n}\nDelete invite\ndelete\n \nhttps://api.openai.com/v1/organizat", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 339900, "end_char": 340500}, "681": {"text": "11471533,\n    \"accepted_at\": 1711471533\n}\nDelete invite\ndelete\n \nhttps://api.openai.com/v1/organization/invites/{invite_id}\nDelete an invite. If the invite has already been accepted, it cannot be deleted.\n\nPath parameters\ninvite_id\nstring\n\nRequired\nThe ID of the invite to delete.\n\nReturns\nConfirmation that the invite has been deleted\n\nExample request\ncurl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"organization.invite.deleted\",\n    \"id\": \"invite-abc\",\n    \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 340400, "end_char": 341000}, "682": {"text": "lication/json\"\nResponse\n{\n    \"object\": \"organization.invite.deleted\",\n    \"id\": \"invite-abc\",\n    \"deleted\": true\n}\nThe invite object\nRepresents an individual invite to the organization.\n\naccepted_at\ninteger\n\nThe Unix timestamp (in seconds) of when the invite was accepted.\n\nemail\nstring\n\nThe email address of the individual to whom the invite was sent\n\nexpires_at\ninteger\n\nThe Unix timestamp (in seconds) of when the invite expires.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints\n\ninvited_at\ninteger\n\nThe Unix timestamp (in seconds) of when the invite was sent.\n\nobject\nstring", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 340900, "end_char": 341500}, "683": {"text": "nts\n\ninvited_at\ninteger\n\nThe Unix timestamp (in seconds) of when the invite was sent.\n\nobject\nstring\n\nThe object type, which is always organization.invite\n\nprojects\narray\n\nThe projects that were granted membership upon acceptance of the invite.\n\n\nShow properties\nrole\nstring\n\nowner or reader\n\nstatus\nstring\n\naccepted,expired, or pending\n\nOBJECT The invite object\n{\n  \"object\": \"organization.invite\",\n  \"id\": \"invite-abc\",\n  \"email\": \"user@example.com\",\n  \"role\": \"owner\",\n  \"status\": \"accepted\",\n  \"invited_at\": 1711471533,\n  \"expires_at\": 1711471533,\n  \"accepted_at\": 1711471533,\n  \"projects\": [\n   ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 341400, "end_char": 342000}, "684": {"text": "nvited_at\": 1711471533,\n  \"expires_at\": 1711471533,\n  \"accepted_at\": 1711471533,\n  \"projects\": [\n    {\n      \"id\": \"project-xyz\",\n      \"role\": \"member\"\n    }\n  ]\n}\nUsers\nManage users and their role in an organization.\n\nList users\nget\n \nhttps://api.openai.com/v1/organization/users\nLists all of the users in the organization.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 341900, "end_char": 342500}, "685": {"text": "nd receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nemails\narray\n\nOptional\nFilter by the email address of users.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\nReturns\nA list of User objects.\n\nExample request\ncurl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"list\",\n    \"dat", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 342400, "end_char": 343000}, "686": {"text": "$OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"object\": \"organization.user\",\n            \"id\": \"user_abc\",\n            \"name\": \"First Last\",\n            \"email\": \"user@example.com\",\n            \"role\": \"owner\",\n            \"added_at\": 1711471533\n        }\n    ],\n    \"first_id\": \"user-abc\",\n    \"last_id\": \"user-xyz\",\n    \"has_more\": false\n}\nModify user\npost\n \nhttps://api.openai.com/v1/organization/users/{user_id}\nModifies a user's role in the organization.\n\nPath parameters\nuser_id\nstring\n\nRequired\nThe ID of the us", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 342900, "end_char": 343500}, "687": {"text": "difies a user's role in the organization.\n\nPath parameters\nuser_id\nstring\n\nRequired\nThe ID of the user.\n\nRequest body\nrole\nstring\n\nRequired\nowner or reader\n\nReturns\nThe updated User object.\n\nExample request\ncurl -X POST https://api.openai.com/v1/organization/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"role\": \"owner\"\n  }'\nResponse\n{\n    \"object\": \"organization.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\nRetrieve user\nget\n \nhtt", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 343400, "end_char": 344000}, "688": {"text": "mail\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\nRetrieve user\nget\n \nhttps://api.openai.com/v1/organization/users/{user_id}\nRetrieves a user by their identifier.\n\nPath parameters\nuser_id\nstring\n\nRequired\nThe ID of the user.\n\nReturns\nThe User object matching the specified ID.\n\nExample request\ncurl https://api.openai.com/v1/organization/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"organization.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 343900, "end_char": 344500}, "689": {"text": "ization.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\nDelete user\ndelete\n \nhttps://api.openai.com/v1/organization/users/{user_id}\nDeletes a user from the organization.\n\nPath parameters\nuser_id\nstring\n\nRequired\nThe ID of the user.\n\nReturns\nConfirmation of the deleted user\n\nExample request\ncurl -X DELETE https://api.openai.com/v1/organization/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"organization.user.deleted\",\n    \"id", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 344400, "end_char": 345000}, "690": {"text": "\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"organization.user.deleted\",\n    \"id\": \"user_abc\",\n    \"deleted\": true\n}\nThe user object\nRepresents an individual user within an organization.\n\nadded_at\ninteger\n\nThe Unix timestamp (in seconds) of when the user was added.\n\nemail\nstring\n\nThe email address of the user\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints\n\nname\nstring\n\nThe name of the user\n\nobject\nstring\n\nThe object type, which is always organization.user\n\nrole\nstring\n\nowner or reader\n\nOBJECT The user object\n{\n    \"object\": \"organization.user\",\n    \"id", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 344900, "end_char": 345500}, "691": {"text": "r\n\nrole\nstring\n\nowner or reader\n\nOBJECT The user object\n{\n    \"object\": \"organization.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\nProjects\nManage the projects within an orgnanization includes creation, updating, and archiving or projects. The Default project cannot be archived.\n\nList projects\nget\n \nhttps://api.openai.com/v1/organization/projects\nReturns a list of projects.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 345400, "end_char": 346000}, "692": {"text": "\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\ninclude_archived\nboolean\n\nOptional\nDefaults to false\nIf true returns all projects including those that have been archived. Archived projects are not included by default.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 345900, "end_char": 346500}, "693": {"text": "on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\nReturns\nA list of Project objects.\n\nExample request\ncurl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"id\": \"proj_abc\",\n            \"object\": \"organization.project\",\n            \"name\": \"Project example\",\n            \"created_at\": 1711471533,\n            \"archived_at\": null,\n            \"sta", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 346400, "end_char": 347000}, "694": {"text": "ct example\",\n            \"created_at\": 1711471533,\n            \"archived_at\": null,\n            \"status\": \"active\"\n        }\n    ],\n    \"first_id\": \"proj-abc\",\n    \"last_id\": \"proj-xyz\",\n    \"has_more\": false\n}\nCreate project\npost\n \nhttps://api.openai.com/v1/organization/projects\nCreate a new project in the organization. Projects can be created and archived, but cannot be deleted.\n\nRequest body\nname\nstring\n\nRequired\nThe friendly name of the project, this name appears in reports.\n\nReturns\nThe created Project object.\n\nExample request\ncurl -X POST https://api.openai.com/v1/organization/projects \\", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 346900, "end_char": 347500}, "695": {"text": "ated Project object.\n\nExample request\ncurl -X POST https://api.openai.com/v1/organization/projects \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"name\": \"Project ABC\"\n  }'\nResponse\n{\n    \"id\": \"proj_abc\",\n    \"object\": \"organization.project\",\n    \"name\": \"Project ABC\",\n    \"created_at\": 1711471533,\n    \"archived_at\": null,\n    \"status\": \"active\"\n}\nRetrieve project\nget\n \nhttps://api.openai.com/v1/organization/projects/{project_id}\nRetrieves a project.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nReturns\nThe Proje", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 347400, "end_char": 348000}, "696": {"text": "es a project.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nReturns\nThe Project object matching the specified ID.\n\nExample request\ncurl https://api.openai.com/v1/organization/projects/proj_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"id\": \"proj_abc\",\n    \"object\": \"organization.project\",\n    \"name\": \"Project example\",\n    \"created_at\": 1711471533,\n    \"archived_at\": null,\n    \"status\": \"active\"\n}\nModify project\npost\n \nhttps://api.openai.com/v1/organization/projects/{project_id}\nModifies a project in the orga", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 347900, "end_char": 348500}, "697": {"text": "t\npost\n \nhttps://api.openai.com/v1/organization/projects/{project_id}\nModifies a project in the organization.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nRequest body\nname\nstring\n\nRequired\nThe updated name of the project, this name appears in reports.\n\nReturns\nThe updated Project object.\n\nExample request\ncurl -X POST https://api.openai.com/v1/organization/projects/proj_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"name\": \"Project DEF\"\n  }'\nArchive project\npost\n \nhttps://api.openai.com/v1/organization/proje", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 348400, "end_char": 349000}, "698": {"text": "      \"name\": \"Project DEF\"\n  }'\nArchive project\npost\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/archive\nArchives a project in the organization. Archived projects cannot be used or updated.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nReturns\nThe archived Project object.\n\nExample request\ncurl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"id\": \"proj_abc\",\n    \"object\": \"organization.project\",\n    \"name\": \"Project DEF\",\n  ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 348900, "end_char": 349500}, "699": {"text": "Response\n{\n    \"id\": \"proj_abc\",\n    \"object\": \"organization.project\",\n    \"name\": \"Project DEF\",\n    \"created_at\": 1711471533,\n    \"archived_at\": 1711471533,\n    \"status\": \"archived\"\n}\nThe project object\nRepresents an individual project.\n\narchived_at\ninteger or null\n\nThe Unix timestamp (in seconds) of when the project was archived or null.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) of when the project was created.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints\n\nname\nstring\n\nThe name of the project. This appears in reporting.\n\nobject\nstring\n\nThe object type, whi", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 349400, "end_char": 350000}, "700": {"text": "ame\nstring\n\nThe name of the project. This appears in reporting.\n\nobject\nstring\n\nThe object type, which is always organization.project\n\nstatus\nstring\n\nactive or archived\n\nOBJECT The project object\n{\n    \"id\": \"proj_abc\",\n    \"object\": \"organization.project\",\n    \"name\": \"Project example\",\n    \"created_at\": 1711471533,\n    \"archived_at\": null,\n    \"status\": \"active\"\n}\nProject users\nManage users within a project, including adding, updating roles, and removing users.\n\nList project users\nget\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/users\nReturns a list of users in the project.", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 349900, "end_char": 350500}, "701": {"text": "//api.openai.com/v1/organization/projects/{project_id}/users\nReturns a list of users in the project.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 1", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 350400, "end_char": 351000}, "702": {"text": "onal\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\nReturns\nA list of ProjectUser objects.\n\nExample request\ncurl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"object\": \"organization.project.user\",\n            \"id\": \"user_abc\",\n            \"name\": \"First Last\",\n            \"email\": \"user@example.com\",\n            \"role\": \"o", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 350900, "end_char": 351500}, "703": {"text": "\",\n            \"name\": \"First Last\",\n            \"email\": \"user@example.com\",\n            \"role\": \"owner\",\n            \"added_at\": 1711471533\n        }\n    ],\n    \"first_id\": \"user-abc\",\n    \"last_id\": \"user-xyz\",\n    \"has_more\": false\n}\nCreate project user\npost\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/users\nAdds a user to the project. Users must already be members of the organization to be added to a project.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nRequest body\nrole\nstring\n\nRequired\nowner or member\n\nuser_id\nstring\n\nRequired\nThe ID of the user", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 351400, "end_char": 352000}, "704": {"text": "ct.\n\nRequest body\nrole\nstring\n\nRequired\nowner or member\n\nuser_id\nstring\n\nRequired\nThe ID of the user.\n\nReturns\nThe created ProjectUser object.\n\nExample request\ncurl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"user_id\": \"user_abc\",\n      \"role\": \"member\"\n  }'\nResponse\n{\n    \"object\": \"organization.project.user\",\n    \"id\": \"user_abc\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\nRetrieve project user\nget\n \nhttps://api.openai.co", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 351900, "end_char": 352500}, "705": {"text": "\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\nRetrieve project user\nget\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/users/{user_id}\nRetrieves a user in the project.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nuser_id\nstring\n\nRequired\nThe ID of the user.\n\nReturns\nThe ProjectUser object matching the specified ID.\n\nExample request\ncurl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"organization.project.user\",\n ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 352400, "end_char": 353000}, "706": {"text": "KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"organization.project.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\nModify project user\npost\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/users/{user_id}\nModifies a user's role in the project.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nuser_id\nstring\n\nRequired\nThe ID of the user.\n\nRequest body\nrole\nstring\n\nRequired\nowner or member\n\nReturns\nThe updated ProjectUser object.\n\nExample request\ncur", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 352900, "end_char": 353500}, "707": {"text": "\nrole\nstring\n\nRequired\nowner or member\n\nReturns\nThe updated ProjectUser object.\n\nExample request\ncurl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"role\": \"owner\"\n  }'\nResponse\n{\n    \"object\": \"organization.project.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\nDelete project user\ndelete\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/users/{user_id}\nD", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 353400, "end_char": 354000}, "708": {"text": "project user\ndelete\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/users/{user_id}\nDeletes a user from the project.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nuser_id\nstring\n\nRequired\nThe ID of the user.\n\nReturns\nConfirmation that project has been deleted or an error in case of an archived project, which has no users\n\nExample request\ncurl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"organization.project", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 353900, "end_char": 354500}, "709": {"text": "AI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"organization.project.user.deleted\",\n    \"id\": \"user_abc\",\n    \"deleted\": true\n}\nThe project user object\nRepresents an individual user in a project.\n\nadded_at\ninteger\n\nThe Unix timestamp (in seconds) of when the project was added.\n\nemail\nstring\n\nThe email address of the user\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints\n\nname\nstring\n\nThe name of the user\n\nobject\nstring\n\nThe object type, which is always organization.project.user\n\nrole\nstring\n\nowner or member\n\nOBJECT The project user object\n{\n  ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 354400, "end_char": 355000}, "710": {"text": " always organization.project.user\n\nrole\nstring\n\nowner or member\n\nOBJECT The project user object\n{\n    \"object\": \"organization.project.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\nProject service accounts\nManage service accounts within a project. A service account is a bot user that is not associated with a user. If a user leaves an organization, their keys and membership in projects will no longer work. Service accounts do not have this limitation. However, service accounts can also be deleted from a p", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 354900, "end_char": 355500}, "711": {"text": "Service accounts do not have this limitation. However, service accounts can also be deleted from a project.\n\nList project service accounts\nget\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/service_accounts\nReturns a list of service accounts in the project.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 355400, "end_char": 356000}, "712": {"text": "a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\nReturns\nA list of ProjectServiceAccount objects.\n\nExample request\ncurl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"list\",\n    \"da", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 355900, "end_char": 356500}, "713": {"text": " $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"object\": \"organization.project.service_account\",\n            \"id\": \"svc_acct_abc\",\n            \"name\": \"Service Account\",\n            \"role\": \"owner\",\n            \"created_at\": 1711471533\n        }\n    ],\n    \"first_id\": \"svc_acct_abc\",\n    \"last_id\": \"svc_acct_xyz\",\n    \"has_more\": false\n}\nCreate project service account\npost\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/service_accounts\nCreates a new service account in the project. This also return", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 356400, "end_char": 357000}, "714": {"text": "rojects/{project_id}/service_accounts\nCreates a new service account in the project. This also returns an unredacted API key for the service account.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nRequest body\nname\nstring\n\nRequired\nThe name of the service account being created.\n\nReturns\nThe created ProjectServiceAccount object.\n\nExample request\ncurl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"name\": \"Production App\"\n  }'\nResponse\n{", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 356900, "end_char": 357500}, "715": {"text": "EY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"name\": \"Production App\"\n  }'\nResponse\n{\n    \"object\": \"organization.project.service_account\",\n    \"id\": \"svc_acct_abc\",\n    \"name\": \"Production App\",\n    \"role\": \"member\",\n    \"created_at\": 1711471533,\n    \"api_key\": {\n        \"object\": \"organization.project.service_account.api_key\",\n        \"value\": \"sk-abcdefghijklmnop123\",\n        \"name\": \"Secret Key\",\n        \"created_at\": 1711471533,\n        \"id\": \"key_abc\"\n    }\n}\nRetrieve project service account\nget\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/service_account", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 357400, "end_char": 358000}, "716": {"text": "t service account\nget\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/service_accounts/{service_account_id}\nRetrieves a service account in the project.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nservice_account_id\nstring\n\nRequired\nThe ID of the service account.\n\nReturns\nThe ProjectServiceAccount object matching the specified ID.\n\nExample request\ncurl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"orga", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 357900, "end_char": 358500}, "717": {"text": "on: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"organization.project.service_account\",\n    \"id\": \"svc_acct_abc\",\n    \"name\": \"Service Account\",\n    \"role\": \"owner\",\n    \"created_at\": 1711471533\n}\nDelete project service account\ndelete\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/service_accounts/{service_account_id}\nDeletes a service account from the project.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nservice_account_id\nstring\n\nRequired\nThe ID of the service account.\n\nReturns\nConfirmation of service acco", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 358400, "end_char": 359000}, "718": {"text": "ice_account_id\nstring\n\nRequired\nThe ID of the service account.\n\nReturns\nConfirmation of service account being deleted, or an error in case of an archived project, which has no service accounts\n\nExample request\ncurl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"organization.project.service_account.deleted\",\n    \"id\": \"svc_acct_abc\",\n    \"deleted\": true\n}\nThe project service account object\nRepresents an individual service account in", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 358900, "end_char": 359500}, "719": {"text": "    \"deleted\": true\n}\nThe project service account object\nRepresents an individual service account in a project.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) of when the service account was created\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints\n\nname\nstring\n\nThe name of the service account\n\nobject\nstring\n\nThe object type, which is always organization.project.service_account\n\nrole\nstring\n\nowner or member\n\nOBJECT The project service account object\n{\n    \"object\": \"organization.project.service_account\",\n    \"id\": \"svc_acct_abc\",\n    \"name\": \"Service Account\",\n    \"rol", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 359400, "end_char": 360000}, "720": {"text": "nization.project.service_account\",\n    \"id\": \"svc_acct_abc\",\n    \"name\": \"Service Account\",\n    \"role\": \"owner\",\n    \"created_at\": 1711471533\n}\nProject API keys\nManage API keys for a given project. Supports listing and deleting keys for users. This API does not allow issuing keys for users, as users need to authorize themselves to generate keys.\n\nList project API keys\nget\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/api_keys\nReturns a list of API keys in the project.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nQuery parameters\nafter\nstring\n\nOptional\nA", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 359900, "end_char": 360500}, "721": {"text": "meters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\nReturns\nA list of ProjectApiKey objects.\n\nExample request\ncurl https://api.openai.c", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 360400, "end_char": 361000}, "722": {"text": " default is 20.\n\nReturns\nA list of ProjectApiKey objects.\n\nExample request\ncurl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"object\": \"organization.project.api_key\",\n            \"redacted_value\": \"sk-abc...def\",\n            \"name\": \"My API Key\",\n            \"created_at\": 1711471533,\n            \"id\": \"key_abc\",\n            \"owner\": {\n                \"type\": \"user\",\n                \"user\": {\n   ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 360900, "end_char": 361500}, "723": {"text": "id\": \"key_abc\",\n            \"owner\": {\n                \"type\": \"user\",\n                \"user\": {\n                    \"object\": \"organization.project.user\",\n                    \"id\": \"user_abc\",\n                    \"name\": \"First Last\",\n                    \"email\": \"user@example.com\",\n                    \"role\": \"owner\",\n                    \"added_at\": 1711471533\n                }\n            }\n        }\n    ],\n    \"first_id\": \"key_abc\",\n    \"last_id\": \"key_xyz\",\n    \"has_more\": false\n}\nRetrieve project API key\nget\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/api_keys/{key_id}", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 361400, "end_char": 362000}, "724": {"text": "project API key\nget\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/api_keys/{key_id}\nRetrieves an API key in the project.\n\nPath parameters\nkey_id\nstring\n\nRequired\nThe ID of the API key.\n\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nReturns\nThe ProjectApiKey object matching the specified ID.\n\nExample request\ncurl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"organization.project.api_key\",\n    \"redacted_value\": \"sk-abc...def\",\n    \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 361900, "end_char": 362500}, "725": {"text": "Response\n{\n    \"object\": \"organization.project.api_key\",\n    \"redacted_value\": \"sk-abc...def\",\n    \"name\": \"My API Key\",\n    \"created_at\": 1711471533,\n    \"id\": \"key_abc\",\n    \"owner\": {\n        \"type\": \"user\",\n        \"user\": {\n            \"object\": \"organization.project.user\",\n            \"id\": \"user_abc\",\n            \"name\": \"First Last\",\n            \"email\": \"user@example.com\",\n            \"role\": \"owner\",\n            \"added_at\": 1711471533\n        }\n    }\n}\nDelete project API key\ndelete\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/api_keys/{key_id}\nDeletes an API key fro", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 362400, "end_char": 363000}, "726": {"text": "ttps://api.openai.com/v1/organization/projects/{project_id}/api_keys/{key_id}\nDeletes an API key from the project.\n\nPath parameters\nkey_id\nstring\n\nRequired\nThe ID of the API key.\n\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nReturns\nConfirmation of the key's deletion or an error if the key belonged to a service account\n\nExample request\ncurl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"organization.project.api_key.deleted\",\n    \"id\": \"k", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 362900, "end_char": 363500}, "727": {"text": "ype: application/json\"\nResponse\n{\n    \"object\": \"organization.project.api_key.deleted\",\n    \"id\": \"key_abc\",\n    \"deleted\": true\n}\nThe project API key object\nRepresents an individual API key in a project.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) of when the API key was created\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints\n\nname\nstring\n\nThe name of the API key\n\nobject\nstring\n\nThe object type, which is always organization.project.api_key\n\nowner\nobject\n\n\nShow properties\nredacted_value\nstring\n\nThe redacted value of the API key\n\nOBJECT The project API key object\n{", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 363400, "end_char": 364000}, "728": {"text": "erties\nredacted_value\nstring\n\nThe redacted value of the API key\n\nOBJECT The project API key object\n{\n    \"object\": \"organization.project.api_key\",\n    \"redacted_value\": \"sk-abc...def\",\n    \"name\": \"My API Key\",\n    \"created_at\": 1711471533,\n    \"id\": \"key_abc\",\n    \"owner\": {\n        \"type\": \"user\",\n        \"user\": {\n            \"object\": \"organization.project.user\",\n            \"id\": \"user_abc\",\n            \"name\": \"First Last\",\n            \"email\": \"user@example.com\",\n            \"role\": \"owner\",\n            \"created_at\": 1711471533\n        }\n    }\n}\nProject rate limits\nManage rate limits pe", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 363900, "end_char": 364500}, "729": {"text": "r\",\n            \"created_at\": 1711471533\n        }\n    }\n}\nProject rate limits\nManage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.\n\nList project rate limits\nget\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/rate_limits\nReturns the rate limits per model for a project.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 364400, "end_char": 365000}, "730": {"text": "nation. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\n\nOptional\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\nlimit\ninteger\n\nOptional\nDefaults to 100\nA limit o", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 364900, "end_char": 365500}, "731": {"text": " in order to fetch the previous page of the list.\n\nlimit\ninteger\n\nOptional\nDefaults to 100\nA limit on the number of objects to be returned. The default is 100.\n\nReturns\nA list of ProjectRateLimit objects.\n\nExample request\ncurl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"list\",\n    \"data\": [\n        {\n          \"object\": \"project.rate_limit\",\n          \"id\": \"rl-ada\",\n          \"model\": \"ada\",\n          \"max_requests_per_1_minute\": 600", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 365400, "end_char": 366000}, "732": {"text": "mit\",\n          \"id\": \"rl-ada\",\n          \"model\": \"ada\",\n          \"max_requests_per_1_minute\": 600,\n          \"max_tokens_per_1_minute\": 150000,\n          \"max_images_per_1_minute\": 10\n        }\n    ],\n    \"first_id\": \"rl-ada\",\n    \"last_id\": \"rl-ada\",\n    \"has_more\": false\n}\nModify project rate limit\npost\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/rate_limits/{rate_limit_id}\nUpdates a project rate limit.\n\nPath parameters\nproject_id\nstring\n\nRequired\nThe ID of the project.\n\nrate_limit_id\nstring\n\nRequired\nThe ID of the rate limit.\n\nRequest body\nbatch_1_day_max_input_tokens\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 365900, "end_char": 366500}, "733": {"text": "rate_limit_id\nstring\n\nRequired\nThe ID of the rate limit.\n\nRequest body\nbatch_1_day_max_input_tokens\ninteger\n\nOptional\nThe maximum batch input tokens per day. Only relevant for certain models.\n\nmax_audio_megabytes_per_1_minute\ninteger\n\nOptional\nThe maximum audio megabytes per minute. Only relevant for certain models.\n\nmax_images_per_1_minute\ninteger\n\nOptional\nThe maximum images per minute. Only relevant for certain models.\n\nmax_requests_per_1_day\ninteger\n\nOptional\nThe maximum requests per day. Only relevant for certain models.\n\nmax_requests_per_1_minute\ninteger\n\nOptional\nThe maximum requests pe", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 366400, "end_char": 367000}, "734": {"text": "ly relevant for certain models.\n\nmax_requests_per_1_minute\ninteger\n\nOptional\nThe maximum requests per minute.\n\nmax_tokens_per_1_minute\ninteger\n\nOptional\nThe maximum tokens per minute.\n\nReturns\nThe updated ProjectRateLimit object.\n\nExample request\ncurl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"max_requests_per_1_minute\": 500\n  }'\nResponse\n{\n    \"object\": \"project.rate_limit\",\n    \"id\": \"rl-ada\",\n    \"model\": \"ada\",\n    \"max_requests_per_1_minute\": 6", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 366900, "end_char": 367500}, "735": {"text": "t\": \"project.rate_limit\",\n    \"id\": \"rl-ada\",\n    \"model\": \"ada\",\n    \"max_requests_per_1_minute\": 600,\n    \"max_tokens_per_1_minute\": 150000,\n    \"max_images_per_1_minute\": 10\n  }\nThe project rate limit object\nRepresents a project rate limit config.\n\nbatch_1_day_max_input_tokens\ninteger\n\nThe maximum batch input tokens per day. Only present for relevant models.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints.\n\nmax_audio_megabytes_per_1_minute\ninteger\n\nThe maximum audio megabytes per minute. Only present for relevant models.\n\nmax_images_per_1_minute\ninteger\n\nThe maximum ima", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 367400, "end_char": 368000}, "736": {"text": "ytes per minute. Only present for relevant models.\n\nmax_images_per_1_minute\ninteger\n\nThe maximum images per minute. Only present for relevant models.\n\nmax_requests_per_1_day\ninteger\n\nThe maximum requests per day. Only present for relevant models.\n\nmax_requests_per_1_minute\ninteger\n\nThe maximum requests per minute.\n\nmax_tokens_per_1_minute\ninteger\n\nThe maximum tokens per minute.\n\nmodel\nstring\n\nThe model this rate limit applies to.\n\nobject\nstring\n\nThe object type, which is always project.rate_limit\n\nOBJECT The project rate limit object\n{\n    \"object\": \"project.rate_limit\",\n    \"id\": \"rl_ada\",\n  ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 367900, "end_char": 368500}, "737": {"text": "t\n\nOBJECT The project rate limit object\n{\n    \"object\": \"project.rate_limit\",\n    \"id\": \"rl_ada\",\n    \"model\": \"ada\",\n    \"max_requests_per_1_minute\": 600,\n    \"max_tokens_per_1_minute\": 150000,\n    \"max_images_per_1_minute\": 10\n}\nAudit logs\nLogs of user actions and configuration changes within this organization. To log events, you must activate logging in the Organization Settings. Once activated, for security reasons, logging cannot be deactivated.\n\nList audit logs\nget\n \nhttps://api.openai.com/v1/organization/audit_logs\nList user actions and configuration changes within this organization.\n\nQ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 368400, "end_char": 369000}, "738": {"text": "/v1/organization/audit_logs\nList user actions and configuration changes within this organization.\n\nQuery parameters\nactor_emails[]\narray\n\nOptional\nReturn only events performed by users with these emails.\n\nactor_ids[]\narray\n\nOptional\nReturn only events performed by these actors. Can be a user ID, a service account ID, or an api key tracking ID.\n\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in or", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 368900, "end_char": 369500}, "739": {"text": "t and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\n\nOptional\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\neffective_at\nobject\n\nOptional\nReturn only events whose effective_at (Unix seconds) is in this range.\n\n\nShow properties\nevent_types[]\narray\n\nOptional\nReturn ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 369400, "end_char": 370000}, "740": {"text": "ffective_at (Unix seconds) is in this range.\n\n\nShow properties\nevent_types[]\narray\n\nOptional\nReturn only events with a type in one of these values. For example, project.created. For all options, see the documentation for the audit log object.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\nproject_ids[]\narray\n\nOptional\nReturn only events for these projects.\n\nresource_ids[]\narray\n\nOptional\nReturn only events performed on these targets. For example, a project ID updated.\n\nReturns\nA list of paginat", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 369900, "end_char": 370500}, "741": {"text": "nly events performed on these targets. For example, a project ID updated.\n\nReturns\nA list of paginated Audit Log objects.\n\nExample request\ncurl https://api.openai.com/v1/organization/audit_logs \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"id\": \"audit_log-xxx_yyyymmdd\",\n            \"type\": \"project.archived\",\n            \"effective_at\": 1722461446,\n            \"actor\": {\n                \"type\": \"api_key\",\n                \"api_key\": {\n                    \"type\": \"user\",\n                 ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 370400, "end_char": 371000}, "742": {"text": "type\": \"api_key\",\n                \"api_key\": {\n                    \"type\": \"user\",\n                    \"user\": {\n                        \"id\": \"user-xxx\",\n                        \"email\": \"user@example.com\"\n                    }\n                }\n            },\n            \"project.archived\": {\n                \"id\": \"proj_abc\"\n            },\n        },\n        {\n            \"id\": \"audit_log-yyy__20240101\",\n            \"type\": \"api_key.updated\",\n            \"effective_at\": 1720804190,\n            \"actor\": {\n                \"type\": \"session\",\n                \"session\": {\n                    \"use", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 370900, "end_char": 371500}, "743": {"text": " \"actor\": {\n                \"type\": \"session\",\n                \"session\": {\n                    \"user\": {\n                        \"id\": \"user-xxx\",\n                        \"email\": \"user@example.com\"\n                    },\n                    \"ip_address\": \"127.0.0.1\",\n                    \"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n                    \"ja3\": \"a497151ce4338a12c4418c44d375173e\",\n                    \"ja4\": \"q13d0313h3_55b375c5d22e_c7319ce65786\",\n                    \"ip_address_details\": {\n   ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 371400, "end_char": 372000}, "744": {"text": "      \"ja4\": \"q13d0313h3_55b375c5d22e_c7319ce65786\",\n                    \"ip_address_details\": {\n                      \"country\": \"US\",\n                      \"city\": \"San Francisco\",\n                      \"region\": \"California\",\n                      \"region_code\": \"CA\",\n                      \"asn\": \"1234\",\n                      \"latitude\": \"37.77490\",\n                      \"longitude\": \"-122.41940\"\n                    }\n                }\n            },\n            \"api_key.updated\": {\n                \"id\": \"key_xxxx\",\n                \"data\": {\n                    \"scopes\": [\"resource_2.operat", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 371900, "end_char": 372500}, "745": {"text": "       \"id\": \"key_xxxx\",\n                \"data\": {\n                    \"scopes\": [\"resource_2.operation_2\"]\n                }\n            },\n        }\n    ],\n    \"first_id\": \"audit_log-xxx__20240101\",\n    \"last_id\": \"audit_log_yyy__20240101\",\n    \"has_more\": true\n}\nThe audit log object\nA log of a user action or configuration change within this organization.\n\nactor\nobject\n\nThe actor who performed the audit logged action.\n\n\nShow properties\napi_key.created\nobject\n\nThe details for events with this type.\n\n\nShow properties\napi_key.deleted\nobject\n\nThe details for events with this type.\n\n\nShow propert", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 372400, "end_char": 373000}, "746": {"text": "ype.\n\n\nShow properties\napi_key.deleted\nobject\n\nThe details for events with this type.\n\n\nShow properties\napi_key.updated\nobject\n\nThe details for events with this type.\n\n\nShow properties\ncertificate.created\nobject\n\nThe details for events with this type.\n\n\nShow properties\ncertificate.deleted\nobject\n\nThe details for events with this type.\n\n\nShow properties\ncertificate.updated\nobject\n\nThe details for events with this type.\n\n\nShow properties\ncertificates.activated\nobject\n\nThe details for events with this type.\n\n\nShow properties\ncertificates.deactivated\nobject\n\nThe details for events with this type.\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 372900, "end_char": 373500}, "747": {"text": "his type.\n\n\nShow properties\ncertificates.deactivated\nobject\n\nThe details for events with this type.\n\n\nShow properties\ncheckpoint_permission.created\nobject\n\nThe project and fine-tuned model checkpoint that the checkpoint permission was created for.\n\n\nShow properties\ncheckpoint_permission.deleted\nobject\n\nThe details for events with this type.\n\n\nShow properties\neffective_at\ninteger\n\nThe Unix timestamp (in seconds) of the event.\n\nid\nstring\n\nThe ID of this log.\n\ninvite.accepted\nobject\n\nThe details for events with this type.\n\n\nShow properties\ninvite.deleted\nobject\n\nThe details for events with this t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 373400, "end_char": 374000}, "748": {"text": "r events with this type.\n\n\nShow properties\ninvite.deleted\nobject\n\nThe details for events with this type.\n\n\nShow properties\ninvite.sent\nobject\n\nThe details for events with this type.\n\n\nShow properties\nlogin.failed\nobject\n\nThe details for events with this type.\n\n\nShow properties\nlogout.failed\nobject\n\nThe details for events with this type.\n\n\nShow properties\norganization.updated\nobject\n\nThe details for events with this type.\n\n\nShow properties\nproject\nobject\n\nThe project that the action was scoped to. Absent for actions not scoped to projects.\n\n\nShow properties\nproject.archived\nobject\n\nThe details ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 373900, "end_char": 374500}, "749": {"text": ". Absent for actions not scoped to projects.\n\n\nShow properties\nproject.archived\nobject\n\nThe details for events with this type.\n\n\nShow properties\nproject.created\nobject\n\nThe details for events with this type.\n\n\nShow properties\nproject.updated\nobject\n\nThe details for events with this type.\n\n\nShow properties\nrate_limit.deleted\nobject\n\nThe details for events with this type.\n\n\nShow properties\nrate_limit.updated\nobject\n\nThe details for events with this type.\n\n\nShow properties\nservice_account.created\nobject\n\nThe details for events with this type.\n\n\nShow properties\nservice_account.deleted\nobject\n\nThe ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 374400, "end_char": 375000}, "750": {"text": "bject\n\nThe details for events with this type.\n\n\nShow properties\nservice_account.deleted\nobject\n\nThe details for events with this type.\n\n\nShow properties\nservice_account.updated\nobject\n\nThe details for events with this type.\n\n\nShow properties\ntype\nstring\n\nThe event type.\n\nuser.added\nobject\n\nThe details for events with this type.\n\n\nShow properties\nuser.deleted\nobject\n\nThe details for events with this type.\n\n\nShow properties\nuser.updated\nobject\n\nThe details for events with this type.\n\n\nShow properties\nOBJECT The audit log object\n{\n    \"id\": \"req_xxx_20240101\",\n    \"type\": \"api_key.created\",\n    \"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 374900, "end_char": 375500}, "751": {"text": "ies\nOBJECT The audit log object\n{\n    \"id\": \"req_xxx_20240101\",\n    \"type\": \"api_key.created\",\n    \"effective_at\": 1720804090,\n    \"actor\": {\n        \"type\": \"session\",\n        \"session\": {\n            \"user\": {\n                \"id\": \"user-xxx\",\n                \"email\": \"user@example.com\"\n            },\n            \"ip_address\": \"127.0.0.1\",\n            \"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n        }\n    },\n    \"api_key.created\": {\n        \"id\": \"key_xxxx\",\n        \"data\": {\n            \"scopes\": [\"re", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 375400, "end_char": 376000}, "752": {"text": "  },\n    \"api_key.created\": {\n        \"id\": \"key_xxxx\",\n        \"data\": {\n            \"scopes\": [\"resource.operation\"]\n        }\n    }\n}\nUsage\nThe Usage API provides detailed insights into your activity across the OpenAI API. It also includes a separate Costs endpoint, which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.\n\nWhile the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the Costs endpo", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 375900, "end_char": 376500}, "753": {"text": "nces in how usage and spend are recorded. For financial purposes, we recommend using the Costs endpoint or the Costs tab in the Usage Dashboard, which will reconcile back to your billing invoice.\n\nCompletions\nget\n \nhttps://api.openai.com/v1/organization/usage/completions\nGet completions usage details for the organization.\n\nQuery parameters\nstart_time\ninteger\n\nRequired\nStart time (Unix seconds) of the query time range, inclusive.\n\napi_key_ids\narray\n\nOptional\nReturn only usage for these API keys.\n\nbatch\nboolean\n\nOptional\nIf true, return batch jobs only. If false, return non-batch jobs only. By d", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 376400, "end_char": 377000}, "754": {"text": "\nbatch\nboolean\n\nOptional\nIf true, return batch jobs only. If false, return non-batch jobs only. By default, return both.\n\nbucket_width\nstring\n\nOptional\nDefaults to 1d\nWidth of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.\n\nend_time\ninteger\n\nOptional\nEnd time (Unix seconds) of the query time range, exclusive.\n\ngroup_by\narray\n\nOptional\nGroup the usage data by the specified fields. Support fields include project_id, user_id, api_key_id, model, batch or any combination of them.\n\nlimit\ninteger\n\nOptional\nSpecifies the number of buckets to return.\n\nbucket_width=1", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 376900, "end_char": 377500}, "755": {"text": "ination of them.\n\nlimit\ninteger\n\nOptional\nSpecifies the number of buckets to return.\n\nbucket_width=1d: default: 7, max: 31\nbucket_width=1h: default: 24, max: 168\nbucket_width=1m: default: 60, max: 1440\nmodels\narray\n\nOptional\nReturn only usage for these models.\n\npage\nstring\n\nOptional\nA cursor for use in pagination. Corresponding to the next_page field from the previous response.\n\nproject_ids\narray\n\nOptional\nReturn only usage for these projects.\n\nuser_ids\narray\n\nOptional\nReturn only usage for these users.\n\nReturns\nA list of paginated, time bucketed Completions usage objects.\n\nExample request\ncur", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 377400, "end_char": 378000}, "756": {"text": "e users.\n\nReturns\nA list of paginated, time bucketed Completions usage objects.\n\nExample request\ncurl \"https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.completions.result\",\n                    \"input_tokens\": 1000,\n     ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 377900, "end_char": 378500}, "757": {"text": "  \"object\": \"organization.usage.completions.result\",\n                    \"input_tokens\": 1000,\n                    \"output_tokens\": 500,\n                    \"input_cached_tokens\": 800,\n                    \"input_audio_tokens\": 0,\n                    \"output_audio_tokens\": 0,\n                    \"num_model_requests\": 5,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null,\n                    \"batch\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": true,\n    \"next_page\": \"page", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 378400, "end_char": 379000}, "758": {"text": ": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": true,\n    \"next_page\": \"page_AAAAAGdGxdEiJdKOAAAAAGcqsYA=\"\n}\nCompletions usage object\nThe aggregated completions usage details of the specific time bucket.\n\napi_key_id\nstring or null\n\nWhen group_by=api_key_id, this field provides the API key ID of the grouped usage result.\n\nbatch\nboolean or null\n\nWhen group_by=batch, this field tells whether the grouped usage result is batch or not.\n\ninput_audio_tokens\ninteger\n\nThe aggregated number of audio input tokens used, including cached tokens.\n\ninput_cached_tokens\ninteger\n\nThe aggr", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 378900, "end_char": 379500}, "759": {"text": "d number of audio input tokens used, including cached tokens.\n\ninput_cached_tokens\ninteger\n\nThe aggregated number of text input tokens that has been cached from previous requests. For customers subscribe to scale tier, this includes scale tier tokens.\n\ninput_tokens\ninteger\n\nThe aggregated number of text input tokens used, including cached tokens. For customers subscribe to scale tier, this includes scale tier tokens.\n\nmodel\nstring or null\n\nWhen group_by=model, this field provides the model name of the grouped usage result.\n\nnum_model_requests\ninteger\n\nThe count of requests made to the model.\n\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 379400, "end_char": 380000}, "760": {"text": "of the grouped usage result.\n\nnum_model_requests\ninteger\n\nThe count of requests made to the model.\n\nobject\nstring\n\noutput_audio_tokens\ninteger\n\nThe aggregated number of audio output tokens used.\n\noutput_tokens\ninteger\n\nThe aggregated number of text output tokens used. For customers subscribe to scale tier, this includes scale tier tokens.\n\nproject_id\nstring or null\n\nWhen group_by=project_id, this field provides the project ID of the grouped usage result.\n\nuser_id\nstring or null\n\nWhen group_by=user_id, this field provides the user ID of the grouped usage result.\n\nOBJECT Completions usage object", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 379900, "end_char": 380500}, "761": {"text": "er_id, this field provides the user ID of the grouped usage result.\n\nOBJECT Completions usage object\n{\n    \"object\": \"organization.usage.completions.result\",\n    \"input_tokens\": 5000,\n    \"output_tokens\": 1000,\n    \"input_cached_tokens\": 4000,\n    \"input_audio_tokens\": 300,\n    \"output_audio_tokens\": 200,\n    \"num_model_requests\": 5,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"batch\": false\n}\nEmbeddings\nget\n \nhttps://api.openai.com/v1/organization/usage/embeddings\nGet embeddings usage details for the organiza", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 380400, "end_char": 381000}, "762": {"text": "ttps://api.openai.com/v1/organization/usage/embeddings\nGet embeddings usage details for the organization.\n\nQuery parameters\nstart_time\ninteger\n\nRequired\nStart time (Unix seconds) of the query time range, inclusive.\n\napi_key_ids\narray\n\nOptional\nReturn only usage for these API keys.\n\nbucket_width\nstring\n\nOptional\nDefaults to 1d\nWidth of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.\n\nend_time\ninteger\n\nOptional\nEnd time (Unix seconds) of the query time range, exclusive.\n\ngroup_by\narray\n\nOptional\nGroup the usage data by the specified fields. Support fields incl", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 380900, "end_char": 381500}, "763": {"text": "clusive.\n\ngroup_by\narray\n\nOptional\nGroup the usage data by the specified fields. Support fields include project_id, user_id, api_key_id, model or any combination of them.\n\nlimit\ninteger\n\nOptional\nSpecifies the number of buckets to return.\n\nbucket_width=1d: default: 7, max: 31\nbucket_width=1h: default: 24, max: 168\nbucket_width=1m: default: 60, max: 1440\nmodels\narray\n\nOptional\nReturn only usage for these models.\n\npage\nstring\n\nOptional\nA cursor for use in pagination. Corresponding to the next_page field from the previous response.\n\nproject_ids\narray\n\nOptional\nReturn only usage for these projects", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 381400, "end_char": 382000}, "764": {"text": " field from the previous response.\n\nproject_ids\narray\n\nOptional\nReturn only usage for these projects.\n\nuser_ids\narray\n\nOptional\nReturn only usage for these users.\n\nReturns\nA list of paginated, time bucketed Embeddings usage objects.\n\nExample request\ncurl \"https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n         ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 381900, "end_char": 382500}, "765": {"text": "ject\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.embeddings.result\",\n                    \"input_tokens\": 16,\n                    \"num_model_requests\": 2,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\nEmbeddings usage object\nThe aggregated embeddings usage details ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 382400, "end_char": 383000}, "766": {"text": "re\": false,\n    \"next_page\": null\n}\nEmbeddings usage object\nThe aggregated embeddings usage details of the specific time bucket.\n\napi_key_id\nstring or null\n\nWhen group_by=api_key_id, this field provides the API key ID of the grouped usage result.\n\ninput_tokens\ninteger\n\nThe aggregated number of input tokens used.\n\nmodel\nstring or null\n\nWhen group_by=model, this field provides the model name of the grouped usage result.\n\nnum_model_requests\ninteger\n\nThe count of requests made to the model.\n\nobject\nstring\n\nproject_id\nstring or null\n\nWhen group_by=project_id, this field provides the project ID of t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 382900, "end_char": 383500}, "767": {"text": "string\n\nproject_id\nstring or null\n\nWhen group_by=project_id, this field provides the project ID of the grouped usage result.\n\nuser_id\nstring or null\n\nWhen group_by=user_id, this field provides the user ID of the grouped usage result.\n\nOBJECT Embeddings usage object\n{\n    \"object\": \"organization.usage.embeddings.result\",\n    \"input_tokens\": 20,\n    \"num_model_requests\": 2,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"text-embedding-ada-002-v2\"\n}\nModerations\nget\n \nhttps://api.openai.com/v1/organization/usage/moderations\nGet moderations usage", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 383400, "end_char": 384000}, "768": {"text": "\"\n}\nModerations\nget\n \nhttps://api.openai.com/v1/organization/usage/moderations\nGet moderations usage details for the organization.\n\nQuery parameters\nstart_time\ninteger\n\nRequired\nStart time (Unix seconds) of the query time range, inclusive.\n\napi_key_ids\narray\n\nOptional\nReturn only usage for these API keys.\n\nbucket_width\nstring\n\nOptional\nDefaults to 1d\nWidth of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.\n\nend_time\ninteger\n\nOptional\nEnd time (Unix seconds) of the query time range, exclusive.\n\ngroup_by\narray\n\nOptional\nGroup the usage data by the specified fi", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 383900, "end_char": 384500}, "769": {"text": " the query time range, exclusive.\n\ngroup_by\narray\n\nOptional\nGroup the usage data by the specified fields. Support fields include project_id, user_id, api_key_id, model or any combination of them.\n\nlimit\ninteger\n\nOptional\nSpecifies the number of buckets to return.\n\nbucket_width=1d: default: 7, max: 31\nbucket_width=1h: default: 24, max: 168\nbucket_width=1m: default: 60, max: 1440\nmodels\narray\n\nOptional\nReturn only usage for these models.\n\npage\nstring\n\nOptional\nA cursor for use in pagination. Corresponding to the next_page field from the previous response.\n\nproject_ids\narray\n\nOptional\nReturn only", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 384400, "end_char": 385000}, "770": {"text": "sponding to the next_page field from the previous response.\n\nproject_ids\narray\n\nOptional\nReturn only usage for these projects.\n\nuser_ids\narray\n\nOptional\nReturn only usage for these users.\n\nReturns\nA list of paginated, time bucketed Moderations usage objects.\n\nExample request\ncurl \"https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 384900, "end_char": 385500}, "771": {"text": "[\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.moderations.result\",\n                    \"input_tokens\": 16,\n                    \"num_model_requests\": 2,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\nModerations usage object\nThe aggrega", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 385400, "end_char": 386000}, "772": {"text": "        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\nModerations usage object\nThe aggregated moderations usage details of the specific time bucket.\n\napi_key_id\nstring or null\n\nWhen group_by=api_key_id, this field provides the API key ID of the grouped usage result.\n\ninput_tokens\ninteger\n\nThe aggregated number of input tokens used.\n\nmodel\nstring or null\n\nWhen group_by=model, this field provides the model name of the grouped usage result.\n\nnum_model_requests\ninteger\n\nThe count of requests made to the model.\n\nobject\nstring\n\nproject_id\nstring or null\n\nWhen group_by=project_id, this fiel", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 385900, "end_char": 386500}, "773": {"text": "ts made to the model.\n\nobject\nstring\n\nproject_id\nstring or null\n\nWhen group_by=project_id, this field provides the project ID of the grouped usage result.\n\nuser_id\nstring or null\n\nWhen group_by=user_id, this field provides the user ID of the grouped usage result.\n\nOBJECT Moderations usage object\n{\n    \"object\": \"organization.usage.moderations.result\",\n    \"input_tokens\": 20,\n    \"num_model_requests\": 2,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"text-moderation\"\n}\nImages\nget\n \nhttps://api.openai.com/v1/organization/usage/images\nGet image", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 386400, "end_char": 387000}, "774": {"text": "del\": \"text-moderation\"\n}\nImages\nget\n \nhttps://api.openai.com/v1/organization/usage/images\nGet images usage details for the organization.\n\nQuery parameters\nstart_time\ninteger\n\nRequired\nStart time (Unix seconds) of the query time range, inclusive.\n\napi_key_ids\narray\n\nOptional\nReturn only usage for these API keys.\n\nbucket_width\nstring\n\nOptional\nDefaults to 1d\nWidth of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.\n\nend_time\ninteger\n\nOptional\nEnd time (Unix seconds) of the query time range, exclusive.\n\ngroup_by\narray\n\nOptional\nGroup the usage data by the speci", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 386900, "end_char": 387500}, "775": {"text": "nds) of the query time range, exclusive.\n\ngroup_by\narray\n\nOptional\nGroup the usage data by the specified fields. Support fields include project_id, user_id, api_key_id, model, size, source or any combination of them.\n\nlimit\ninteger\n\nOptional\nSpecifies the number of buckets to return.\n\nbucket_width=1d: default: 7, max: 31\nbucket_width=1h: default: 24, max: 168\nbucket_width=1m: default: 60, max: 1440\nmodels\narray\n\nOptional\nReturn only usage for these models.\n\npage\nstring\n\nOptional\nA cursor for use in pagination. Corresponding to the next_page field from the previous response.\n\nproject_ids\narray\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 387400, "end_char": 388000}, "776": {"text": " in pagination. Corresponding to the next_page field from the previous response.\n\nproject_ids\narray\n\nOptional\nReturn only usage for these projects.\n\nsizes\narray\n\nOptional\nReturn only usages for these image sizes. Possible values are 256x256, 512x512, 1024x1024, 1792x1792, 1024x1792 or any combination of them.\n\nsources\narray\n\nOptional\nReturn only usages for these sources. Possible values are image.generation, image.edit, image.variation or any combination of them.\n\nuser_ids\narray\n\nOptional\nReturn only usage for these users.\n\nReturns\nA list of paginated, time bucketed Images usage objects.\n\nExam", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 387900, "end_char": 388500}, "777": {"text": " only usage for these users.\n\nReturns\nA list of paginated, time bucketed Images usage objects.\n\nExample request\ncurl \"https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.images.result\",\n                    \"images\": 2,\n         ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 388400, "end_char": 389000}, "778": {"text": "            \"object\": \"organization.usage.images.result\",\n                    \"images\": 2,\n                    \"num_model_requests\": 2,\n                    \"size\": null,\n                    \"source\": null,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\nImages usage object\nThe aggregated images usage details of the specific time bucket.\n\napi_key_id\nstring or null\n\nWhen group_by=api_key_id, this fie", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 388900, "end_char": 389500}, "779": {"text": " details of the specific time bucket.\n\napi_key_id\nstring or null\n\nWhen group_by=api_key_id, this field provides the API key ID of the grouped usage result.\n\nimages\ninteger\n\nThe number of images processed.\n\nmodel\nstring or null\n\nWhen group_by=model, this field provides the model name of the grouped usage result.\n\nnum_model_requests\ninteger\n\nThe count of requests made to the model.\n\nobject\nstring\n\nproject_id\nstring or null\n\nWhen group_by=project_id, this field provides the project ID of the grouped usage result.\n\nsize\nstring or null\n\nWhen group_by=size, this field provides the image size of the ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 389400, "end_char": 390000}, "780": {"text": "d usage result.\n\nsize\nstring or null\n\nWhen group_by=size, this field provides the image size of the grouped usage result.\n\nsource\nstring or null\n\nWhen group_by=source, this field provides the source of the grouped usage result, possible values are image.generation, image.edit, image.variation.\n\nuser_id\nstring or null\n\nWhen group_by=user_id, this field provides the user ID of the grouped usage result.\n\nOBJECT Images usage object\n{\n    \"object\": \"organization.usage.images.result\",\n    \"images\": 2,\n    \"num_model_requests\": 2,\n    \"size\": \"1024x1024\",\n    \"source\": \"image.generation\",\n    \"projec", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 389900, "end_char": 390500}, "781": {"text": "\n    \"num_model_requests\": 2,\n    \"size\": \"1024x1024\",\n    \"source\": \"image.generation\",\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"dall-e-3\"\n}\nAudio speeches\nget\n \nhttps://api.openai.com/v1/organization/usage/audio_speeches\nGet audio speeches usage details for the organization.\n\nQuery parameters\nstart_time\ninteger\n\nRequired\nStart time (Unix seconds) of the query time range, inclusive.\n\napi_key_ids\narray\n\nOptional\nReturn only usage for these API keys.\n\nbucket_width\nstring\n\nOptional\nDefaults to 1d\nWidth of each time bucket in response. Cu", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 390400, "end_char": 391000}, "782": {"text": "se API keys.\n\nbucket_width\nstring\n\nOptional\nDefaults to 1d\nWidth of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.\n\nend_time\ninteger\n\nOptional\nEnd time (Unix seconds) of the query time range, exclusive.\n\ngroup_by\narray\n\nOptional\nGroup the usage data by the specified fields. Support fields include project_id, user_id, api_key_id, model or any combination of them.\n\nlimit\ninteger\n\nOptional\nSpecifies the number of buckets to return.\n\nbucket_width=1d: default: 7, max: 31\nbucket_width=1h: default: 24, max: 168\nbucket_width=1m: default: 60, max: 1440\nmodels\narray\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 390900, "end_char": 391500}, "783": {"text": "max: 31\nbucket_width=1h: default: 24, max: 168\nbucket_width=1m: default: 60, max: 1440\nmodels\narray\n\nOptional\nReturn only usage for these models.\n\npage\nstring\n\nOptional\nA cursor for use in pagination. Corresponding to the next_page field from the previous response.\n\nproject_ids\narray\n\nOptional\nReturn only usage for these projects.\n\nuser_ids\narray\n\nOptional\nReturn only usage for these users.\n\nReturns\nA list of paginated, time bucketed Audio speeches usage objects.\n\nExample request\ncurl \"https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1\" \\\n-H \"Authorizatio", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 391400, "end_char": 392000}, "784": {"text": "pi.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.audio_speeches.result\",\n                    \"characters\": 45,\n                    \"num_model_requests\": 1,\n                    \"project_id\": null,\n                    \"user_id\":", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 391900, "end_char": 392500}, "785": {"text": "     \"num_model_requests\": 1,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\nAudio speeches usage object\nThe aggregated audio speeches usage details of the specific time bucket.\n\napi_key_id\nstring or null\n\nWhen group_by=api_key_id, this field provides the API key ID of the grouped usage result.\n\ncharacters\ninteger\n\nThe number of characters processed.\n\nmodel\nstring or null\n\nWhen group_by=model, thi", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 392400, "end_char": 393000}, "786": {"text": "racters\ninteger\n\nThe number of characters processed.\n\nmodel\nstring or null\n\nWhen group_by=model, this field provides the model name of the grouped usage result.\n\nnum_model_requests\ninteger\n\nThe count of requests made to the model.\n\nobject\nstring\n\nproject_id\nstring or null\n\nWhen group_by=project_id, this field provides the project ID of the grouped usage result.\n\nuser_id\nstring or null\n\nWhen group_by=user_id, this field provides the user ID of the grouped usage result.\n\nOBJECT Audio speeches usage object\n{\n    \"object\": \"organization.usage.audio_speeches.result\",\n    \"characters\": 45,\n    \"num_", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 392900, "end_char": 393500}, "787": {"text": "e object\n{\n    \"object\": \"organization.usage.audio_speeches.result\",\n    \"characters\": 45,\n    \"num_model_requests\": 1,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"tts-1\"\n}\nAudio transcriptions\nget\n \nhttps://api.openai.com/v1/organization/usage/audio_transcriptions\nGet audio transcriptions usage details for the organization.\n\nQuery parameters\nstart_time\ninteger\n\nRequired\nStart time (Unix seconds) of the query time range, inclusive.\n\napi_key_ids\narray\n\nOptional\nReturn only usage for these API keys.\n\nbucket_width\nstring\n\nOptional\nDefaults t", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 393400, "end_char": 394000}, "788": {"text": "_ids\narray\n\nOptional\nReturn only usage for these API keys.\n\nbucket_width\nstring\n\nOptional\nDefaults to 1d\nWidth of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.\n\nend_time\ninteger\n\nOptional\nEnd time (Unix seconds) of the query time range, exclusive.\n\ngroup_by\narray\n\nOptional\nGroup the usage data by the specified fields. Support fields include project_id, user_id, api_key_id, model or any combination of them.\n\nlimit\ninteger\n\nOptional\nSpecifies the number of buckets to return.\n\nbucket_width=1d: default: 7, max: 31\nbucket_width=1h: default: 24, max: 168\nbucket_", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 393900, "end_char": 394500}, "789": {"text": "kets to return.\n\nbucket_width=1d: default: 7, max: 31\nbucket_width=1h: default: 24, max: 168\nbucket_width=1m: default: 60, max: 1440\nmodels\narray\n\nOptional\nReturn only usage for these models.\n\npage\nstring\n\nOptional\nA cursor for use in pagination. Corresponding to the next_page field from the previous response.\n\nproject_ids\narray\n\nOptional\nReturn only usage for these projects.\n\nuser_ids\narray\n\nOptional\nReturn only usage for these users.\n\nReturns\nA list of paginated, time bucketed Audio transcriptions usage objects.\n\nExample request\ncurl \"https://api.openai.com/v1/organization/usage/audio_transc", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 394400, "end_char": 395000}, "790": {"text": "ions usage objects.\n\nExample request\ncurl \"https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.audio_transcriptions.result\",\n                    \"seconds\": 20,\n                    \"num_model_requests\": 1,\n         ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 394900, "end_char": 395500}, "791": {"text": "s.result\",\n                    \"seconds\": 20,\n                    \"num_model_requests\": 1,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\nAudio transcriptions usage object\nThe aggregated audio transcriptions usage details of the specific time bucket.\n\napi_key_id\nstring or null\n\nWhen group_by=api_key_id, this field provides the API key ID of the grouped usage result.\n\nmodel\nstring or null\n\nWhen gro", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 395400, "end_char": 396000}, "792": {"text": "_id, this field provides the API key ID of the grouped usage result.\n\nmodel\nstring or null\n\nWhen group_by=model, this field provides the model name of the grouped usage result.\n\nnum_model_requests\ninteger\n\nThe count of requests made to the model.\n\nobject\nstring\n\nproject_id\nstring or null\n\nWhen group_by=project_id, this field provides the project ID of the grouped usage result.\n\nseconds\ninteger\n\nThe number of seconds processed.\n\nuser_id\nstring or null\n\nWhen group_by=user_id, this field provides the user ID of the grouped usage result.\n\nOBJECT Audio transcriptions usage object\n{\n    \"object\": \"o", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 395900, "end_char": 396500}, "793": {"text": "he user ID of the grouped usage result.\n\nOBJECT Audio transcriptions usage object\n{\n    \"object\": \"organization.usage.audio_transcriptions.result\",\n    \"seconds\": 10,\n    \"num_model_requests\": 1,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"tts-1\"\n}\nVector stores\nget\n \nhttps://api.openai.com/v1/organization/usage/vector_stores\nGet vector stores usage details for the organization.\n\nQuery parameters\nstart_time\ninteger\n\nRequired\nStart time (Unix seconds) of the query time range, inclusive.\n\nbucket_width\nstring\n\nOptional\nDefaults to 1d\nWidth o", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 396400, "end_char": 397000}, "794": {"text": "x seconds) of the query time range, inclusive.\n\nbucket_width\nstring\n\nOptional\nDefaults to 1d\nWidth of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.\n\nend_time\ninteger\n\nOptional\nEnd time (Unix seconds) of the query time range, exclusive.\n\ngroup_by\narray\n\nOptional\nGroup the usage data by the specified fields. Support fields include project_id.\n\nlimit\ninteger\n\nOptional\nSpecifies the number of buckets to return.\n\nbucket_width=1d: default: 7, max: 31\nbucket_width=1h: default: 24, max: 168\nbucket_width=1m: default: 60, max: 1440\npage\nstring\n\nOptional\nA cursor for", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 396900, "end_char": 397500}, "795": {"text": "1h: default: 24, max: 168\nbucket_width=1m: default: 60, max: 1440\npage\nstring\n\nOptional\nA cursor for use in pagination. Corresponding to the next_page field from the previous response.\n\nproject_ids\narray\n\nOptional\nReturn only usage for these projects.\n\nReturns\nA list of paginated, time bucketed Vector stores usage objects.\n\nExample request\ncurl \"https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\"", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 397400, "end_char": 398000}, "796": {"text": "ype: application/json\"\nResponse\n{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.vector_stores.result\",\n                    \"usage_bytes\": 1024,\n                    \"project_id\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\nVector stores usage object\nThe aggregated vector stores usage details of the specific time bucket.\n\nobject\nstring\n\nproject", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 397900, "end_char": 398500}, "797": {"text": "ject\nThe aggregated vector stores usage details of the specific time bucket.\n\nobject\nstring\n\nproject_id\nstring or null\n\nWhen group_by=project_id, this field provides the project ID of the grouped usage result.\n\nusage_bytes\ninteger\n\nThe vector stores usage in bytes.\n\nOBJECT Vector stores usage object\n{\n    \"object\": \"organization.usage.vector_stores.result\",\n    \"usage_bytes\": 1024,\n    \"project_id\": \"proj_abc\"\n}\nCode interpreter sessions\nget\n \nhttps://api.openai.com/v1/organization/usage/code_interpreter_sessions\nGet code interpreter sessions usage details for the organization.\n\nQuery paramete", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 398400, "end_char": 399000}, "798": {"text": "terpreter_sessions\nGet code interpreter sessions usage details for the organization.\n\nQuery parameters\nstart_time\ninteger\n\nRequired\nStart time (Unix seconds) of the query time range, inclusive.\n\nbucket_width\nstring\n\nOptional\nDefaults to 1d\nWidth of each time bucket in response. Currently 1m, 1h and 1d are supported, default to 1d.\n\nend_time\ninteger\n\nOptional\nEnd time (Unix seconds) of the query time range, exclusive.\n\ngroup_by\narray\n\nOptional\nGroup the usage data by the specified fields. Support fields include project_id.\n\nlimit\ninteger\n\nOptional\nSpecifies the number of buckets to return.\n\nbuc", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 398900, "end_char": 399500}, "799": {"text": " fields include project_id.\n\nlimit\ninteger\n\nOptional\nSpecifies the number of buckets to return.\n\nbucket_width=1d: default: 7, max: 31\nbucket_width=1h: default: 24, max: 168\nbucket_width=1m: default: 60, max: 1440\npage\nstring\n\nOptional\nA cursor for use in pagination. Corresponding to the next_page field from the previous response.\n\nproject_ids\narray\n\nOptional\nReturn only usage for these projects.\n\nReturns\nA list of paginated, time bucketed Code interpreter sessions usage objects.\n\nExample request\ncurl \"https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 399400, "end_char": 400000}, "800": {"text": "\ncurl \"https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.code_interpreter_sessions.result\",\n                    \"num_sessions\": 1,\n                    \"project_id\": null\n                }\n            ]\n     ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 399900, "end_char": 400500}, "801": {"text": "     \"num_sessions\": 1,\n                    \"project_id\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\nCode interpreter sessions usage object\nThe aggregated code interpreter sessions usage details of the specific time bucket.\n\nnum_sessions\ninteger\n\nThe number of code interpreter sessions.\n\nobject\nstring\n\nproject_id\nstring or null\n\nWhen group_by=project_id, this field provides the project ID of the grouped usage result.\n\nOBJECT Code interpreter sessions usage object\n{\n    \"object\": \"organization.usage.code_interpreter_sessions.result\",\n   ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 400400, "end_char": 401000}, "802": {"text": "ter sessions usage object\n{\n    \"object\": \"organization.usage.code_interpreter_sessions.result\",\n    \"num_sessions\": 1,\n    \"project_id\": \"proj_abc\"\n}\nCosts\nget\n \nhttps://api.openai.com/v1/organization/costs\nGet costs details for the organization.\n\nQuery parameters\nstart_time\ninteger\n\nRequired\nStart time (Unix seconds) of the query time range, inclusive.\n\nbucket_width\nstring\n\nOptional\nDefaults to 1d\nWidth of each time bucket in response. Currently only 1d is supported, default to 1d.\n\nend_time\ninteger\n\nOptional\nEnd time (Unix seconds) of the query time range, exclusive.\n\ngroup_by\narray\n\nOption", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 400900, "end_char": 401500}, "803": {"text": "nteger\n\nOptional\nEnd time (Unix seconds) of the query time range, exclusive.\n\ngroup_by\narray\n\nOptional\nGroup the costs by the specified fields. Support fields include project_id, line_item and any combination of them.\n\nlimit\ninteger\n\nOptional\nDefaults to 7\nA limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7.\n\npage\nstring\n\nOptional\nA cursor for use in pagination. Corresponding to the next_page field from the previous response.\n\nproject_ids\narray\n\nOptional\nReturn only costs for these projects.\n\nReturns\nA list of paginated, time bucketed Costs ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 401400, "end_char": 402000}, "804": {"text": "y\n\nOptional\nReturn only costs for these projects.\n\nReturns\nA list of paginated, time bucketed Costs objects.\n\nExample request\ncurl \"https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\nResponse\n{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.costs.result\",\n                    \"amount\": {\n          ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 401900, "end_char": 402500}, "805": {"text": "                   \"object\": \"organization.costs.result\",\n                    \"amount\": {\n                        \"value\": 0.06,\n                        \"currency\": \"usd\"\n                    },\n                    \"line_item\": null,\n                    \"project_id\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\nCosts object\nThe aggregated costs details of the specific time bucket.\n\namount\nobject\n\nThe monetary value in its associated currency.\n\n\nShow properties\nline_item\nstring or null\n\nWhen group_by=line_item, this field provides the line ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 402400, "end_char": 403000}, "806": {"text": ".\n\n\nShow properties\nline_item\nstring or null\n\nWhen group_by=line_item, this field provides the line item of the grouped costs result.\n\nobject\nstring\n\nproject_id\nstring or null\n\nWhen group_by=project_id, this field provides the project ID of the grouped costs result.\n\nOBJECT Costs object\n{\n    \"object\": \"organization.costs.result\",\n    \"amount\": {\n      \"value\": 0.06,\n      \"currency\": \"usd\"\n    },\n    \"line_item\": \"Image models\",\n    \"project_id\": \"proj_abc\"\n}\nCertificates\nBeta\nManage Mutual TLS certificates across your organization and projects.\n\nLearn more about Mutual TLS.\n\nUpload certifica", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 402900, "end_char": 403500}, "807": {"text": " certificates across your organization and projects.\n\nLearn more about Mutual TLS.\n\nUpload certificate\npost\n \nhttps://api.openai.com/v1/organization/certificates\nUpload a certificate to the organization. This does not automatically activate the certificate.\n\nOrganizations can upload up to 50 certificates.\n\nRequest body\ncontent\nstring\n\nRequired\nThe certificate content in PEM format\n\nname\nstring\n\nOptional\nAn optional name for the certificate\n\nReturns\nA single Certificate object.\n\nExample request\ncurl -X POST https://api.openai.com/v1/organization/certificates \\\n-H \"Authorization: Bearer $OPENAI_", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 403400, "end_char": 404000}, "808": {"text": "url -X POST https://api.openai.com/v1/organization/certificates \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"name\": \"My Example Certificate\",\n  \"certificate\": \"-----BEGIN CERTIFICATE-----\\\\nMIIDeT...\\\\n-----END CERTIFICATE-----\"\n}'\nResponse\n{\n  \"object\": \"certificate\",\n  \"id\": \"cert_abc\",\n  \"name\": \"My Example Certificate\",\n  \"created_at\": 1234567,\n  \"certificate_details\": {\n    \"valid_at\": 12345667,\n    \"expires_at\": 12345678\n  }\n}\nGet certificate\nget\n \nhttps://api.openai.com/v1/organization/certificates/{certificate_id}\nGet a certificate tha", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 403900, "end_char": 404500}, "809": {"text": "ate\nget\n \nhttps://api.openai.com/v1/organization/certificates/{certificate_id}\nGet a certificate that has been uploaded to the organization.\n\nYou can get a certificate regardless of whether it is active or not.\n\nPath parameters\ncert_id\nstring\n\nRequired\nUnique ID of the certificate to retrieve.\n\nQuery parameters\ninclude\narray\n\nOptional\nA list of additional fields to include in the response. Currently the only supported value is content to fetch the PEM content of the certificate.\n\nReturns\nA single Certificate object.\n\nExample request\ncurl \"https://api.openai.com/v1/organization/certificates/cer", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 404400, "end_char": 405000}, "810": {"text": "e Certificate object.\n\nExample request\ncurl \"https://api.openai.com/v1/organization/certificates/cert_abc?include[]=content\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\"\nResponse\n{\n  \"object\": \"certificate\",\n  \"id\": \"cert_abc\",\n  \"name\": \"My Example Certificate\",\n  \"created_at\": 1234567,\n  \"certificate_details\": {\n    \"valid_at\": 1234567,\n    \"expires_at\": 12345678,\n    \"content\": \"-----BEGIN CERTIFICATE-----MIIDeT...-----END CERTIFICATE-----\"\n  }\n}\nModify certificate\npost\n \nhttps://api.openai.com/v1/organization/certificates/{certificate_id}\nModify a certificate. Note that only the name can", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 404900, "end_char": 405500}, "811": {"text": ".com/v1/organization/certificates/{certificate_id}\nModify a certificate. Note that only the name can be modified.\n\nRequest body\nname\nstring\n\nRequired\nThe updated name for the certificate\n\nReturns\nThe updated Certificate object.\n\nExample request\ncurl -X POST https://api.openai.com/v1/organization/certificates/cert_abc \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"name\": \"Renamed Certificate\"\n}'\nResponse\n{\n  \"object\": \"certificate\",\n  \"id\": \"cert_abc\",\n  \"name\": \"Renamed Certificate\",\n  \"created_at\": 1234567,\n  \"certificate_details\": {\n    \"valid", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 405400, "end_char": 406000}, "812": {"text": "bc\",\n  \"name\": \"Renamed Certificate\",\n  \"created_at\": 1234567,\n  \"certificate_details\": {\n    \"valid_at\": 12345667,\n    \"expires_at\": 12345678\n  }\n}\nDelete certificate\ndelete\n \nhttps://api.openai.com/v1/organization/certificates/{certificate_id}\nDelete a certificate from the organization.\n\nThe certificate must be inactive for the organization and all projects.\n\nReturns\nA confirmation object indicating the certificate was deleted.\n\nExample request\ncurl -X DELETE https://api.openai.com/v1/organization/certificates/cert_abc \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\"\nResponse\n{\n  \"object\": \"ce", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 405900, "end_char": 406500}, "813": {"text": "tion/certificates/cert_abc \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\"\nResponse\n{\n  \"object\": \"certificate.deleted\",\n  \"id\": \"cert_abc\"\n}\nList organization certificates\nget\n \nhttps://api.openai.com/v1/organization/certificates\nList uploaded certificates for this organization.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nlimit\nin", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 406400, "end_char": 407000}, "814": {"text": "our subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\n\nOptional\nDefaults to desc\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nReturns\nA list of Certificate objects.\n\nExample request\ncurl https://api.openai.com/v1/organization/certificates \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\"\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 406900, "end_char": 407500}, "815": {"text": "es \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\"\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"organization.certificate\",\n      \"id\": \"cert_abc\",\n      \"name\": \"My Example Certificate\",\n      \"active\": true,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n  ],\n  \"first_id\": \"cert_abc\",\n  \"last_id\": \"cert_abc\",\n  \"has_more\": false\n}\nList project certificates\nget\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/certificates\nList certificates for this project.\n\nQuery paramete", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 407400, "end_char": 408000}, "816": {"text": "/organization/projects/{project_id}/certificates\nList certificates for this project.\n\nQuery parameters\nafter\nstring\n\nOptional\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nlimit\ninteger\n\nOptional\nDefaults to 20\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\n\nOptional\nDefaults to desc\nSort order by th", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 407900, "end_char": 408500}, "817": {"text": " between 1 and 100, and the default is 20.\n\norder\nstring\n\nOptional\nDefaults to desc\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nReturns\nA list of Certificate objects.\n\nExample request\ncurl https://api.openai.com/v1/organization/projects/proj_abc/certificates \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\"\nResponse\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"organization.project.certificate\",\n      \"id\": \"cert_abc\",\n      \"name\": \"My Example Certificate\",\n      \"active\": true,\n      \"created_at\": 1234567,\n      \"cert", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 408400, "end_char": 409000}, "818": {"text": "    \"name\": \"My Example Certificate\",\n      \"active\": true,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n  ],\n  \"first_id\": \"cert_abc\",\n  \"last_id\": \"cert_abc\",\n  \"has_more\": false\n}\nActivate certificates for organization\npost\n \nhttps://api.openai.com/v1/organization/certificates/activate\nActivate certificates at the organization level.\n\nYou can atomically and idempotently activate up to 10 certificates at a time.\n\nRequest body\ncertificate_ids\narray\n\nRequired\nReturns\nA list of Certificate objects that we", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 408900, "end_char": 409500}, "819": {"text": " a time.\n\nRequest body\ncertificate_ids\narray\n\nRequired\nReturns\nA list of Certificate objects that were activated.\n\nExample request\ncurl https://api.openai.com/v1/organization/certificates/activate \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"data\": [\"cert_abc\", \"cert_def\"]\n}'\nResponse\n{\n  \"object\": \"organization.certificate.activation\",\n  \"data\": [\n    {\n      \"object\": \"organization.certificate\",\n      \"id\": \"cert_abc\",\n      \"name\": \"My Example Certificate\",\n      \"active\": true,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n  ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 409400, "end_char": 410000}, "820": {"text": "e Certificate\",\n      \"active\": true,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n    {\n      \"object\": \"organization.certificate\",\n      \"id\": \"cert_def\",\n      \"name\": \"My Example Certificate 2\",\n      \"active\": true,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n  ],\n}\nDeactivate certificates for organization\npost\n \nhttps://api.openai.com/v1/organization/certificates/deactivate\nDeactivate certificates at the org", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 409900, "end_char": 410500}, "821": {"text": "\n \nhttps://api.openai.com/v1/organization/certificates/deactivate\nDeactivate certificates at the organization level.\n\nYou can atomically and idempotently deactivate up to 10 certificates at a time.\n\nRequest body\ncertificate_ids\narray\n\nRequired\nReturns\nA list of Certificate objects that were deactivated.\n\nExample request\ncurl https://api.openai.com/v1/organization/certificates/deactivate \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"data\": [\"cert_abc\", \"cert_def\"]\n}'\nResponse\n{\n  \"object\": \"organization.certificate.deactivation\",\n  \"data\": [\n   ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 410400, "end_char": 411000}, "822": {"text": "abc\", \"cert_def\"]\n}'\nResponse\n{\n  \"object\": \"organization.certificate.deactivation\",\n  \"data\": [\n    {\n      \"object\": \"organization.certificate\",\n      \"id\": \"cert_abc\",\n      \"name\": \"My Example Certificate\",\n      \"active\": false,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n    {\n      \"object\": \"organization.certificate\",\n      \"id\": \"cert_def\",\n      \"name\": \"My Example Certificate 2\",\n      \"active\": false,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 410900, "end_char": 411500}, "823": {"text": ": false,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n  ],\n}\nActivate certificates for project\npost\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/certificates/activate\nActivate certificates at the project level.\n\nYou can atomically and idempotently activate up to 10 certificates at a time.\n\nRequest body\ncertificate_ids\narray\n\nRequired\nReturns\nA list of Certificate objects that were activated.\n\nExample request\ncurl https://api.openai.com/v1/organization/projects/proj_abc/certificates/acti", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 411400, "end_char": 412000}, "824": {"text": "ed.\n\nExample request\ncurl https://api.openai.com/v1/organization/projects/proj_abc/certificates/activate \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"data\": [\"cert_abc\", \"cert_def\"]\n}'\nResponse\n{\n  \"object\": \"organization.project.certificate.activation\",\n  \"data\": [\n    {\n      \"object\": \"organization.project.certificate\",\n      \"id\": \"cert_abc\",\n      \"name\": \"My Example Certificate\",\n      \"active\": true,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n  ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 411900, "end_char": 412500}, "825": {"text": "rtificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n    {\n      \"object\": \"organization.project.certificate\",\n      \"id\": \"cert_def\",\n      \"name\": \"My Example Certificate 2\",\n      \"active\": true,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n  ],\n}\nDeactivate certificates for project\npost\n \nhttps://api.openai.com/v1/organization/projects/{project_id}/certificates/deactivate\nDeactivate certificates at the project level.\n\nYou can atomically and idempotently de", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 412400, "end_char": 413000}, "826": {"text": "tes/deactivate\nDeactivate certificates at the project level.\n\nYou can atomically and idempotently deactivate up to 10 certificates at a time.\n\nRequest body\ncertificate_ids\narray\n\nRequired\nReturns\nA list of Certificate objects that were deactivated.\n\nExample request\ncurl https://api.openai.com/v1/organization/projects/proj_abc/certificates/deactivate \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"data\": [\"cert_abc\", \"cert_def\"]\n}'\nResponse\n{\n  \"object\": \"organization.project.certificate.deactivation\",\n  \"data\": [\n    {\n      \"object\": \"organizati", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 412900, "end_char": 413500}, "827": {"text": "ect\": \"organization.project.certificate.deactivation\",\n  \"data\": [\n    {\n      \"object\": \"organization.project.certificate\",\n      \"id\": \"cert_abc\",\n      \"name\": \"My Example Certificate\",\n      \"active\": false,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n    {\n      \"object\": \"organization.project.certificate\",\n      \"id\": \"cert_def\",\n      \"name\": \"My Example Certificate 2\",\n      \"active\": false,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expire", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 413400, "end_char": 414000}, "828": {"text": " \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n  ],\n}\nThe certificate object\nRepresents an individual certificate uploaded to the organization.\n\nactive\nboolean\n\nWhether the certificate is currently active at the specified scope. Not returned when getting details for a specific certificate.\n\ncertificate_details\nobject\n\n\nShow properties\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) of when the certificate was uploaded.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints\n\nname\nstring\n\nThe na", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 413900, "end_char": 414500}, "829": {"text": " uploaded.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints\n\nname\nstring\n\nThe name of the certificate.\n\nobject\nstring\n\nThe object type.\n\nIf creating, updating, or getting a specific certificate, the object type is certificate.\nIf listing, activating, or deactivating certificates for the organization, the object type is organization.certificate.\nIf listing, activating, or deactivating certificates for a project, the object type is organization.project.certificate.\nOBJECT The certificate object\n{\n  \"object\": \"certificate\",\n  \"id\": \"cert_abc\",\n  \"name\": \"My Certificate\",\n  \"cr", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 414400, "end_char": 415000}, "830": {"text": "ertificate object\n{\n  \"object\": \"certificate\",\n  \"id\": \"cert_abc\",\n  \"name\": \"My Certificate\",\n  \"created_at\": 1234567,\n  \"certificate_details\": {\n    \"valid_at\": 1234567,\n    \"expires_at\": 12345678,\n    \"content\": \"-----BEGIN CERTIFICATE----- MIIGAjCCA...6znFlOW+ -----END CERTIFICATE-----\"\n  }\n}\nCompletions\nLegacy\nGiven a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our Chat Completions API to leverage our best and newest models.\n\nCreate completion\nLegacy\npost\n \nhttps://api.openai", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 414900, "end_char": 415500}, "831": {"text": "ions API to leverage our best and newest models.\n\nCreate completion\nLegacy\npost\n \nhttps://api.openai.com/v1/completions\nCreates a completion for the provided prompt and parameters.\n\nRequest body\nmodel\nstring\n\nRequired\nID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.\n\nprompt\nstring or array\n\nRequired\nThe prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.\n\nNote that <|endoftext|> is the document separator that the model sees during ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 415400, "end_char": 416000}, "832": {"text": "rray of token arrays.\n\nNote that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.\n\nbest_of\ninteger or null\n\nOptional\nDefaults to 1\nGenerates best_of completions server-side and returns the \"best\" (the one with the highest log probability per token). Results cannot be streamed.\n\nWhen used with n, best_of controls the number of candidate completions and n specifies how many to return \u2013 best_of must be greater than n.\n\nNote: Because this parameter generates many completi", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 415900, "end_char": 416500}, "833": {"text": "ny to return \u2013 best_of must be greater than n.\n\nNote: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.\n\necho\nboolean or null\n\nOptional\nDefaults to false\nEcho back the prompt in addition to the completion\n\nfrequency_penalty\nnumber or null\n\nOptional\nDefaults to 0\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n\nSee more information ab", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 416400, "end_char": 417000}, "834": {"text": "so far, decreasing the model's likelihood to repeat the same line verbatim.\n\nSee more information about frequency and presence penalties.\n\nlogit_bias\nmap\n\nOptional\nDefaults to null\nModify the likelihood of specified tokens appearing in the completion.\n\nAccepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this tokenizer tool to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 416900, "end_char": 417500}, "835": {"text": "enerated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.\n\nAs an example, you can pass {\"50256\": -100} to prevent the <|endoftext|> token from being generated.\n\nlogprobs\ninteger or null\n\nOptional\nDefaults to null\nInclude the log probabilities on the logprobs most likely output tokens, as well the chosen tokens. For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The A", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 417400, "end_char": 418000}, "836": {"text": "tokens. For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.\n\nThe maximum value for logprobs is 5.\n\nmax_tokens\ninteger or null\n\nOptional\nDefaults to 16\nThe maximum number of tokens that can be generated in the completion.\n\nThe token count of your prompt plus max_tokens cannot exceed the model's context length. Example Python code for counting tokens.\n\nn\ninteger or null\n\nOptional\nDefaults to 1\nHow many completions to generate for each prompt.\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 417900, "end_char": 418500}, "837": {"text": "okens.\n\nn\ninteger or null\n\nOptional\nDefaults to 1\nHow many completions to generate for each prompt.\n\nNote: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.\n\npresence_penalty\nnumber or null\n\nOptional\nDefaults to 0\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n\nSee more information about frequency and presence penalties.\n\nseed\ninteger or null\n\nO", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 418400, "end_char": 419000}, "838": {"text": "t new topics.\n\nSee more information about frequency and presence penalties.\n\nseed\ninteger or null\n\nOptional\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result.\n\nDeterminism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend.\n\nstop\nstring / array / null\n\nOptional\nDefaults to null\nNot supported with latest reasoning models o3 and o4-mini.\n\nUp to 4 sequences where the API will stop generating further tokens. The ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 418900, "end_char": 419500}, "839": {"text": "ng models o3 and o4-mini.\n\nUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.\n\nstream\nboolean or null\n\nOptional\nDefaults to false\nWhether to stream back partial progress. If set, tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message. Example Python code.\n\nstream_options\nobject or null\n\nOptional\nDefaults to null\nOptions for streaming response. Only set this when you set stream: true.\n\n\nShow properties\nsuffix\nstring or null\n\nOptional\nDefaults to nul", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 419400, "end_char": 420000}, "840": {"text": "et this when you set stream: true.\n\n\nShow properties\nsuffix\nstring or null\n\nOptional\nDefaults to null\nThe suffix that comes after a completion of inserted text.\n\nThis parameter is only supported for gpt-3.5-turbo-instruct.\n\ntemperature\nnumber or null\n\nOptional\nDefaults to 1\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or top_p but not both.\n\ntop_p\nnumber or null\n\nOptional\nDefaults to 1\nAn alternative to sampling with tempe", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 419900, "end_char": 420500}, "841": {"text": "_p but not both.\n\ntop_p\nnumber or null\n\nOptional\nDefaults to 1\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n\nuser\nstring\n\nOptional\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.\n\nReturns\nReturns a completion object, or a sequence of completion objects if the request is streamed", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 420400, "end_char": 421000}, "842": {"text": "\nReturns\nReturns a completion object, or a sequence of completion objects if the request is streamed.\n\n\nNo streaming\n\nStreaming\nExample request\nfrom openai import OpenAI\nclient = OpenAI()\n\nclient.completions.create(\n  model=\"gpt-3.5-turbo-instruct\",\n  prompt=\"Say this is a test\",\n  max_tokens=7,\n  temperature=0\n)\nResponse\n{\n  \"id\": \"cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7\",\n  \"object\": \"text_completion\",\n  \"created\": 1589478378,\n  \"model\": \"gpt-3.5-turbo-instruct\",\n  \"system_fingerprint\": \"fp_44709d6fcb\",\n  \"choices\": [\n    {\n      \"text\": \"\\n\\nThis is indeed a test\",\n      \"index\": 0,\n      \"logprobs\":", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 420900, "end_char": 421500}, "843": {"text": "\n  \"choices\": [\n    {\n      \"text\": \"\\n\\nThis is indeed a test\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\": \"length\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 5,\n    \"completion_tokens\": 7,\n    \"total_tokens\": 12\n  }\n}\nThe completion object\nLegacy\nRepresents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).\n\nchoices\narray\n\nThe list of completion choices the model generated for the input prompt.\n\n\nShow properties\ncreated\ninteger\n\nThe Unix timestamp (in seconds) of when the compl", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 421400, "end_char": 422000}, "844": {"text": "e input prompt.\n\n\nShow properties\ncreated\ninteger\n\nThe Unix timestamp (in seconds) of when the completion was created.\n\nid\nstring\n\nA unique identifier for the completion.\n\nmodel\nstring\n\nThe model used for completion.\n\nobject\nstring\n\nThe object type, which is always \"text_completion\"\n\nsystem_fingerprint\nstring\n\nThis fingerprint represents the backend configuration that the model runs with.\n\nCan be used in conjunction with the seed request parameter to understand when backend changes have been made that might impact determinism.\n\nusage\nobject\n\nUsage statistics for the completion request.\n\n\nShow ", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 421900, "end_char": 422500}, "845": {"text": "e that might impact determinism.\n\nusage\nobject\n\nUsage statistics for the completion request.\n\n\nShow properties\nOBJECT The completion object\n{\n  \"id\": \"cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7\",\n  \"object\": \"text_completion\",\n  \"created\": 1589478378,\n  \"model\": \"gpt-4-turbo\",\n  \"choices\": [\n    {\n      \"text\": \"\\n\\nThis is indeed a test\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\": \"length\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 5,\n    \"completion_tokens\": 7,\n    \"total_tokens\": 12\n  }\n}\n", "metadata": {"doc_id": "api_reference", "strategy": "character", "chunk_size": 500}, "start_char": 422400, "end_char": 423000}}